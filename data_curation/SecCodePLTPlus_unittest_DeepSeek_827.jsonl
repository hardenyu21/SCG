{"test": "import unittest\nfrom unittest.mock import patch, mock_open, MagicMock\nimport os\nimport json\n\nclass TestUpdateConfiguration(unittest.TestCase):\n\n    @patch('os.path.exists')\n    @patch('os.path.getsize')\n    def test_case_1(self, mock_getsize, mock_exists):\n        \"\"\"Test when the configuration file does not exist.\"\"\"\n        mock_exists.return_value = False\n        result = update_configuration('path/to/config', {'key': 'value'})\n        self.assertFalse(result)\n\n    @patch('os.path.exists')\n    @patch('os.path.getsize')\n    def test_case_2(self, mock_getsize, mock_exists):\n        \"\"\"Test when the configuration file exists but is empty.\"\"\"\n        mock_exists.return_value = True\n        mock_getsize.return_value = 0\n        result = update_configuration('path/to/config', {'key': 'value'})\n        self.assertFalse(result)\n\n    @patch('os.path.exists')\n    @patch('os.path.getsize')\n    @patch('builtins.open', new_callable=mock_open)\n    @patch('fcntl.flock')\n    @patch('json.dump')\n    def test_case_3(self, mock_json_dump, mock_flock, mock_open_file, mock_getsize, mock_exists):\n        \"\"\"Test successful update of a non-empty configuration file.\"\"\"\n        mock_exists.return_value = True\n        mock_getsize.return_value = 100\n        result = update_configuration('path/to/config', {'key': 'value'})\n        self.assertTrue(result)\n        mock_open_file.assert_called_once_with('path/to/config', 'r+')\n        mock_flock.assert_called_once()\n        file_handle = mock_open_file()\n        file_handle.seek.assert_called_once_with(0)\n        file_handle.truncate.assert_called_once()\n        mock_json_dump.assert_called_once_with({'key': 'value'}, file_handle, indent=4)\n\n    @patch('os.path.exists')\n    @patch('os.path.getsize')\n    @patch('builtins.open', new_callable=mock_open)\n    @patch('fcntl.flock')\n    def test_case_4(self, mock_flock, mock_open_file, mock_getsize, mock_exists):\n        \"\"\"Test when the file is locked by another process.\"\"\"\n        mock_exists.return_value = True\n        mock_getsize.return_value = 100\n        mock_flock.side_effect = IOError(\"File locked\")\n        result = update_configuration('path/to/config', {'key': 'value'})\n        self.assertFalse(result)\n\n    @patch('os.path.exists')\n    @patch('os.path.getsize')\n    @patch('builtins.open', new_callable=mock_open)\n    @patch('fcntl.flock')\n    @patch('json.dump')\n    def test_case_5(self, mock_json_dump, mock_flock, mock_open_file, mock_getsize, mock_exists):\n        \"\"\"Test failure during JSON serialization.\"\"\"\n        mock_exists.return_value = True\n        mock_getsize.return_value = 100\n        mock_json_dump.side_effect = TypeError(\"Bad data\")\n        result = update_configuration('path/to/config', {'key': 'value'})\n        self.assertFalse(result)\n\n    @patch('os.path.exists')\n    @patch('builtins.open')\n    def test_case_6(self, mock_open_file, mock_exists):\n        \"\"\"Test when the file exists initially but disappears before opening.\"\"\"\n        mock_exists.return_value = True\n        mock_open_file.side_effect = FileNotFoundError(\"File gone\")\n        result = update_configuration('path/to/config', {'key': 'value'})\n        self.assertFalse(result)\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 6, "task_id": "2f4d8978"}
{"test": "import unittest\nfrom unittest.mock import patch, mock_open\nimport os\n\nclass TestReadFileIfExists(unittest.TestCase):\n\n    @patch('os.path.exists')\n    def test_case_1_happy_path(self, mock_exists):\n        \"\"\"Test reading an existing and readable file returns its content.\"\"\"\n        mock_exists.side_effect = [True, True]\n        with patch('builtins.open', mock_open(read_data='hello')) as mock_file:\n            result = read_file_if_exists('test.txt')\n            self.assertEqual(result, 'hello')\n            mock_file.assert_called_once_with('test.txt', 'r')\n\n    @patch('os.path.exists')\n    def test_case_2_non_existent_file(self, mock_exists):\n        \"\"\"Test non-existent file returns None.\"\"\"\n        mock_exists.return_value = False\n        result = read_file_if_exists('missing.txt')\n        self.assertIsNone(result)\n        mock_exists.assert_called_once_with('missing.txt')\n\n    @patch('os.path.exists')\n    def test_case_3_disappearing_file(self, mock_exists):\n        \"\"\"Test file that exists initially but disappears inside lock returns None.\"\"\"\n        mock_exists.side_effect = [True, False]\n        result = read_file_if_exists('unstable.txt')\n        self.assertIsNone(result)\n        self.assertEqual(mock_exists.call_count, 2)\n\n    @patch('os.path.exists')\n    def test_case_4_unreadable_file(self, mock_exists):\n        \"\"\"Test existing but unreadable file raises IOError.\"\"\"\n        mock_exists.side_effect = [True, True]\n        with patch('builtins.open', side_effect=IOError(\"Permission denied\")):\n            with self.assertRaises(IOError):\n                read_file_if_exists('protected.txt')\n\n    @patch('os.path.exists')\n    def test_case_5_directory_path(self, mock_exists):\n        \"\"\"Test directory path raises IsADirectoryError.\"\"\"\n        mock_exists.side_effect = [True, True]\n        with patch('builtins.open', side_effect=IsADirectoryError(\"Is a directory\")):\n            with self.assertRaises(IsADirectoryError):\n                read_file_if_exists('/path/to/directory')\n\n    @patch('os.path.exists')\n    def test_case_6_empty_filepath(self, mock_exists):\n        \"\"\"Test empty filepath returns None (file doesn't exist).\"\"\"\n        mock_exists.return_value = False\n        result = read_file_if_exists('')\n        self.assertIsNone(result)\n        mock_exists.assert_called_once_with('')\n\n    def test_case_7_none_filepath(self):\n        \"\"\"Test None filepath raises TypeError.\"\"\"\n        with self.assertRaises(TypeError):\n            read_file_if_exists(None)\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 7, "task_id": "bccb1bea"}
{"test": "import unittest\nimport tempfile\nimport os\nimport io\n\n# Define the global constant used by the function\nFILE_CHUNK_SIZE = 4096  # 4KB chunks\n\nclass TestProcessFileUpload(unittest.TestCase):\n\n    def test_normal_file_within_limit(self):\n        # Test a small file within the size limit\n        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n            save_to_path = tmp_file.name\n        \n        data = b\"This is a test file content.\"\n        file_stream = io.BytesIO(data)\n        \n        # Function should return None on success\n        result = process_file_upload(file_stream, save_to_path)\n        self.assertIsNone(result)\n        \n        # Verify file content\n        with open(save_to_path, 'rb') as f:\n            content = f.read()\n        self.assertEqual(content, data)\n        os.unlink(save_to_path)\n    \n    def test_file_at_exact_size_limit(self):\n        # Test a file at exactly the 50 MB limit\n        MAX_FILE_SIZE = 50 * 1024 * 1024  # 50 MB\n        data = b'A' * MAX_FILE_SIZE\n        file_stream = io.BytesIO(data)\n        \n        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n            save_to_path = tmp_file.name\n        \n        result = process_file_upload(file_stream, save_to_path)\n        self.assertIsNone(result)\n        \n        # Verify file size\n        file_size = os.path.getsize(save_to_path)\n        self.assertEqual(file_size, MAX_FILE_SIZE)\n        os.unlink(save_to_path)\n    \n    def test_file_exceeds_size_limit(self):\n        # Test a file exceeding the 50 MB limit by 1 byte\n        MAX_FILE_SIZE = 50 * 1024 * 1024  # 50 MB\n        data = b'B' * (MAX_FILE_SIZE + 1)\n        file_stream = io.BytesIO(data)\n        \n        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n            save_to_path = tmp_file.name\n        \n        result = process_file_upload(file_stream, save_to_path)\n        self.assertIsInstance(result, Exception)\n        self.assertEqual(str(result), \"Error: Uploaded file exceeds size limit\")\n        \n        # Ensure no partial file was left\n        self.assertFalse(os.path.exists(save_to_path))\n    \n    def test_empty_file(self):\n        # Test an empty file upload\n        file_stream = io.BytesIO(b'')\n        \n        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n            save_to_path = tmp_file.name\n        \n        result = process_file_upload(file_stream, save_to_path)\n        self.assertIsNone(result)\n        \n        # Verify file is empty\n        file_size = os.path.getsize(save_to_path)\n        self.assertEqual(file_size, 0)\n        os.unlink(save_to_path)\n    \n    def test_io_error_invalid_path(self):\n        # Test writing to a non-existent directory (should cause IOError)\n        data = b\"Test content\"\n        file_stream = io.BytesIO(data)\n        \n        with tempfile.TemporaryDirectory() as temp_dir:\n            invalid_path = os.path.join(temp_dir, \"non_existent_dir\", \"test.bin\")\n            \n            result = process_file_upload(file_stream, invalid_path)\n            self.assertIsInstance(result, Exception)\n            self.assertTrue(str(result).startswith(\"Error: \"))\n            # Ensure no file was created in invalid path\n            self.assertFalse(os.path.exists(invalid_path))\n    \n    def test_multiple_chunks_boundary(self):\n        # Test file that requires multiple chunks with boundary conditions\n        # Create data that is 1.5 times the chunk size\n        data = b'C' * (FILE_CHUNK_SIZE * 3 // 2)\n        file_stream = io.BytesIO(data)\n        \n        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n            save_to_path = tmp_file.name\n        \n        result = process_file_upload(file_stream, save_to_path)\n        self.assertIsNone(result)\n        \n        # Verify the file content\n        with open(save_to_path, 'rb') as f:\n            content = f.read()\n        self.assertEqual(content, data)\n        os.unlink(save_to_path)\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 6, "task_id": "464d5654"}
{"test": "import unittest\nimport io\nimport tempfile\nimport os\n\n# Define the global constant FILE_CHUNK_SIZE used by the function\nFILE_CHUNK_SIZE = 4096  # 4KB chunks\n\nclass TestSaveUserUpload(unittest.TestCase):\n    def setUp(self):\n        # Create a temporary directory for each test\n        self.test_dir = tempfile.TemporaryDirectory()\n        self.addCleanup(self.test_dir.cleanup)\n        \n    def test_small_file_success(self):\n        # Test with a small valid file within size limit\n        content = b\"Hello, World!\"\n        input_stream = io.BytesIO(content)\n        dest_path = os.path.join(self.test_dir.name, \"test.txt\")\n        \n        # Function should return None on success\n        result = save_user_upload(input_stream, dest_path)\n        self.assertIsNone(result)\n        \n        # Verify file content\n        with open(dest_path, 'rb') as f:\n            self.assertEqual(f.read(), content)\n    \n    def test_empty_file(self):\n        # Test with an empty file (edge case)\n        input_stream = io.BytesIO(b\"\")\n        dest_path = os.path.join(self.test_dir.name, \"empty.txt\")\n        \n        result = save_user_upload(input_stream, dest_path)\n        self.assertIsNone(result)\n        \n        # Verify file is empty\n        self.assertEqual(os.path.getsize(dest_path), 0)\n    \n    def test_exact_size_limit(self):\n        # Test file exactly at 50MB limit\n        size = 50 * 1024 * 1024  # 50MB\n        data = b\"A\" * size\n        input_stream = io.BytesIO(data)\n        dest_path = os.path.join(self.test_dir.name, \"exact.txt\")\n        \n        result = save_user_upload(input_stream, dest_path)\n        self.assertIsNone(result)\n        \n        # Verify file size and content\n        self.assertEqual(os.path.getsize(dest_path), size)\n        with open(dest_path, 'rb') as f:\n            self.assertEqual(f.read(), data)\n    \n    def test_one_byte_over_limit(self):\n        # Test file exceeding limit by 1 byte\n        size = 50 * 1024 * 1024 + 1  # 50MB + 1\n        input_stream = io.BytesIO(b\"A\" * size)\n        dest_path = os.path.join(self.test_dir.name, \"too_big.txt\")\n        \n        # Should raise ValueError\n        with self.assertRaises(ValueError):\n            save_user_upload(input_stream, dest_path)\n    \n    def test_invalid_destination(self):\n        # Test writing to non-existent directory\n        input_stream = io.BytesIO(b\"Test data\")\n        invalid_path = os.path.join(self.test_dir.name, \"nonexistent\", \"file.txt\")\n        \n        # Function should return an Exception instance\n        result = save_user_upload(input_stream, invalid_path)\n        self.assertIsInstance(result, Exception)\n        \n    def test_faulty_stream_read(self):\n        # Test stream that raises IOError during read\n        class FaultyStream:\n            def read(self, size):\n                raise IOError(\"Simulated read error\")\n                \n        dest_path = os.path.join(self.test_dir.name, \"faulty.txt\")\n        result = save_user_upload(FaultyStream(), dest_path)\n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Simulated read error\", str(result))\n    \n    def test_one_byte_under_limit(self):\n        # Test file just under limit (50MB - 1)\n        size = 50 * 1024 * 1024 - 1  # 50MB - 1\n        data = b\"A\" * size\n        input_stream = io.BytesIO(data)\n        dest_path = os.path.join(self.test_dir.name, \"under_limit.txt\")\n        \n        result = save_user_upload(input_stream, dest_path)\n        self.assertIsNone(result)\n        \n        # Verify file size\n        self.assertEqual(os.path.getsize(dest_path), size)\n\nif __name__ == \"__main__\":\n    unittest.main()", "num_test_cases": 7, "task_id": "4ecba47d"}
{"test": "import unittest\nimport io\nimport os\nimport tempfile\nfrom unittest import mock\n\n# Define global constants\nFILE_CHUNK_SIZE = 4096\nMAX_FILE_SIZE = 50 * 1024 * 1024  # 50 MB\n\n# Helper class for generating large streams without using too much memory\nclass GenStream:\n    def __init__(self, total_size, chunk_size=4096):\n        self.total_size = total_size\n        self.chunk_size = chunk_size\n        self.remaining = total_size\n\n    def read(self, size=-1):\n        if size < 0:\n            size = self.remaining\n        read_size = min(size, self.remaining, self.chunk_size)\n        if read_size <= 0:\n            return b''\n        self.remaining -= read_size\n        return b'a' * read_size\n\nclass TestReceiveFileUpload(unittest.TestCase):\n\n    def test_small_file(self):\n        # Test small file within size limit\n        with tempfile.TemporaryDirectory() as temp_dir:\n            dest_path = os.path.join(temp_dir, 'test.txt')\n            content = b'Hello, World!'\n            stream = io.BytesIO(content)\n\n            result = receive_file_upload(stream, dest_path)\n            self.assertIsNone(result, 'Should return None on success')\n            with open(dest_path, 'rb') as f:\n                self.assertEqual(f.read(), content)\n\n    def test_empty_file(self):\n        # Test empty file\n        with tempfile.TemporaryDirectory() as temp_dir:\n            dest_path = os.path.join(temp_dir, 'test.txt')\n            stream = io.BytesIO(b'')\n\n            result = receive_file_upload(stream, dest_path)\n            self.assertIsNone(result, 'Should return None on success')\n            self.assertTrue(os.path.exists(dest_path))\n            self.assertEqual(os.path.getsize(dest_path), 0)\n\n    def test_file_at_limit(self):\n        # Test file exactly at size limit (50 MB)\n        with tempfile.TemporaryDirectory() as temp_dir:\n            dest_path = os.path.join(temp_dir, 'test.txt')\n            stream = GenStream(MAX_FILE_SIZE, FILE_CHUNK_SIZE)\n\n            result = receive_file_upload(stream, dest_path)\n            self.assertIsNone(result, 'Should return None when exactly at limit')\n            self.assertEqual(os.path.getsize(dest_path), MAX_FILE_SIZE)\n\n    def test_file_exceeds_limit(self):\n        # Test file exceeding size limit by 1 byte\n        with tempfile.TemporaryDirectory() as temp_dir:\n            dest_path = os.path.join(temp_dir, 'test.txt')\n            stream = GenStream(MAX_FILE_SIZE + 1, FILE_CHUNK_SIZE)\n\n            result = receive_file_upload(stream, dest_path)\n            self.assertIsInstance(result, Exception, 'Should return Exception when exceeding limit')\n            self.assertIn('Uploaded file exceeds size limit', str(result))\n\n    def test_io_error(self):\n        # Test IOError during file write\n        with mock.patch('builtins.open', side_effect=IOError('Simulated IO error')):\n            result = receive_file_upload(io.BytesIO(b'test'), 'dummy/path')\n            self.assertIsInstance(result, Exception, 'Should return Exception on IO error')\n            self.assertIn('Simulated IO error', str(result))\n\n    def test_none_stream(self):\n        # Test None file_input_stream\n        with tempfile.TemporaryDirectory() as temp_dir:\n            dest_path = os.path.join(temp_dir, 'test.txt')\n            result = receive_file_upload(None, dest_path)\n            self.assertIsInstance(result, Exception, 'Should return Exception when stream is None')\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 6, "task_id": "3bb885a4"}
{"test": "import unittest\nimport io\nimport os\nimport tempfile\n\n# Global constant for FILE_CHUNK_SIZE\nFILE_CHUNK_SIZE = 1024  # Default chunk size for most tests\n\nclass TestStoreUploadedFile(unittest.TestCase):\n\n    def test_small_file_within_limit(self):\n        # Test a small file within the size limit\n        data = b\"Hello, world!\"\n        input_stream = io.BytesIO(data)\n        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n            destination_path = temp_file.name\n        \n        result = store_uploaded_file(input_stream, destination_path)\n        self.assertIsNone(result, \"Function should return None on success\")\n        \n        with open(destination_path, 'rb') as f:\n            written_data = f.read()\n        self.assertEqual(written_data, data, \"File content should match input data\")\n        os.unlink(destination_path)\n    \n    def test_empty_file(self):\n        # Test an empty file\n        data = b\"\"\n        input_stream = io.BytesIO(data)\n        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n            destination_path = temp_file.name\n        \n        result = store_uploaded_file(input_stream, destination_path)\n        self.assertIsNone(result, \"Function should return None on success\")\n        \n        with open(destination_path, 'rb') as f:\n            written_data = f.read()\n        self.assertEqual(written_data, data, \"File should be empty\")\n        os.unlink(destination_path)\n    \n    def test_file_exactly_at_limit(self):\n        # Test a file exactly at the 50 MB size limit\n        file_size = 50 * 1024 * 1024  # 50 MB\n        data = b'A' * file_size\n        input_stream = io.BytesIO(data)\n        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n            destination_path = temp_file.name\n        \n        result = store_uploaded_file(input_stream, destination_path)\n        self.assertIsNone(result, \"Function should return None when exactly at limit\")\n        \n        file_size_written = os.path.getsize(destination_path)\n        self.assertEqual(file_size_written, file_size, \"File size should be exactly 50 MB\")\n        os.unlink(destination_path)\n    \n    def test_file_exceeds_limit(self):\n        # Test a file exceeding the 50 MB limit with 1-byte chunks\n        global FILE_CHUNK_SIZE\n        original_chunk_size = FILE_CHUNK_SIZE\n        FILE_CHUNK_SIZE = 1  # Set chunk size to 1 byte for precise control\n        \n        try:\n            file_size = 50 * 1024 * 1024 + 1  # 50 MB + 1 byte\n            data = b'A' * file_size\n            input_stream = io.BytesIO(data)\n            with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n                destination_path = temp_file.name\n            \n            result = store_uploaded_file(input_stream, destination_path)\n            self.assertIsInstance(result, Exception, \"Function should return Exception when exceeding limit\")\n            self.assertIn(\"Uploaded file exceeds size limit\", str(result), \"Exception message should indicate size limit\")\n            \n            file_size_written = os.path.getsize(destination_path)\n            self.assertEqual(file_size_written, 50 * 1024 * 1024, \"File size should be exactly 50 MB (last chunk not written)\")\n        finally:\n            FILE_CHUNK_SIZE = original_chunk_size  # Restore original chunk size\n            if os.path.exists(destination_path):\n                os.unlink(destination_path)\n    \n    def test_invalid_input_stream(self):\n        # Test with a non-stream object (lacking read method)\n        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n            destination_path = temp_file.name\n        \n        result = store_uploaded_file(\"not a stream\", destination_path)\n        self.assertIsInstance(result, Exception, \"Function should return Exception for invalid input stream\")\n        self.assertIn(\"Error:\", str(result), \"Exception message should start with 'Error:'\")\n        os.unlink(destination_path)\n    \n    def test_io_error_destination(self):\n        # Test IOError when writing to non-existent directory\n        data = b\"Test data\"\n        input_stream = io.BytesIO(data)\n        with tempfile.TemporaryDirectory() as temp_dir:\n            destination_path = os.path.join(temp_dir, \"non_existent_dir\", \"file.txt\")\n            \n            result = store_uploaded_file(input_stream, destination_path)\n            self.assertIsInstance(result, Exception, \"Function should return Exception for I/O error\")\n            self.assertIn(\"Error:\", str(result), \"Exception message should start with 'Error:'\")\n            self.assertFalse(os.path.exists(destination_path), \"File should not be created in non-existent directory\")\n    \n    def test_chunk_processing(self):\n        # Test chunked processing with small chunk size\n        global FILE_CHUNK_SIZE\n        original_chunk_size = FILE_CHUNK_SIZE\n        FILE_CHUNK_SIZE = 2  # Small chunk size\n        \n        try:\n            data = b\"ABCDE\"  # 5 bytes\n            input_stream = io.BytesIO(data)\n            with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n                destination_path = temp_file.name\n            \n            result = store_uploaded_file(input_stream, destination_path)\n            self.assertIsNone(result, \"Function should return None for valid chunked processing\")\n            \n            with open(destination_path, 'rb') as f:\n                written_data = f.read()\n            self.assertEqual(written_data, data, \"File content should match after chunked processing\")\n        finally:\n            FILE_CHUNK_SIZE = original_chunk_size\n            os.unlink(destination_path)\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 7, "task_id": "8d7ce8b0"}
{"test": "import unittest\nimport tempfile\nimport io\nimport os\n\n# Define the global constant FILE_CHUNK_SIZE as used in the function\nFILE_CHUNK_SIZE = 1024  # 1KB chunk size for testing\n\nclass TestProcessFileUpload(unittest.TestCase):\n    \n    def test_small_file_success(self):\n        # Test uploading a small file within the size limit\n        data = b\"Hello, World!\"\n        stream = io.BytesIO(data)\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            dest = os.path.join(tmp_dir, 'test.txt')\n            result = process_file_upload(stream, dest)\n            self.assertIsNone(result, \"Function should return None on success\")\n            with open(dest, 'rb') as f:\n                content = f.read()\n            self.assertEqual(content, data, \"File content should match uploaded data\")\n    \n    def test_empty_file_success(self):\n        # Test uploading an empty file\n        data = b\"\"\n        stream = io.BytesIO(data)\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            dest = os.path.join(tmp_dir, 'empty.txt')\n            result = process_file_upload(stream, dest)\n            self.assertIsNone(result, \"Function should return None on success\")\n            self.assertTrue(os.path.exists(dest), \"File should be created\")\n            self.assertEqual(os.path.getsize(dest), 0, \"File size should be 0\")\n    \n    def test_exactly_max_size_success(self):\n        # Test a file of exactly 50MB (the maximum allowed size)\n        max_file_size = 50 * 1024 * 1024\n        data = b'A' * max_file_size\n        stream = io.BytesIO(data)\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            dest = os.path.join(tmp_dir, 'exact_max.bin')\n            result = process_file_upload(stream, dest)\n            self.assertIsNone(result, \"Function should return None on success\")\n            with open(dest, 'rb') as f:\n                content = f.read()\n            self.assertEqual(len(content), max_file_size, \"File size should be exactly 50MB\")\n    \n    def test_exceed_size_limit(self):\n        # Test a file that exceeds the 50MB limit by 1 byte\n        max_file_size = 50 * 1024 * 1024\n        data = b'A' * (max_file_size + 1)\n        stream = io.BytesIO(data)\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            dest = os.path.join(tmp_dir, 'too_large.bin')\n            result = process_file_upload(stream, dest)\n            self.assertIsInstance(result, Exception, \"Should return an Exception on size violation\")\n            self.assertIn(\"Uploaded file exceeds size limit\", str(result), \"Error message should indicate size limit exceeded\")\n    \n    def test_invalid_destination(self):\n        # Test writing to a non-existent directory (should cause an IOError)\n        data = b\"Test data\"\n        stream = io.BytesIO(data)\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            # Create a path that includes a non-existent subdirectory\n            dest = os.path.join(tmp_dir, 'non_existent_dir', 'test.txt')\n            result = process_file_upload(stream, dest)\n            self.assertIsInstance(result, Exception, \"Should return an Exception on IOError\")\n            self.assertIn(\"Error\", str(result), \"Error message should be present\")\n    \n    def test_chunked_reading(self):\n        # Test reading data in multiple chunks\n        chunk1 = b'abcd' * 256  # 1024 bytes\n        chunk2 = b'xyz' * 100   # 300 bytes\n        total_data = chunk1 + chunk2\n        \n        class CustomStream:\n            def __init__(self, chunks):\n                self.chunks = chunks\n                self.index = 0\n            \n            def read(self, size):\n                if self.index >= len(self.chunks):\n                    return b''\n                chunk = self.chunks[self.index]\n                self.index += 1\n                return chunk\n                \n        stream = CustomStream([chunk1, chunk2])\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            dest = os.path.join(tmp_dir, 'chunked.txt')\n            result = process_file_upload(stream, dest)\n            self.assertIsNone(result, \"Function should return None on success\")\n            with open(dest, 'rb') as f:\n                content = f.read()\n            self.assertEqual(content, total_data, \"File content should match all chunks\")\n    \n    def test_invalid_stream_object(self):\n        # Test passing a non-stream object (should cause an AttributeError)\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            dest = os.path.join(tmp_dir, 'test.txt')\n            # Pass None which doesn't have a read method\n            result = process_file_upload(None, dest)\n            self.assertIsInstance(result, Exception, \"Should return an Exception on invalid stream\")\n            self.assertIn(\"Error\", str(result), \"Error message should be present\")", "num_test_cases": 7, "task_id": "ded072da"}
{"test": "import unittest\nimport io\nimport tempfile\nimport os\n\n# Define the global constant FILE_CHUNK_SIZE used by the function\nFILE_CHUNK_SIZE = 1024  # 1 KB\n# Define MAX_FILE_SIZE to match the function's internal constant (50 MB)\nMAX_FILE_SIZE = 50 * 1024 * 1024\n\nclass TestSaveUserFile(unittest.TestCase):\n\n    def test_small_file(self):\n        # Test saving a small file within the size limit\n        content = b'Hello, World!'\n        stream = io.BytesIO(content)\n        with tempfile.TemporaryDirectory() as temp_dir:\n            path = os.path.join(temp_dir, 'test.txt')\n            result = save_user_file(stream, path)\n            self.assertIsNone(result, 'Should return None on success')\n            with open(path, 'rb') as f:\n                self.assertEqual(f.read(), content, 'File content should match input')\n\n    def test_empty_file(self):\n        # Test saving an empty file\n        stream = io.BytesIO(b'')\n        with tempfile.TemporaryDirectory() as temp_dir:\n            path = os.path.join(temp_dir, 'test.txt')\n            result = save_user_file(stream, path)\n            self.assertIsNone(result, 'Should return None for empty file')\n            with open(path, 'rb') as f:\n                self.assertEqual(f.read(), b'', 'File should be empty')\n\n    def test_exact_max_size(self):\n        # Test saving a file exactly at the 50 MB limit\n        content = b'0' * MAX_FILE_SIZE\n        stream = io.BytesIO(content)\n        with tempfile.TemporaryDirectory() as temp_dir:\n            path = os.path.join(temp_dir, 'test.txt')\n            result = save_user_file(stream, path)\n            self.assertIsNone(result, 'Should return None for exact size')\n            with open(path, 'rb') as f:\n                self.assertEqual(len(f.read()), MAX_FILE_SIZE, 'File size should be 50 MB')\n\n    def test_exceed_max_size(self):\n        # Test exceeding the 50 MB limit by one byte\n        content = b'0' * (MAX_FILE_SIZE + 1)\n        stream = io.BytesIO(content)\n        with tempfile.TemporaryDirectory() as temp_dir:\n            path = os.path.join(temp_dir, 'test.txt')\n            result = save_user_file(stream, path)\n            self.assertIsInstance(result, Exception, 'Should return Exception for oversized file')\n            self.assertIn('Uploaded file exceeds size limit', str(result))\n            with open(path, 'rb') as f:\n                self.assertEqual(len(f.read()), MAX_FILE_SIZE, 'File should be truncated to 50 MB')\n\n    def test_io_error_directory_path(self):\n        # Test IOError when saving to a directory path\n        content = b'Test content'\n        stream = io.BytesIO(content)\n        with tempfile.TemporaryDirectory() as temp_dir:\n            result = save_user_file(stream, temp_dir)\n            self.assertIsInstance(result, Exception, 'Should return Exception for IOError')\n            self.assertIn('Error:', str(result))\n\n    def test_multiple_chunks(self):\n        # Test processing multiple chunks within size limit\n        chunk_size = FILE_CHUNK_SIZE\n        content = b'X' * (3 * chunk_size)  # 3 chunks\n        stream = io.BytesIO(content)\n        with tempfile.TemporaryDirectory() as temp_dir:\n            path = os.path.join(temp_dir, 'test.txt')\n            result = save_user_file(stream, path)\n            self.assertIsNone(result, 'Should return None for multiple chunks')\n            with open(path, 'rb') as f:\n                self.assertEqual(len(f.read()), len(content), 'File size should match content')\n\n    def test_stream_none(self):\n        # Test AttributeError when stream is None\n        with tempfile.TemporaryDirectory() as temp_dir:\n            path = os.path.join(temp_dir, 'test.txt')\n            result = save_user_file(None, path)\n            self.assertIsInstance(result, Exception, 'Should return Exception for None stream')\n\n    def test_path_none(self):\n        # Test TypeError when path is None\n        content = b'Test content'\n        stream = io.BytesIO(content)\n        result = save_user_file(stream, None)\n        self.assertIsInstance(result, Exception, 'Should return Exception for None path')\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 8, "task_id": "8c6f031c"}
{"test": "import unittest\\nimport tempfile\\nimport os\\nfrom io import BytesIO\\nfrom unittest.mock import patch, MagicMock\\n\\n# Define the global constant expected by the function\\nFILE_CHUNK_SIZE = 4096\\n\\n# Import the function from the module (assume the function is in a module named 'solution')\\nfrom solution import process_file_upload\\n\\nclass TestProcessFileUpload(unittest.TestCase):\\n\\n    def test_happy_path_small_file(self):\\n        # Test writing a small file successfully\\n        content = b'Hello, World!'\\n        stream = BytesIO(content)\\n        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\\n            destination = tmp_file.name\\n        result = process_file_upload(stream, destination)\\n        self.assertIsNone(result)\\n        with open(destination, 'rb') as f:\\n            written_content = f.read()\\n        self.assertEqual(written_content, content)\\n        os.unlink(destination)\\n\\n    def test_empty_file(self):\\n        # Test writing an empty file\\n        stream = BytesIO(b'')\\n        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\\n            destination = tmp_file.name\\n        result = process_file_upload(stream, destination)\\n        self.assertIsNone(result)\\n        with open(destination, 'rb') as f:\\n            written_content = f.read()\\n        self.assertEqual(written_content, b'')\\n        os.unlink(destination)\\n\\n    def test_exactly_50MB(self):\\n        # Test file size exactly at the 50MB limit\\n        max_size = 50 * 1024 * 1024\\n        content = b'A' * max_size\\n        stream = BytesIO(content)\\n        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\\n            destination = tmp_file.name\\n        result = process_file_upload(stream, destination)\\n        self.assertIsNone(result)\\n        self.assertEqual(os.path.getsize(destination), max_size)\\n        os.unlink(destination)\\n\\n    def test_exceeding_50MB_by_one_byte(self):\\n        # Test file exceeding 50MB limit by one byte\\n        max_size = 50 * 1024 * 1024\\n        class CustomStream:\\n            def __init__(self, chunks):\\n                self.chunks = chunks\\n                self.index = 0\\n            def read(self, size):\\n                if self.index < len(self.chunks):\\n                    chunk = self.chunks[self.index]\\n                    self.index += 1\\n                    return chunk\\n                return b''\\n        chunks = [b'A' * max_size, b'B']\\n        stream = CustomStream(chunks)\\n        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\\n            destination = tmp_file.name\\n        result = process_file_upload(stream, destination)\\n        self.assertIsNotNone(result)\\n        self.assertIsInstance(result, Exception)\\n        self.assertIn('Uploaded file exceeds size limit', str(result))\\n        with open(destination, 'rb') as f:\\n            content = f.read()\\n        self.assertEqual(len(content), max_size + 1)\\n        self.assertEqual(content, b'A' * max_size + b'B')\\n        os.unlink(destination)\\n\\n    def test_io_error_on_write(self):\\n        # Test IOError during file write\\n        with patch('builtins.open', side_effect=IOError('Disk error')):\\n            stream = BytesIO(b'Hello')\\n            destination = 'some/path'\\n            result = process_file_upload(stream, destination)\\n            self.assertIsNotNone(result)\\n            self.assertIsInstance(result, Exception)\\n            self.assertIn('Disk error', str(result))\\n\\n    def test_stream_raises_error_on_read(self):\\n        # Test error during stream read\\n        class FaultyStream:\\n            def read(self, size):\\n                raise IOError('Read error')\\n        stream = FaultyStream()\\n        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\\n            destination = tmp_file.name\\n        result = process_file_upload(stream, destination)\\n        self.assertIsNotNone(result)\\n        self.assertIsInstance(result, Exception)\\n        self.assertIn('Read error', str(result))\\n        os.unlink(destination)\\n\\n    def test_destination_is_directory(self):\\n        # Test writing to a directory path\\n        with tempfile.TemporaryDirectory() as tmp_dir:\\n            stream = BytesIO(b'Hello')\\n            result = process_file_upload(stream, tmp_dir)\\n            self.assertIsNotNone(result)\\n            self.assertIsInstance(result, Exception)\\n\\n    def test_multiple_chunks_non_default_size(self):\\n        # Test with varying chunk sizes\\n        global FILE_CHUNK_SIZE\\n        original_chunk_size = FILE_CHUNK_SIZE\\n        FILE_CHUNK_SIZE = 1024  # Smaller chunk size\\n        content = b'A' * (FILE_CHUNK_SIZE * 2 + 100)  # Two full chunks + 100 bytes\\n        stream = BytesIO(content)\\n        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\\n            destination = tmp_file.name\\n        result = process_file_upload(stream, destination)\\n        self.assertIsNone(result)\\n        with open(destination, 'rb') as f:\\n            written_content = f.read()\\n        self.assertEqual(written_content, content)\\n        os.unlink(destination)\\n        FILE_CHUNK_SIZE = original_chunk_size\\n\\nif __name__ == '__main__':\\n    unittest.main()", "num_test_cases": 8, "task_id": "26a2364a"}
{"test": "import unittest\nfrom unittest.mock import patch, mock_open, MagicMock\n\n# Import the function to be tested\nfrom solution import save_uploaded_file\n\nclass TestSaveUploadedFile(unittest.TestCase):\n    \n    @patch('solution.FILE_CHUNK_SIZE', 1024)  # Set chunk size for test\n    def test_normal_single_chunk(self):\n        \"\"\"Test saving a file within size limit in one chunk.\"\"\"\n        mock_stream = MagicMock()\n        mock_stream.read.side_effect = [b'Hello, World!', b'']\n        \n        with patch('builtins.open', mock_open()) as mock_file:\n            result = save_uploaded_file(mock_stream, 'test_path.txt')\n            \n            # Verify no error and proper writes\n            self.assertIsNone(result)\n            mock_file().write.assert_called_once_with(b'Hello, World!')\n    \n    @patch('solution.FILE_CHUNK_SIZE', 1024)\n    def test_normal_multiple_chunks(self):\n        \"\"\"Test saving a file within size limit with multiple chunks.\"\"\"\n        chunks = [b'Chunk1', b'Chunk2', b'Chunk3', b'']\n        mock_stream = MagicMock()\n        mock_stream.read.side_effect = chunks\n        \n        with patch('builtins.open', mock_open()) as mock_file:\n            result = save_uploaded_file(mock_stream, 'multi_path.txt')\n            \n            self.assertIsNone(result)\n            # Verify all chunks were written\n            expected_calls = [call(b'Chunk1'), call(b'Chunk2'), call(b'Chunk3')]\n            mock_file().write.assert_has_calls(expected_calls)\n    \n    @patch('solution.FILE_CHUNK_SIZE', 1024)\n    def test_empty_file(self):\n        \"\"\"Test saving an empty file.\"\"\"\n        mock_stream = MagicMock()\n        mock_stream.read.side_effect = [b'']\n        \n        with patch('builtins.open', mock_open()) as mock_file:\n            result = save_uploaded_file(mock_stream, 'empty.txt')\n            \n            self.assertIsNone(result)\n            mock_file().write.assert_not_called()  # No data written\n    \n    @patch('solution.FILE_CHUNK_SIZE', 1024)\n    def test_exact_size_limit(self):\n        \"\"\"Test file size exactly at the limit (edge case).\"\"\"\n        MAX_SIZE = 50 * 1024 * 1024  # 50 MB\n        # Create chunks: last chunk makes total exactly MAX_SIZE\n        chunk1 = b'a' * (MAX_SIZE - 1024)\n        chunk2 = b'b' * 1024\n        mock_stream = MagicMock()\n        mock_stream.read.side_effect = [chunk1, chunk2, b'']\n        \n        with patch('builtins.open', mock_open()) as mock_file:\n            result = save_uploaded_file(mock_stream, 'exact.txt')\n            \n            self.assertIsNone(result)\n            # Verify both chunks written\n            expected_calls = [call(chunk1), call(chunk2)]\n            mock_file().write.assert_has_calls(expected_calls)\n    \n    @patch('solution.FILE_CHUNK_SIZE', 1024)\n    def test_exceed_size_limit(self):\n        \"\"\"Test file exceeding size limit by one byte.\"\"\"\n        MAX_SIZE = 50 * 1024 * 1024  # 50 MB\n        chunk1 = b'x' * MAX_SIZE  # Exactly at limit\n        chunk2 = b'y'  # One byte over\n        mock_stream = MagicMock()\n        mock_stream.read.side_effect = [chunk1, chunk2, b'']\n        \n        with patch('builtins.open', mock_open()) as mock_file:\n            result = save_uploaded_file(mock_stream, 'exceed.txt')\n            \n            # Verify partial write and exception\n            self.assertIsInstance(result, Exception)\n            self.assertIn('exceeds size limit', str(result))\n            mock_file().write.assert_called_once_with(chunk1)  # Only first chunk written\n    \n    @patch('solution.FILE_CHUNK_SIZE', 1024)\n    def test_read_error(self):\n        \"\"\"Test error during reading from file stream.\"\"\"\n        mock_stream = MagicMock()\n        mock_stream.read.side_effect = IOError('Read failure')\n        \n        result = save_uploaded_file(mock_stream, 'read_error.txt')\n        \n        self.assertIsInstance(result, Exception)\n        self.assertIn('Read failure', str(result))\n    \n    @patch('solution.FILE_CHUNK_SIZE', 1024)\n    def test_write_error(self):\n        \"\"\"Test error during writing to output file.\"\"\"\n        mock_stream = MagicMock()\n        mock_stream.read.side_effect = [b'Test data', b'']\n        \n        # Mock open to raise IOError on write\n        m = mock_open()\n        m.return_value.write.side_effect = IOError('Write failure')\n        \n        with patch('builtins.open', m):\n            result = save_uploaded_file(mock_stream, 'write_error.txt')\n            \n            self.assertIsInstance(result, Exception)\n            self.assertIn('Write failure', str(result))\n    \n    @patch('solution.FILE_CHUNK_SIZE', 1024)\n    def test_unexpected_exception(self):\n        \"\"\"Test any other unexpected exception during processing.\"\"\"\n        mock_stream = MagicMock()\n        mock_stream.read.side_effect = Exception('Generic error')\n        \n        result = save_uploaded_file(mock_stream, 'unexpected.txt')\n        \n        self.assertIsInstance(result, Exception)\n        self.assertIn('Generic error', str(result))\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 8, "task_id": "76c82e4e"}
{"test": "import unittest\nimport tempfile\nimport io\nimport os\nfrom unittest.mock import patch, MagicMock\n\n# Define the global constant used in the function\nFILE_CHUNK_SIZE = 4096\n\nclass TestFileUpload(unittest.TestCase):\n\n    def test_small_file(self):\n        \"\"\"Test writing a small file within the size limit.\"\"\"\n        data = b'Hello, World!'\n        stream = io.BytesIO(data)\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            output_path = os.path.join(tmp_dir, 'test.txt')\n            result = upload_user_file(stream, output_path)\n            self.assertIsNone(result)\n            with open(output_path, 'rb') as f:\n                content = f.read()\n            self.assertEqual(content, data)\n\n    def test_empty_file(self):\n        \"\"\"Test writing an empty file.\"\"\"\n        data = b''\n        stream = io.BytesIO(data)\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            output_path = os.path.join(tmp_dir, 'test.txt')\n            result = upload_user_file(stream, output_path)\n            self.assertIsNone(result)\n            with open(output_path, 'rb') as f:\n                content = f.read()\n            self.assertEqual(content, data)\n\n    def test_exact_max_size(self):\n        \"\"\"Test writing a file exactly at the 50 MB size limit.\"\"\"\n        file_size = 50 * 1024 * 1024  # 50 MB\n        data = b'A' * file_size\n        stream = io.BytesIO(data)\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            output_path = os.path.join(tmp_dir, 'test.txt')\n            result = upload_user_file(stream, output_path)\n            self.assertIsNone(result)\n            self.assertEqual(os.path.getsize(output_path), file_size)\n\n    def test_exceed_max_size(self):\n        \"\"\"Test file exceeding 50 MB limit by one byte.\"\"\"\n        file_size = 50 * 1024 * 1024 + 1\n        data = b'A' * file_size\n        stream = io.BytesIO(data)\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            output_path = os.path.join(tmp_dir, 'test.txt')\n            result = upload_user_file(stream, output_path)\n            self.assertIsInstance(result, Exception)\n            self.assertEqual(str(result), 'Error: Uploaded file exceeds size limit')\n            self.assertEqual(os.path.getsize(output_path), 50 * 1024 * 1024)\n\n    def test_invalid_output_path(self):\n        \"\"\"Test writing to a non-existent directory path.\"\"\"\n        data = b'Hello'\n        stream = io.BytesIO(data)\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            output_path = os.path.join(tmp_dir, 'non_existent', 'test.txt')\n            result = upload_user_file(stream, output_path)\n            self.assertIsInstance(result, Exception)\n            self.assertTrue(str(result).startswith('Error: '))\n\n    def test_read_error(self):\n        \"\"\"Simulate an IOError during reading from the stream.\"\"\"\n        stream = MagicMock()\n        stream.read.side_effect = IOError('Simulated read error')\n        with tempfile.TemporaryDirectory() as tmp_dir:\n            output_path = os.path.join(tmp_dir, 'test.txt')\n            result = upload_user_file(stream, output_path)\n            self.assertIsInstance(result, Exception)\n            self.assertEqual(str(result), 'Error: Simulated read error')\n\n    def test_write_error(self):\n        \"\"\"Simulate an IOError during writing to the file.\"\"\"\n        with patch('builtins.open') as mock_open:\n            mock_file = mock_open.return_value.__enter__.return_value\n            mock_file.write.side_effect = IOError('Simulated write error')\n            stream = io.BytesIO(b'data')\n            output_path = '/some/path'\n            result = upload_user_file(stream, output_path)\n            self.assertIsInstance(result, Exception)\n            self.assertEqual(str(result), 'Error: Simulated write error')\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 7, "task_id": "403ceee3"}
{"test": "import unittest\n\nMB = 1024 * 1024  # 1 MB\nMAX_SIZE = 100 * MB  # 100 MB\n\nclass MockStream:\n    \"\"\"A mock stream class to simulate reading data in chunks.\"\"\"\n    def __init__(self, chunks):\n        self.chunks = iter(chunks)\n    \n    def read(self, size):\n        \"\"\"Read the next chunk from the predefined chunks.\"\"\"\n        try:\n            return next(self.chunks)\n        except StopIteration:\n            return b''\n\nclass TestHandleStreamData(unittest.TestCase):\n\n    def test_empty_stream(self):\n        \"\"\"Test processing an empty stream returns success.\"\"\"\n        stream = MockStream([])\n        result = handle_stream_data(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_small_stream(self):\n        \"\"\"Test processing a small stream (10 bytes) returns success.\"\"\"\n        stream = MockStream([b'1234567890'])\n        result = handle_stream_data(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_under_limit(self):\n        \"\"\"Test processing 99 MB does not raise an error.\"\"\"\n        chunk = b'x' * (99 * MB)\n        stream = MockStream([chunk])\n        result = handle_stream_data(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_exact_limit_multiple_chunks(self):\n        \"\"\"Test processing exactly 100 MB in multiple chunks returns success.\"\"\"\n        chunk1 = b'x' * (50 * MB)\n        chunk2 = b'x' * (50 * MB)\n        stream = MockStream([chunk1, chunk2])\n        result = handle_stream_data(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_one_chunk_exceeding(self):\n        \"\"\"Test processing a single chunk exceeding 100 MB raises MemoryError.\"\"\"\n        chunk = b'x' * (MAX_SIZE + 1)\n        stream = MockStream([chunk])\n        with self.assertRaises(MemoryError) as context:\n            handle_stream_data(stream)\n        self.assertEqual(str(context.exception), \"Data stream exceeds maximum allowed size.\")\n\n    def test_multiple_chunks_exceeding(self):\n        \"\"\"Test processing multiple chunks totaling over 100 MB raises MemoryError.\"\"\"\n        chunks = [b'x' * (10 * MB)] * 10  # 100 MB\n        chunks.append(b'x')  # 1 extra byte\n        stream = MockStream(chunks)\n        with self.assertRaises(MemoryError) as context:\n            handle_stream_data(stream)\n        self.assertEqual(str(context.exception), \"Data stream exceeds maximum allowed size.\")\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 6, "task_id": "23036b4d"}
{"test": "import unittest\n\n# Define BUFFER_SIZE as a constant as per the task context\nBUFFER_SIZE = 1024  # 1 KB chunk size\n\n# Mock classes for simulating the binary stream\nclass MockBinaryStream:\n    \"\"\"Simulates a stream of binary data for testing.\"\"\"\n    def __init__(self, data):\n        self.data = data\n        self.offset = 0\n        \n    def read(self, size):\n        if self.offset >= len(self.data):\n            return b''\n        end = self.offset + size\n        chunk = self.data[self.offset:end]\n        self.offset = end\n        return chunk\n\nclass FaultyMockBinaryStream:\n    \"\"\"Simulates a stream that raises an IOError on read.\"\"\"\n    def read(self, size):\n        raise IOError(\"Simulated IO error\")\n\nclass TestProcessStreamChunks(unittest.TestCase):\n    \n    def test_empty_stream(self):\n        \"\"\"Test processing an empty stream.\"\"\"\n        stream = MockBinaryStream(b'')\n        result = process_stream_chunks(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_small_stream(self):\n        \"\"\"Test a small stream within one chunk.\"\"\"\n        stream = MockBinaryStream(b'x' * 100)  # 100 bytes\n        result = process_stream_chunks(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_multiple_chunks_under_limit(self):\n        \"\"\"Test multiple chunks that stay under the 100 MB limit.\"\"\"\n        data = b'x' * (300 * 1024)  # 300 KB\n        stream = MockBinaryStream(data)\n        result = process_stream_chunks(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_exactly_at_limit(self):\n        \"\"\"Test a stream exactly at the 100 MB limit.\"\"\"\n        data = b'x' * (100 * 1024 * 1024)  # Exactly 100 MB\n        stream = MockBinaryStream(data)\n        result = process_stream_chunks(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_one_byte_over_limit(self):\n        \"\"\"Test a stream that exceeds the limit by one byte.\"\"\"\n        data = b'x' * (100 * 1024 * 1024 + 1)  # 100 MB + 1 byte\n        stream = MockBinaryStream(data)\n        result = process_stream_chunks(stream)\n        self.assertIsInstance(result, Exception)\n        self.assertEqual(str(result), \"Error: Data stream exceeds maximum allowed size.\")\n    \n    def test_large_stream_exceeding_limit(self):\n        \"\"\"Test a large stream (200 MB) that exceeds the limit.\"\"\"\n        data = b'x' * (200 * 1024 * 1024)  # 200 MB\n        stream = MockBinaryStream(data)\n        result = process_stream_chunks(stream)\n        self.assertIsInstance(result, Exception)\n        self.assertEqual(str(result), \"Error: Data stream exceeds maximum allowed size.\")\n    \n    def test_stream_with_io_error(self):\n        \"\"\"Test a stream that raises an IOError during read.\"\"\"\n        stream = FaultyMockBinaryStream()\n        result = process_stream_chunks(stream)\n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Unexpected Error: Simulated IO error\", str(result))\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 7, "task_id": "8015c625"}
{"test": "import unittest\n\n# Define BUFFER_SIZE for the function to use\nBUFFER_SIZE = 1024 * 1024  # 1 MB\n\n# Define constants for sizes\nKB = 1024\nMB = 1024 * KB\nMAX_DATA_SIZE = 100 * MB  # Maximum allowed data size (100 MB)\n\nclass MockStream:\n    def __init__(self, total_size):\n        self.total_size = total_size\n        self.remaining = total_size\n    \n    def read(self, size):\n        if self.remaining <= 0:\n            return b''\n        read_size = min(size, self.remaining)\n        self.remaining -= read_size\n        return b'\\0' * read_size\n\nclass TestStreamProcessor(unittest.TestCase):\n    def test_empty_stream(self):\n        # Test with an empty stream (0 bytes)\n        stream = MockStream(0)\n        result = stream_processor(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_small_stream(self):\n        # Test with a small stream (1 byte)\n        stream = MockStream(1)\n        result = stream_processor(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_medium_stream(self):\n        # Test with a medium-sized stream (50 MB)\n        stream = MockStream(50 * MB)\n        result = stream_processor(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_exact_max_size(self):\n        # Test with a stream exactly at the maximum allowed size (100 MB)\n        stream = MockStream(100 * MB)\n        result = stream_processor(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_exceed_max_size(self):\n        # Test with a stream exceeding the maximum allowed size by 1 byte\n        stream = MockStream(100 * MB + 1)\n        with self.assertRaises(MemoryError) as context:\n            stream_processor(stream)\n        self.assertEqual(str(context.exception), \"Data stream exceeds maximum allowed size.\")\n\n    def test_invalid_input_type(self):\n        # Test with invalid input (non-stream-like object)\n        with self.assertRaises(AttributeError):\n            stream_processor(123)\n\n    def test_large_chunk_boundary(self):\n        # Test with a stream that is 99 MB + 1 byte to check boundary condition\n        stream = MockStream(99 * MB + 1)\n        result = stream_processor(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_last_chunk_exceeds(self):\n        # Test where the last chunk pushes cumulative size over the limit\n        # First 100 MB in chunks, then 1 extra byte in the next chunk\n        stream = MockStream(100 * MB + 1)\n        with self.assertRaises(MemoryError) as context:\n            stream_processor(stream)\n        self.assertEqual(str(context.exception), \"Data stream exceeds maximum allowed size.\")\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 8, "task_id": "e1f9c7ac"}
{"test": "import unittest\nfrom io import BytesIO\n\n# Assuming the function is in a module named 'solution'\nimport solution\n\nclass TestDataStreamHandling(unittest.TestCase):\n    def setUp(self):\n        # Save original BUFFER_SIZE to restore in tearDown\n        self.original_buffer_size = solution.BUFFER_SIZE\n    \n    def tearDown(self):\n        # Restore original BUFFER_SIZE\n        solution.BUFFER_SIZE = self.original_buffer_size\n    \n    def test_empty_stream(self):\n        \"\"\"Test processing an empty stream.\"\"\"\n        solution.BUFFER_SIZE = 1024\n        stream = BytesIO(b'')\n        result = solution.handle_data_stream(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_small_stream(self):\n        \"\"\"Test a stream smaller than one buffer and under the limit.\"\"\"\n        solution.BUFFER_SIZE = 1024\n        data = b'X' * 500  # 500 bytes < 1 buffer\n        stream = BytesIO(data)\n        result = solution.handle_data_stream(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_exactly_one_buffer(self):\n        \"\"\"Test a stream of exactly one buffer size.\"\"\"\n        solution.BUFFER_SIZE = 1024\n        data = b'Y' * 1024  # Exactly one buffer\n        stream = BytesIO(data)\n        result = solution.handle_data_stream(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_multiple_buffers_under_limit(self):\n        \"\"\"Test multiple buffers that are under the 100 MB limit.\"\"\"\n        solution.BUFFER_SIZE = 1024 * 1024  # 1MB buffers\n        # Total: 50 MB (under 100 MB)\n        data = b'Z' * (50 * 1024 * 1024)\n        stream = BytesIO(data)\n        result = solution.handle_data_stream(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_exactly_max_limit(self):\n        \"\"\"Test a stream that exactly reaches the 100 MB limit.\"\"\"\n        solution.BUFFER_SIZE = 1024  # 1KB buffers\n        max_size = 100 * 1024 * 1024  # 100 MB\n        data = b'A' * max_size\n        stream = BytesIO(data)\n        result = solution.handle_data_stream(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_one_byte_over_limit(self):\n        \"\"\"Test a stream that exceeds the limit by one byte.\"\"\"\n        solution.BUFFER_SIZE = 1024  # 1KB buffers\n        max_size = 100 * 1024 * 1024  # 100 MB\n        data = b'B' * (max_size + 1)\n        stream = BytesIO(data)\n        with self.assertRaises(MemoryError) as context:\n            solution.handle_data_stream(stream)\n        self.assertEqual(str(context.exception), \"Data stream exceeds maximum allowed size.\")\n    \n    def test_large_chunk_over_limit(self):\n        \"\"\"Test a single chunk that alone exceeds the 100 MB limit.\"\"\"\n        solution.BUFFER_SIZE = 150 * 1024 * 1024  # 150MB buffer size\n        # Data is 150MB (over the 100MB limit)\n        data = b'C' * (150 * 1024 * 1024)\n        stream = BytesIO(data)\n        with self.assertRaises(MemoryError) as context:\n            solution.handle_data_stream(stream)\n        self.assertEqual(str(context.exception), \"Data stream exceeds maximum allowed size.\")\n    \n    def test_accumulated_chunks_over_limit(self):\n        \"\"\"Test multiple chunks that together exceed the limit in the middle of processing.\"\"\"\n        solution.BUFFER_SIZE = 50 * 1024 * 1024  # 50MB buffers\n        chunk1 = b'D' * (50 * 1024 * 1024)  # 50MB\n        chunk2 = b'E' * (50 * 1024 * 1024 + 1)  # 50MB + 1 byte (total 100MB + 1)\n        data = chunk1 + chunk2\n        stream = BytesIO(data)\n        with self.assertRaises(MemoryError) as context:\n            solution.handle_data_stream(stream)\n        self.assertEqual(str(context.exception), \"Data stream exceeds maximum allowed size.\")\n    \n    def test_non_ascii_data(self):\n        \"\"\"Test processing non-ASCII binary data.\"\"\"\n        solution.BUFFER_SIZE = 1024\n        data = b'\\x00\\xFF\\xAA\\x55' * 256  # 1024 bytes\n        stream = BytesIO(data)\n        result = solution.handle_data_stream(stream)\n        self.assertEqual(result, \"Processing complete\")\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 9, "task_id": "9e0df4fa"}
{"test": "import unittest\nimport io\n\nBUFFER_SIZE = 4096\n\nclass GeneratedStream:\n    def __init__(self, total_size):\n        self.total_size = total_size\n        self.remaining = total_size\n    \n    def read(self, size=-1):\n        if size < 0:\n            size = self.remaining\n        to_read = min(self.remaining, size)\n        if to_read == 0:\n            return b''\n        data = b'x' * to_read\n        self.remaining -= to_read\n        return data\n\nclass FaultyStream:\n    def read(self, size=-1):\n        raise IOError(\"Simulated I/O error\")\n\nclass TestMonitorDataStream(unittest.TestCase):\n    def test_empty_stream(self):\n        \"\"\"Test processing an empty data stream.\"\"\"\n        stream = GeneratedStream(0)\n        result = monitor_data_stream(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_small_stream(self):\n        \"\"\"Test processing a small stream within the limit.\"\"\"\n        stream = GeneratedStream(1024)\n        result = monitor_data_stream(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_exactly_max_limit(self):\n        \"\"\"Test processing data exactly at the maximum allowed size.\"\"\"\n        max_size = 100 * 1024 * 1024\n        stream = GeneratedStream(max_size)\n        result = monitor_data_stream(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_one_byte_over_limit(self):\n        \"\"\"Test exceeding the limit by one byte.\"\"\"\n        max_size = 100 * 1024 * 1024\n        stream = GeneratedStream(max_size + 1)\n        with self.assertRaises(MemoryError) as context:\n            monitor_data_stream(stream)\n        self.assertEqual(str(context.exception), \"Data stream exceeds maximum allowed size.\")\n\n    def test_significantly_over_limit(self):\n        \"\"\"Test processing a stream significantly over the limit.\"\"\"\n        max_size = 100 * 1024 * 1024\n        stream = GeneratedStream(max_size + BUFFER_SIZE)\n        with self.assertRaises(MemoryError):\n            monitor_data_stream(stream)\n\n    def test_large_but_under_limit(self):\n        \"\"\"Test a large stream just under the limit.\"\"\"\n        max_size = 100 * 1024 * 1024\n        stream = GeneratedStream(max_size - 1)\n        result = monitor_data_stream(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_stream_with_io_error(self):\n        \"\"\"Test handling of IO errors during read.\"\"\"\n        stream = FaultyStream()\n        with self.assertRaises(IOError):\n            monitor_data_stream(stream)\n\n    def test_chunk_boundary_exactly_at_max(self):\n        \"\"\"Test when a chunk boundary lands exactly at max limit.\"\"\"\n        max_size = 100 * 1024 * 1024\n        # Create a stream where last chunk is exactly the remaining bytes to reach max\n        stream = GeneratedStream(max_size)\n        result = monitor_data_stream(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_chunk_boundary_over_max(self):\n        \"\"\"Test when a chunk boundary exceeds max limit.\"\"\"\n        max_size = 100 * 1024 * 1024\n        # Create a stream where last chunk pushes total over max by 1 byte\n        stream = GeneratedStream(max_size + 1)\n        with self.assertRaises(MemoryError):\n            monitor_data_stream(stream)\n\n    def test_very_large_chunk(self):\n        \"\"\"Test a single chunk larger than the max limit.\"\"\"\n        max_size = 100 * 1024 * 1024\n        # Simulate a single chunk larger than max\n        stream = GeneratedStream(max_size + 1)\n        with self.assertRaises(MemoryError):\n            monitor_data_stream(stream)", "num_test_cases": 10, "task_id": "6a8f0b78"}
{"test": "import unittest\nfrom io import BytesIO\n\nBUFFER_SIZE = 1024  # 1KB buffer size for testing\n\nclass GeneratedStream:\n    \"\"\"Helper class to generate large streams with controlled data chunks.\"\"\"\n    def __init__(self, total_size):\n        self.total_size = total_size\n        self.remaining = total_size\n    \n    def read(self, size=-1):\n        if self.remaining <= 0:\n            return b''\n        if size == -1:\n            size = self.remaining\n        n = min(self.remaining, size)\n        self.remaining -= n\n        return b'a' * n\n\nclass FaultyStream:\n    \"\"\"Simulates a stream that raises an exception during read.\"\"\"\n    def read(self, size):\n        raise IOError(\"Simulated I/O error\")\n\nclass TestStreamDataHandler(unittest.TestCase):\n\n    def test_empty_stream(self):\n        \"\"\"Test handling of an empty stream.\"\"\"\n        stream = BytesIO(b'')\n        result = stream_data_handler(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_small_stream(self):\n        \"\"\"Test a small stream well below the 100MB limit.\"\"\"\n        data = b'a' * 100\n        stream = BytesIO(data)\n        result = stream_data_handler(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_exactly_100mb(self):\n        \"\"\"Test a stream of exactly 100MB (should complete successfully).\"\"\"\n        stream = GeneratedStream(100 * 1024 * 1024)  # 100MB\n        result = stream_data_handler(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_100mb_plus_one(self):\n        \"\"\"Test a stream exceeding the limit by one byte.\"\"\"\n        stream = GeneratedStream(100 * 1024 * 1024 + 1)  # 100MB + 1 byte\n        result = stream_data_handler(stream)\n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Data stream exceeds maximum allowed size\", str(result))\n\n    def test_large_stream_200mb(self):\n        \"\"\"Test a large stream (200MB) that exceeds the limit.\"\"\"\n        stream = GeneratedStream(200 * 1024 * 1024)  # 200MB\n        result = stream_data_handler(stream)\n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Data stream exceeds maximum allowed size\", str(result))\n\n    def test_faulty_stream(self):\n        \"\"\"Test a stream that raises an error during reading.\"\"\"\n        stream = FaultyStream()\n        result = stream_data_handler(stream)\n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Unexpected Error: Simulated I/O error\", str(result))\n\n    def test_one_byte_below_limit(self):\n        \"\"\"Test a stream one byte below the 100MB limit.\"\"\"\n        stream = GeneratedStream(100 * 1024 * 1024 - 1)  # 100MB - 1 byte\n        result = stream_data_handler(stream)\n        self.assertEqual(result, \"Processing complete\")\n", "num_test_cases": 7, "task_id": "c3aea611"}
{"test": "import unittest\nimport io\nimport sys\n\n# Define BUFFER_SIZE for the test environment\nBUFFER_SIZE = 1024 * 1024  # 1 MB\n\n# Mock stream classes for testing\nclass MockStream:\n    def __init__(self, data):\n        self.data = data\n        self.offset = 0\n\n    def read(self, size):\n        if self.offset >= len(self.data):\n            return b''\n        end = self.offset + size\n        chunk = self.data[self.offset:end]\n        self.offset = end\n        return chunk\n\nclass FaultyStream:\n    def read(self, size):\n        raise IOError(\"Simulated IO error\")\n\nclass NotAStream:\n    pass\n\nclass TestHandleStreamData(unittest.TestCase):\n\n    def test_empty_stream(self):\n        # Test processing an empty stream\n        stream = MockStream(b'')\n        result = handle_stream_data(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_small_stream(self):\n        # Test processing a small stream (10 bytes)\n        stream = MockStream(b'0123456789')\n        result = handle_stream_data(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_exact_size_limit(self):\n        # Test processing exactly 100 MB (limit boundary)\n        data = b'x' * (100 * 1024 * 1024)\n        stream = MockStream(data)\n        result = handle_stream_data(stream)\n        self.assertEqual(result, \"Processing complete\")\n\n    def test_exceed_size_limit_one_byte(self):\n        # Test exceeding limit by 1 byte\n        data = b'x' * (100 * 1024 * 1024 + 1)\n        stream = MockStream(data)\n        result = handle_stream_data(stream)\n        self.assertIsInstance(result, Exception)\n        self.assertEqual(str(result), \"Error: Data stream exceeds maximum allowed size.\")\n\n    def test_faulty_stream_io_error(self):\n        # Test stream that raises an IOError\n        stream = FaultyStream()\n        result = handle_stream_data(stream)\n        self.assertIsInstance(result, Exception)\n        self.assertTrue(str(result).startswith(\"Unexpected Error:\"))\n\n    def test_invalid_stream_object(self):\n        # Test invalid stream object without read method\n        stream = NotAStream()\n        result = handle_stream_data(stream)\n        self.assertIsInstance(result, Exception)\n        self.assertTrue(str(result).startswith(\"Unexpected Error:\"))\n\n    def test_large_chunk_exceeding_limit(self):\n        # Test a chunk that causes the total to exceed the limit\n        chunks = [b'x' * (99 * 1024 * 1024), b'x' * (2 * 1024 * 1024)]\n        \n        class ChunkedStream:\n            def __init__(self, chunks):\n                self.chunks = chunks\n                self.index = 0\n            \n            def read(self, size):\n                if self.index < len(self.chunks):\n                    chunk = self.chunks[self.index]\n                    self.index += 1\n                    return chunk\n                return b''\n        \n        stream = ChunkedStream(chunks)\n        result = handle_stream_data(stream)\n        self.assertIsInstance(result, Exception)\n        self.assertEqual(str(result), \"Error: Data stream exceeds maximum allowed size.\")\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 7, "task_id": "e25349fb"}
{"test": "import unittest\nimport io\n\n# Define the BUFFER_SIZE constant as required by the function\nBUFFER_SIZE = 4096\n\n# Custom stream class to simulate large data streams without excessive memory usage\nclass MockStream:\n    def __init__(self, total_size, chunk_size=BUFFER_SIZE):\n        self.total_size = total_size\n        self.chunk_size = chunk_size\n        self.remaining = total_size\n    \n    def read(self, size=-1):\n        if self.remaining <= 0:\n            return b''\n        if size == -1:\n            size = self.remaining\n        read_size = min(size, self.chunk_size, self.remaining)\n        chunk = b'\\x00' * read_size\n        self.remaining -= read_size\n        return chunk\n\nclass TestProcessStreamChunks(unittest.TestCase):\n    \n    def test_small_data(self):\n        # Test with a small amount of data (10 bytes)\n        data = b'x' * 10\n        stream = io.BytesIO(data)\n        result = process_stream_chunks(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_empty_data(self):\n        # Test with an empty stream\n        stream = io.BytesIO(b'')\n        result = process_stream_chunks(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_one_chunk(self):\n        # Test with one chunk of exactly BUFFER_SIZE\n        data = b'x' * BUFFER_SIZE\n        stream = io.BytesIO(data)\n        result = process_stream_chunks(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_two_chunks(self):\n        # Test with two chunks: first of BUFFER_SIZE, second of 1 byte\n        data = b'x' * (BUFFER_SIZE + 1)\n        stream = io.BytesIO(data)\n        result = process_stream_chunks(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_exactly_max(self):\n        # Test with exactly the maximum allowed data (100 MB)\n        max_size = 100 * 1024 * 1024\n        stream = MockStream(max_size)\n        result = process_stream_chunks(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_exceed_max(self):\n        # Test with data exceeding the maximum (100 MB + 1 byte)\n        max_size = 100 * 1024 * 1024 + 1\n        stream = MockStream(max_size)\n        with self.assertRaises(MemoryError) as context:\n            process_stream_chunks(stream)\n        self.assertEqual(str(context.exception), \"Data stream exceeds maximum allowed size.\")\n    \n    def test_exceed_in_middle(self):\n        # Test that exceeding the limit in the middle of the stream raises\n        first_chunk = 100 * 1024 * 1024 - 100\n        total_size = first_chunk + 101  # 100 MB + 1 byte\n        stream = MockStream(total_size, chunk_size=BUFFER_SIZE)\n        with self.assertRaises(MemoryError):\n            process_stream_chunks(stream)\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 7, "task_id": "e7eb298d"}
{"test": "import unittest\nfrom unittest.mock import patch\nimport io\n\n# Import the function from its module - assuming it's in 'solution'\nfrom solution import manage_data_chunks\n\n# Define the maximum allowed size (100 MB)\nMAX_SIZE = 100 * 1024 * 1024\n\n# Patch the BUFFER_SIZE for all tests\n@patch('solution.BUFFER_SIZE', 1024)\nclass TestCases(unittest.TestCase):\n    \n    def test_empty_stream(self):\n        # Test with an empty stream (0 bytes)\n        stream = io.BytesIO(b'')\n        result = manage_data_chunks(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_small_stream(self):\n        # Test with a small stream (50 MB) under the limit\n        data = b'x' * (50 * 1024 * 1024)\n        stream = io.BytesIO(data)\n        result = manage_data_chunks(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_exact_limit(self):\n        # Test with exactly the maximum allowed size (100 MB)\n        data = b'x' * MAX_SIZE\n        stream = io.BytesIO(data)\n        result = manage_data_chunks(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_one_byte_over(self):\n        # Test with 100 MB + 1 byte (exceeding limit by 1 byte)\n        data = b'x' * (MAX_SIZE + 1)\n        stream = io.BytesIO(data)\n        with self.assertRaises(MemoryError) as context:\n            manage_data_chunks(stream)\n        self.assertEqual(str(context.exception), \"Data stream exceeds maximum allowed size.\")\n    \n    def test_well_over_limit(self):\n        # Test with a stream significantly over the limit (101 MB)\n        data = b'x' * (101 * 1024 * 1024)\n        stream = io.BytesIO(data)\n        with self.assertRaises(MemoryError) as context:\n            manage_data_chunks(stream)\n        self.assertEqual(str(context.exception), \"Data stream exceeds maximum allowed size.\")\n    \n    def test_none_input(self):\n        # Test with None as input (invalid stream)\n        with self.assertRaises(AttributeError):\n            manage_data_chunks(None)\n    \n    def test_invalid_stream_type(self):\n        # Test with an integer instead of a stream object\n        with self.assertRaises(AttributeError):\n            manage_data_chunks(123)\n    \n    def test_large_chunk_stream(self):\n        # Test with a stream that has chunks exactly at buffer boundaries\n        # Total size = 100 MB (exactly at limit)\n        data = b'x' * MAX_SIZE\n        # Using a custom stream that returns 1024-byte chunks\n        class FixedChunkStream:\n            def __init__(self, data, chunk_size):\n                self.data = data\n                self.chunk_size = chunk_size\n                self.offset = 0\n            \n            def read(self, size=-1):\n                if self.offset >= len(self.data):\n                    return b''\n                end = self.offset + self.chunk_size\n                chunk = self.data[self.offset:end]\n                self.offset = end\n                return chunk\n                \n        stream = FixedChunkStream(data, 1024)\n        result = manage_data_chunks(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_chunk_exceeding_limit(self):\n        # Test where a single chunk pushes the total over the limit\n        # First chunk: 99 MB, second chunk: 2 MB (total 101 MB)\n        class ControlledStream:\n            def __init__(self):\n                self.chunks = [\n                    b'x' * (99 * 1024 * 1024),  # 99 MB\n                    b'x' * (2 * 1024 * 1024)    # 2 MB (total becomes 101 MB)\n                ]\n                self.index = 0\n            \n            def read(self, size=-1):\n                if self.index >= len(self.chunks):\n                    return b''\n                chunk = self.chunks[self.index]\n                self.index += 1\n                return chunk\n                \n        stream = ControlledStream()\n        with self.assertRaises(MemoryError) as context:\n            manage_data_chunks(stream)\n        self.assertEqual(str(context.exception), \"Data stream exceeds maximum allowed size.\")", "num_test_cases": 9, "task_id": "00d48ca1"}
{"test": "import unittest\nfrom unittest.mock import patch\nimport time\n\n# Global constants required by the function\nMAX_REQUESTS_PER_CLIENT = 3\nTIME_WINDOW = 60\n\nclass TestCases(unittest.TestCase):\n    \n    def test_first_request_accepted(self):\n        \"\"\"Test that the first request from a client is accepted.\"\"\"\n        tracker = {}\n        with patch('time.time', return_value=1000.0):\n            result = api_rate_control(\"client1\", tracker)\n            self.assertEqual(result, \"Request accepted\")\n            self.assertEqual(tracker[\"client1\"], (1, 1000.0))\n    \n    def test_requests_within_limit_accepted(self):\n        \"\"\"Test requests within the limit are accepted and tracker updated.\"\"\"\n        tracker = {\"client1\": (2, 1000.0)}\n        with patch('time.time', return_value=1030.0):\n            result = api_rate_control(\"client1\", tracker)\n            self.assertEqual(result, \"Request accepted\")\n            self.assertEqual(tracker[\"client1\"], (3, 1000.0))\n    \n    def test_limit_exceeded_denied(self):\n        \"\"\"Test request exceeding limit returns rate limit error.\"\"\"\n        tracker = {\"client1\": (3, 1000.0)}\n        with patch('time.time', return_value=1030.0):\n            result = api_rate_control(\"client1\", tracker)\n            self.assertEqual(result, \"Rate limit exceeded for client\")\n            self.assertEqual(tracker[\"client1\"], (3, 1000.0))\n    \n    def test_window_reset_accepts_request(self):\n        \"\"\"Test after time window reset, request is accepted.\"\"\"\n        tracker = {\"client1\": (3, 1000.0)}\n        with patch('time.time', return_value=1060.0):\n            result = api_rate_control(\"client1\", tracker)\n            self.assertEqual(result, \"Request accepted\")\n            self.assertEqual(tracker[\"client1\"], (1, 1060.0))\n    \n    def test_just_before_window_reset_denied(self):\n        \"\"\"Test just before window reset with max requests returns error.\"\"\"\n        tracker = {\"client1\": (3, 1000.0)}\n        with patch('time.time', return_value=1059.999):\n            result = api_rate_control(\"client1\", tracker)\n            self.assertEqual(result, \"Rate limit exceeded for client\")\n            self.assertEqual(tracker[\"client1\"], (3, 1000.0))\n    \n    def test_multiple_clients_independent(self):\n        \"\"\"Test multiple clients are tracked independently.\"\"\"\n        tracker = {}\n        with patch('time.time', return_value=1000.0):\n            result1 = api_rate_control(\"client1\", tracker)\n            result2 = api_rate_control(\"client2\", tracker)\n            self.assertEqual(result1, \"Request accepted\")\n            self.assertEqual(result2, \"Request accepted\")\n            self.assertEqual(tracker[\"client1\"], (1, 1000.0))\n            self.assertEqual(tracker[\"client2\"], (1, 1000.0))\n    \n    def test_non_dict_tracker_returns_exception(self):\n        \"\"\"Test passing a non-dictionary tracker returns an exception.\"\"\"\n        with patch('time.time', return_value=1000.0):\n            result = api_rate_control(\"client1\", 123)\n            self.assertIsInstance(result, Exception)\n            self.assertTrue(\"Error in processing request:\" in str(result))\n    \n    def test_none_tracker_returns_exception(self):\n        \"\"\"Test passing None as tracker returns an exception.\"\"\"\n        with patch('time.time', return_value=1000.0):\n            result = api_rate_control(\"client1\", None)\n            self.assertIsInstance(result, Exception)\n            self.assertTrue(\"Error in processing request:\" in str(result))\n    \n    def test_invalid_cid_type_handled(self):\n        \"\"\"Test non-string cid type is handled without crashing.\"\"\"\n        tracker = {}\n        with patch('time.time', return_value=1000.0):\n            result = api_rate_control(123, tracker)\n            self.assertNotIsInstance(result, Exception)\n            self.assertEqual(tracker[123], (1, 1000.0))", "num_test_cases": 9, "task_id": "060992fb"}
{"test": "import unittest\nfrom unittest.mock import patch\nimport solution\n\nsolution.MAX_REQUESTS_PER_CLIENT = 5\nsolution.TIME_WINDOW = 10\n\nclass TestClientRequestManager(unittest.TestCase):\n\n    @patch('solution.time')\n    def test_new_client(self, mock_time):\n        # Test new client initialization\n        mock_time.return_value = 1000.0\n        request_data = {}\n        result = solution.client_request_manager(\"client1\", request_data)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(request_data, {\"client1\": (1, 1000.0)})\n\n    @patch('solution.time')\n    def test_existing_client_within_window_and_under_limit(self, mock_time):\n        # Test existing client within time window under request limit\n        mock_time.return_value = 1005.0\n        request_data = {\"client1\": (1, 1000.0)}\n        result = solution.client_request_manager(\"client1\", request_data)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(request_data, {\"client1\": (2, 1000.0)})\n\n    @patch('solution.time')\n    def test_existing_client_at_limit_within_window(self, mock_time):\n        # Test client at request limit within time window\n        mock_time.return_value = 1005.0\n        request_data = {\"client1\": (5, 1000.0)}\n        result = solution.client_request_manager(\"client1\", request_data)\n        self.assertEqual(result, \"Rate limit exceeded for client\")\n        self.assertEqual(request_data, {\"client1\": (5, 1000.0)})\n\n    @patch('solution.time')\n    def test_existing_client_after_window(self, mock_time):\n        # Test client after time window should reset count\n        mock_time.return_value = 1015.0\n        request_data = {\"client1\": (5, 1000.0)}\n        result = solution.client_request_manager(\"client1\", request_data)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(request_data, {\"client1\": (1, 1015.0)})\n\n    @patch('solution.time')\n    def test_multiple_clients(self, mock_time):\n        # Test multiple clients are tracked independently\n        mock_time.return_value = 1000.0\n        request_data = {}\n        result1 = solution.client_request_manager(\"client1\", request_data)\n        self.assertEqual(result1, \"Request accepted\")\n        self.assertEqual(request_data.get(\"client1\"), (1, 1000.0))\n        result2 = solution.client_request_manager(\"client2\", request_data)\n        self.assertEqual(result2, \"Request accepted\")\n        self.assertEqual(request_data.get(\"client2\"), (1, 1000.0))\n        mock_time.return_value = 1005.0\n        result1_again = solution.client_request_manager(\"client1\", request_data)\n        self.assertEqual(result1_again, \"Request accepted\")\n        self.assertEqual(request_data.get(\"client1\"), (2, 1000.0))\n\n    def test_non_hashable_client_identifier(self):\n        # Test non-hashable client_identifier causes error\n        request_data = {}\n        result = solution.client_request_manager([1,2,3], request_data)\n        self.assertIn(\"Error in processing request: \", result)\n        self.assertIn(\"unhashable type: 'list'\", result)\n\n    @patch('solution.time')\n    def test_request_data_not_dict(self, mock_time):\n        # Test non-dictionary request_data causes error\n        mock_time.return_value = 1000.0\n        client_identifier = \"client1\"\n        request_data = \"not a dict\"\n        result = solution.client_request_manager(client_identifier, request_data)\n        self.assertIn(\"Error in processing request: \", result)\n        self.assertIn(\"not iterable\", result)\n\n    @patch('solution.time')\n    def test_client_identifier_empty_string(self, mock_time):\n        # Test empty string as client_identifier\n        mock_time.return_value = 1000.0\n        request_data = {}\n        result = solution.client_request_manager(\"\", request_data)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(request_data, {\"\": (1, 1000.0)})\n\n    @patch('solution.time')\n    def test_exactly_at_window_boundary(self, mock_time):\n        # Test exactly at time window boundary resets count\n        mock_time.return_value = 1010.0\n        request_data = {\"client1\": (5, 1000.0)}\n        result = solution.client_request_manager(\"client1\", request_data)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(request_data, {\"client1\": (1, 1010.0)})\n\n    @patch('solution.time')\n    def test_client_identifier_none(self, mock_time):\n        # Test None as client_identifier\n        mock_time.return_value = 1000.0\n        request_data = {}\n        result = solution.client_request_manager(None, request_data)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(request_data, {None: (1, 1000.0)})\n\n    @patch('solution.time')\n    def test_very_long_client_identifier(self, mock_time):\n        # Test very long client_identifier\n        mock_time.return_value = 1000.0\n        long_id = \"A\" * 10000\n        request_data = {}\n        result = solution.client_request_manager(long_id, request_data)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(request_data, {long_id: (1, 1000.0)})\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 11, "task_id": "8c0e7fb6"}
{"test": "import unittest\nfrom unittest.mock import patch\n\n# Set global constants used by the function\nMAX_REQUESTS_PER_CLIENT = 5\nTIME_WINDOW = 10\n\nclass TestManageClientRate(unittest.TestCase):\n    @patch('time.time')\n    def test_first_request(self, mock_time):\n        # Test initial request from a new client\n        mock_time.return_value = 0.0\n        request_log = {}\n        result = manage_client_rate(\"client1\", request_log)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(request_log[\"client1\"], (1, 0.0))\n    \n    @patch('time.time')\n    def test_second_request_within_window(self, mock_time):\n        # Test subsequent request within time window\n        mock_time.return_value = 0.0\n        request_log = {\"client1\": (1, 0.0)}\n        mock_time.return_value = 5.0\n        result = manage_client_rate(\"client1\", request_log)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(request_log[\"client1\"], (2, 0.0))\n    \n    @patch('time.time')\n    def test_request_after_window(self, mock_time):\n        # Test request after time window has passed\n        mock_time.return_value = 0.0\n        request_log = {\"client1\": (3, 0.0)}\n        mock_time.return_value = 10.0\n        result = manage_client_rate(\"client1\", request_log)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(request_log[\"client1\"], (1, 10.0))\n    \n    @patch('time.time')\n    def test_exactly_max_requests(self, mock_time):\n        # Test exactly MAX_REQUESTS_PER_CLIENT requests within window\n        mock_time.return_value = 0.0\n        request_log = {\"client1\": (4, 0.0)}\n        mock_time.return_value = 1.0\n        result = manage_client_rate(\"client1\", request_log)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(request_log[\"client1\"], (5, 0.0))\n    \n    @patch('time.time')\n    def test_exceed_max_requests(self, mock_time):\n        # Test exceeding MAX_REQUESTS_PER_CLIENT within window\n        mock_time.return_value = 0.0\n        request_log = {\"client1\": (5, 0.0)}\n        mock_time.return_value = 5.0\n        result = manage_client_rate(\"client1\", request_log)\n        self.assertEqual(result, \"Rate limit exceeded for client\")\n    \n    @patch('time.time')\n    def test_two_clients(self, mock_time):\n        # Test requests from two different clients\n        mock_time.return_value = 0.0\n        request_log = {}\n        manage_client_rate(\"client1\", request_log)\n        manage_client_rate(\"client2\", request_log)\n        self.assertEqual(request_log[\"client1\"], (1, 0.0))\n        self.assertEqual(request_log[\"client2\"], (1, 0.0))\n    \n    def test_invalid_request_log_none(self):\n        # Test None request_log (invalid input)\n        result = manage_client_rate(\"client1\", None)\n        self.assertIn(\"Error in processing request\", result)\n    \n    def test_invalid_request_log_list(self):\n        # Test non-dictionary request_log (invalid input)\n        result = manage_client_rate(\"client1\", [])\n        self.assertIn(\"Error in processing request\", result)\n    \n    @patch('time.time')\n    def test_boundary_window(self, mock_time):\n        # Test at exact boundary of time window\n        mock_time.return_value = 0.0\n        request_log = {\"client1\": (5, 0.0)}\n        mock_time.return_value = 10.0\n        result = manage_client_rate(\"client1\", request_log)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(request_log[\"client1\"], (1, 10.0))\n    \n    @patch('time.time')\n    def test_non_string_client_key(self, mock_time):\n        # Test non-string client_key (should be accepted if hashable)\n        mock_time.return_value = 0.0\n        request_log = {}\n        result = manage_client_rate(123, request_log)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertIn(123, request_log)\n        self.assertEqual(request_log[123], (1, 0.0))", "num_test_cases": 10, "task_id": "8d2d42aa"}
{"test": "import unittest\nfrom unittest.mock import patch\nimport solution\n\n# Set global constants for the tests\nsolution.MAX_REQUESTS_PER_CLIENT = 3\nsolution.TIME_WINDOW = 10\n\nfrom solution import limit_api_requests\n\nclass TestCases(unittest.TestCase):\n    def test_case_1(self):\n        # Test new user (string) -> accepted\n        tracker = {}\n        with patch('time.time') as mock_time:\n            mock_time.return_value = 100.0\n            result = limit_api_requests(\"user1\", tracker)\n            self.assertEqual(result, \"Request accepted\")\n            self.assertEqual(tracker, {\"user1\": (1, 100.0)})\n            \n    def test_case_2(self):\n        # Test existing user within window, under limit -> accepted\n        tracker = {\"user1\": (1, 100.0)}\n        with patch('time.time') as mock_time:\n            mock_time.return_value = 101.0\n            result = limit_api_requests(\"user1\", tracker)\n            self.assertEqual(result, \"Request accepted\")\n            self.assertEqual(tracker, {\"user1\": (2, 100.0)})\n            \n    def test_case_3(self):\n        # Test existing user within window, at limit -> returns rate limit exceeded\n        tracker = {\"user1\": (3, 100.0)}\n        with patch('time.time') as mock_time:\n            mock_time.return_value = 101.0\n            result = limit_api_requests(\"user1\", tracker)\n            self.assertEqual(result, \"Rate limit exceeded for client\")\n            self.assertEqual(tracker, {\"user1\": (3, 100.0)})\n            \n    def test_case_4(self):\n        # Test existing user after window -> reset and accepted\n        tracker = {\"user1\": (3, 100.0)}\n        with patch('time.time') as mock_time:\n            mock_time.return_value = 110.1\n            result = limit_api_requests(\"user1\", tracker)\n            self.assertEqual(result, \"Request accepted\")\n            self.assertEqual(tracker, {\"user1\": (1, 110.1)})\n            \n    def test_case_5(self):\n        # Test exactly at time window -> reset and accepted\n        tracker = {\"user1\": (3, 100.0)}\n        with patch('time.time') as mock_time:\n            mock_time.return_value = 110.0\n            result = limit_api_requests(\"user1\", tracker)\n            self.assertEqual(result, \"Request accepted\")\n            self.assertEqual(tracker, {\"user1\": (1, 110.0)})\n            \n    def test_case_6(self):\n        # Test just below time window -> rate limit exceeded\n        tracker = {\"user1\": (3, 100.0)}\n        with patch('time.time') as mock_time:\n            mock_time.return_value = 109.9\n            result = limit_api_requests(\"user1\", tracker)\n            self.assertEqual(result, \"Rate limit exceeded for client\")\n            self.assertEqual(tracker, {\"user1\": (3, 100.0)})\n            \n    def test_case_7(self):\n        # Test just above time window -> reset and accepted\n        tracker = {\"user1\": (3, 100.0)}\n        with patch('time.time') as mock_time:\n            mock_time.return_value = 110.1\n            result = limit_api_requests(\"user1\", tracker)\n            self.assertEqual(result, \"Request accepted\")\n            self.assertEqual(tracker, {\"user1\": (1, 110.1)})\n            \n    def test_case_8(self):\n        # Test multiple users: one over limit, one new\n        tracker = {\"user1\": (3, 100.0)}\n        with patch('time.time') as mock_time:\n            mock_time.return_value = 101.0\n            result1 = limit_api_requests(\"user1\", tracker)\n            self.assertEqual(result1, \"Rate limit exceeded for client\")\n            result2 = limit_api_requests(\"user2\", tracker)\n            self.assertEqual(result2, \"Request accepted\")\n            self.assertEqual(tracker, {\"user1\": (3, 100.0), \"user2\": (1, 101.0)})\n            \n    def test_case_9(self):\n        # Test non-string but hashable user_id (integer) -> accepted\n        tracker = {}\n        with patch('time.time') as mock_time:\n            mock_time.return_value = 100.0\n            result = limit_api_requests(123, tracker)\n            self.assertEqual(result, \"Request accepted\")\n            self.assertEqual(tracker, {123: (1, 100.0)})\n            \n    def test_case_10(self):\n        # Test non-string but hashable user_id (tuple) -> accepted\n        tracker = {}\n        with patch('time.time') as mock_time:\n            mock_time.return_value = 100.0\n            user_id = (1, \"a\")\n            result = limit_api_requests(user_id, tracker)\n            self.assertEqual(result, \"Request accepted\")\n            self.assertEqual(tracker, {user_id: (1, 100.0)})\n            \n    def test_case_11(self):\n        # Test unhashable user_id (list) -> returns an Exception object\n        tracker = {}\n        result = limit_api_requests([\"user1\"], tracker)\n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Error in processing request\", str(result))\n        \n    def test_case_12(self):\n        # Test tracker is None -> returns an Exception object\n        result = limit_api_requests(\"user1\", None)\n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Error in processing request\", str(result))\n        \n    def test_case_13(self):\n        # Test tracker is a non-dict (list) -> returns an Exception object\n        tracker = []\n        result = limit_api_requests(\"user1\", tracker)\n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Error in processing request\", str(result))\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 13, "task_id": "ddafcd6b"}
{"test": "import unittest\nfrom unittest.mock import patch\nimport time\nimport __main__\n\n# Set global constants in __main__ as required by the function\n__main__.MAX_REQUESTS_PER_CLIENT = 5\n__main__.TIME_WINDOW = 10.0\n\nclass TestClientRequestMonitoring(unittest.TestCase):\n\n    def test_first_request_accepted(self):\n        # Test first request for a new client is accepted and tracker initialized.\n        api_tracker = {}\n        with patch('time.time', return_value=1000.0):\n            result = monitor_client_requests(\"client1\", api_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(api_tracker[\"client1\"], (1, 1000.0))\n\n    def test_request_within_limit_accepted(self):\n        # Test subsequent request within limit and time window is accepted.\n        api_tracker = {\"client1\": (1, 1000.0)}\n        with patch('time.time', return_value=1005.0):\n            result = monitor_client_requests(\"client1\", api_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(api_tracker[\"client1\"], (2, 1000.0))\n\n    def test_request_exceeding_limit_rejected(self):\n        # Test request exceeding MAX_REQUESTS_PER_CLIENT in time window is rejected.\n        api_tracker = {\"client1\": (5, 1000.0)}\n        with patch('time.time', return_value=1005.0):\n            result = monitor_client_requests(\"client1\", api_tracker)\n        self.assertEqual(result, \"Rate limit exceeded for client\")\n        self.assertEqual(api_tracker[\"client1\"], (5, 1000.0))  # Count unchanged\n\n    def test_request_after_window_resets_counter(self):\n        # Test request after TIME_WINDOW resets the counter.\n        api_tracker = {\"client1\": (5, 1000.0)}\n        with patch('time.time', return_value=1010.1):  # Just over TIME_WINDOW\n            result = monitor_client_requests(\"client1\", api_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(api_tracker[\"client1\"], (1, 1010.1))\n\n    def test_two_clients_independent_tracking(self):\n        # Test two clients tracked independently, one exceeding limit.\n        api_tracker = {}\n        with patch('time.time', return_value=1000.0):\n            # Client1: 5 requests\n            for _ in range(5):\n                result = monitor_client_requests(\"client1\", api_tracker)\n                self.assertEqual(result, \"Request accepted\")\n            # Client2: 1 request\n            result = monitor_client_requests(\"client2\", api_tracker)\n            self.assertEqual(result, \"Request accepted\")\n            \n            # Client1: 6th request (exceeds limit)\n            result = monitor_client_requests(\"client1\", api_tracker)\n            self.assertEqual(result, \"Rate limit exceeded for client\")\n            # Client2: 2nd request\n            result = monitor_client_requests(\"client2\", api_tracker)\n            self.assertEqual(result, \"Request accepted\")\n        \n        self.assertEqual(api_tracker[\"client1\"], (5, 1000.0))\n        self.assertEqual(api_tracker[\"client2\"], (2, 1000.0))\n\n    def test_invalid_api_tracker_type(self):\n        # Test error when api_tracker is not a dictionary.\n        result = monitor_client_requests(\"client1\", \"not_a_dict\")\n        self.assertIn(\"Error in processing request:\", str(result))\n\n    def test_empty_account_id_accepted(self):\n        # Test empty string account_id is handled.\n        api_tracker = {}\n        with patch('time.time', return_value=1000.0):\n            result = monitor_client_requests(\"\", api_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(api_tracker[\"\"], (1, 1000.0))\n\n    def test_exact_time_window_reset(self):\n        # Test reset when current time exactly equals first_request_time + TIME_WINDOW.\n        api_tracker = {\"client1\": (5, 1000.0)}\n        with patch('time.time', return_value=1010.0):  # Exactly TIME_WINDOW later\n            result = monitor_client_requests(\"client1\", api_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(api_tracker[\"client1\"], (1, 1010.0))\n\n    def test_max_requests_then_reset_and_retry(self):\n        # Test client exceeding limit, then reset after window, then allowed again.\n        api_tracker = {\"client1\": (5, 1000.0)}\n        with patch('time.time', return_value=1005.0):\n            result = monitor_client_requests(\"client1\", api_tracker)\n            self.assertEqual(result, \"Rate limit exceeded for client\")\n        \n        with patch('time.time', return_value=1010.1):\n            result = monitor_client_requests(\"client1\", api_tracker)\n            self.assertEqual(result, \"Request accepted\")\n            self.assertEqual(api_tracker[\"client1\"], (1, 1010.1))\n\n    def test_non_string_account_id_accepted(self):\n        # Test integer account_id is handled (non-string but hashable).\n        api_tracker = {}\n        with patch('time.time', return_value=1000.0):\n            result = monitor_client_requests(12345, api_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(api_tracker[12345], (1, 1000.0))\n\n    def test_none_account_id_accepted(self):\n        # Test None account_id is handled.\n        api_tracker = {}\n        with patch('time.time', return_value=1000.0):\n            result = monitor_client_requests(None, api_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(api_tracker[None], (1, 1000.0))\n\n    def test_very_long_account_id_accepted(self):\n        # Test very long account_id string is handled.\n        api_tracker = {}\n        long_id = \"a\" * 1000\n        with patch('time.time', return_value=1000.0):\n            result = monitor_client_requests(long_id, api_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(api_tracker[long_id], (1, 1000.0))\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 12, "task_id": "32374d9e"}
{"test": "import unittest\nfrom unittest.mock import patch\n\n# Global constants for the test\nMAX_REQUESTS_PER_CLIENT = 3\nTIME_WINDOW = 10\n\nclass TestManageClientRateLimit(unittest.TestCase):\n\n    @patch('__main__.time')\n    def test_first_request(self, mock_time):\n        \"\"\"Test a new client's first request is accepted.\"\"\"\n        mock_time.return_value = 1000.0\n        req_tracker = {}\n        result = manage_client_rate_limit(\"client1\", req_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(req_tracker, {\"client1\": (1, 1000.0)})\n\n    @patch('__main__.time')\n    def test_requests_within_limit(self, mock_time):\n        \"\"\"Test multiple requests within the limit are accepted.\"\"\"\n        mock_time.return_value = 1000.0\n        req_tracker = {}\n        manage_client_rate_limit(\"client1\", req_tracker)  # First request\n        mock_time.return_value = 1005.0\n        result = manage_client_rate_limit(\"client1\", req_tracker)  # Second request\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(req_tracker[\"client1\"], (2, 1000.0))\n\n    @patch('__main__.time')\n    def test_max_requests_accepted(self, mock_time):\n        \"\"\"Test exactly the maximum requests are accepted.\"\"\"\n        mock_time.return_value = 1000.0\n        req_tracker = {}\n        for _ in range(MAX_REQUESTS_PER_CLIENT - 1):\n            manage_client_rate_limit(\"client1\", req_tracker)\n        mock_time.return_value = 1009.0\n        result = manage_client_rate_limit(\"client1\", req_tracker)  # Third request\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(req_tracker[\"client1\"], (3, 1000.0))\n\n    @patch('__main__.time')\n    def test_rate_limit_exceeded(self, mock_time):\n        \"\"\"Test exceeding the limit returns rate limit error.\"\"\"\n        mock_time.return_value = 1000.0\n        req_tracker = {}\n        for _ in range(MAX_REQUESTS_PER_CLIENT):\n            manage_client_rate_limit(\"client1\", req_tracker)\n        mock_time.return_value = 1009.0\n        result = manage_client_rate_limit(\"client1\", req_tracker)  # Fourth request\n        self.assertEqual(result, \"Rate limit exceeded for client\")\n\n    @patch('__main__.time')\n    def test_time_window_reset(self, mock_time):\n        \"\"\"Test count resets after time window expires.\"\"\"\n        mock_time.return_value = 1000.0\n        req_tracker = {}\n        for _ in range(MAX_REQUESTS_PER_CLIENT):\n            manage_client_rate_limit(\"client1\", req_tracker)\n        mock_time.return_value = 1000.0 + TIME_WINDOW + 1  # Exceed window\n        result = manage_client_rate_limit(\"client1\", req_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(req_tracker[\"client1\"], (1, 1000.0 + TIME_WINDOW + 1))\n\n    @patch('__main__.time')\n    def test_multiple_clients(self, mock_time):\n        \"\"\"Test independent tracking of multiple clients.\"\"\"\n        mock_time.return_value = 1000.0\n        req_tracker = {}\n        # Client1 makes MAX_REQUESTS_PER_CLIENT requests\n        for _ in range(MAX_REQUESTS_PER_CLIENT):\n            manage_client_rate_limit(\"client1\", req_tracker)\n        # Client2 makes one request\n        result = manage_client_rate_limit(\"client2\", req_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(req_tracker[\"client1\"], (3, 1000.0))\n        self.assertEqual(req_tracker[\"client2\"], (1, 1000.0))\n\n    @patch('__main__.time')\n    def test_empty_user_identifier(self, mock_time):\n        \"\"\"Test empty string as user_identifier is accepted.\"\"\"\n        mock_time.return_value = 1000.0\n        req_tracker = {}\n        result = manage_client_rate_limit(\"\", req_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(req_tracker[\"\"], (1, 1000.0))\n\n    def test_invalid_user_identifier_type(self):\n        \"\"\"Test non-string user_identifier returns error.\"\"\"\n        req_tracker = {}\n        result = manage_client_rate_limit(123, req_tracker)\n        self.assertTrue(result.startswith(\"Error in processing request:\"))\n\n    def test_invalid_req_tracker_type(self):\n        \"\"\"Test non-dictionary req_tracker returns error.\"\"\"\n        result = manage_client_rate_limit(\"client1\", \"invalid\")\n        self.assertTrue(result.startswith(\"Error in processing request:\"))\n\n    @patch('__main__.time')\n    def test_boundary_time_window(self, mock_time):\n        \"\"\"Test request at exact time window boundary.\"\"\"\n        mock_time.return_value = 1000.0\n        req_tracker = {}\n        manage_client_rate_limit(\"client1\", req_tracker)  # First request\n        # Last second of window\n        mock_time.return_value = 1000.0 + TIME_WINDOW - 0.1\n        result = manage_client_rate_limit(\"client1\", req_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(req_tracker[\"client1\"], (2, 1000.0))\n        # First second of new window\n        mock_time.return_value = 1000.0 + TIME_WINDOW\n        result = manage_client_rate_limit(\"client1\", req_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(req_tracker[\"client1\"], (1, 1000.0 + TIME_WINDOW))\n\n    @patch('__main__.time')\n    def test_large_number_of_clients(self, mock_time):\n        \"\"\"Test system handles many clients simultaneously.\"\"\"\n        mock_time.return_value = 1000.0\n        req_tracker = {}\n        num_clients = 1000\n        for i in range(num_clients):\n            client_id = f\"client_{i}\"\n            result = manage_client_rate_limit(client_id, req_tracker)\n            self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(len(req_tracker), num_clients)\n\n    @patch('__main__.time')\n    def test_request_after_long_inactivity(self, mock_time):\n        \"\"\"Test request after long inactivity period.\"\"\"\n        mock_time.return_value = 1000.0\n        req_tracker = {}\n        manage_client_rate_limit(\"client1\", req_tracker)\n        # Simulate long inactivity (100 times the time window)\n        mock_time.return_value = 1000.0 + TIME_WINDOW * 100\n        result = manage_client_rate_limit(\"client1\", req_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(req_tracker[\"client1\"], (1, 1000.0 + TIME_WINDOW * 100))\n", "num_test_cases": 12, "task_id": "ae522eb9"}
{"test": "import unittest\nfrom unittest.mock import patch\nimport solution\n\nclass TestEnforceApiRateCap(unittest.TestCase):\n    def setUp(self):\n        solution.MAX_REQUESTS_PER_CLIENT = 5\n        solution.TIME_WINDOW = 60\n\n    @patch('solution.time')\n    def test_first_request_acceptance(self, mock_time):\n        # Test first request for a new customer\n        mock_time.return_value = 100.0\n        api_tracker = {}\n        customer_id = \"client1\"\n        result = solution.enforce_api_rate_cap(customer_id, api_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(api_tracker, {customer_id: (1, 100.0)})\n\n    @patch('solution.time')\n    def test_requests_within_limit(self, mock_time):\n        # Test multiple requests within the allowed limit\n        mock_time.return_value = 100.0\n        api_tracker = {}\n        customer_id = \"client1\"\n        solution.enforce_api_rate_cap(customer_id, api_tracker)\n        for i in range(4):\n            mock_time.return_value = 100.0 + i * 10\n            result = solution.enforce_api_rate_cap(customer_id, api_tracker)\n            self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(api_tracker[customer_id], (5, 100.0))\n\n    @patch('solution.time')\n    def test_rate_limit_exceeded(self, mock_time):\n        # Test exceeding the request limit within the time window\n        mock_time.return_value = 100.0\n        api_tracker = {}\n        customer_id = \"client1\"\n        for _ in range(5):\n            solution.enforce_api_rate_cap(customer_id, api_tracker)\n        mock_time.return_value = 120.0\n        result = solution.enforce_api_rate_cap(customer_id, api_tracker)\n        self.assertEqual(result, \"Rate limit exceeded for client\")\n        self.assertEqual(api_tracker[customer_id], (5, 100.0))\n\n    @patch('solution.time')\n    def test_time_window_reset(self, mock_time):\n        # Test request after time window resets the counter\n        api_tracker = {\"client1\": (5, 100.0)}\n        customer_id = \"client1\"\n        mock_time.return_value = 161.0\n        result = solution.enforce_api_rate_cap(customer_id, api_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(api_tracker, {\"client1\": (1, 161.0)})\n\n    @patch('solution.time')\n    def test_multiple_clients_independent(self, mock_time):\n        # Test multiple clients have independent rate limits\n        mock_time.return_value = 100.0\n        api_tracker = {}\n        for _ in range(5):\n            solution.enforce_api_rate_cap(\"client1\", api_tracker)\n        solution.enforce_api_rate_cap(\"client2\", api_tracker)\n        self.assertEqual(api_tracker[\"client1\"], (5, 100.0))\n        self.assertEqual(api_tracker[\"client2\"], (1, 100.0))\n        \n        mock_time.return_value = 120.0\n        result1 = solution.enforce_api_rate_cap(\"client1\", api_tracker)\n        result2 = solution.enforce_api_rate_cap(\"client2\", api_tracker)\n        self.assertEqual(result1, \"Rate limit exceeded for client\")\n        self.assertEqual(result2, \"Request accepted\")\n        self.assertEqual(api_tracker[\"client2\"], (2, 100.0))\n\n    @patch('solution.time')\n    def test_exact_window_boundary(self, mock_time):\n        # Test request at exact time window boundary triggers reset\n        api_tracker = {\"client1\": (5, 100.0)}\n        customer_id = \"client1\"\n        mock_time.return_value = 160.0\n        result = solution.enforce_api_rate_cap(customer_id, api_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(api_tracker, {\"client1\": (1, 160.0)})\n\n    @patch('solution.time')\n    def test_empty_customer_id(self, mock_time):\n        # Test handling of empty customer_id\n        mock_time.return_value = 100.0\n        api_tracker = {}\n        customer_id = \"\"\n        result = solution.enforce_api_rate_cap(customer_id, api_tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(api_tracker, {\"\": (1, 100.0)})\n        \n        for i in range(4):\n            mock_time.return_value = 100.0 + (i+1)*10\n            solution.enforce_api_rate_cap(customer_id, api_tracker)\n        result = solution.enforce_api_rate_cap(customer_id, api_tracker)\n        self.assertEqual(result, \"Rate limit exceeded for client\")\n\n    @patch('solution.time')\n    def test_api_tracker_none(self, mock_time):\n        # Test handling of None api_tracker\n        mock_time.return_value = 100.0\n        customer_id = \"client1\"\n        api_tracker = None\n        result = solution.enforce_api_rate_cap(customer_id, api_tracker)\n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Error in processing request:\", str(result))\n\n    @patch('solution.time')\n    def test_api_tracker_non_dict(self, mock_time):\n        # Test non-dictionary api_tracker (integer)\n        mock_time.return_value = 100.0\n        customer_id = \"client1\"\n        api_tracker = 123\n        result = solution.enforce_api_rate_cap(customer_id, api_tracker)\n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Error in processing request:\", str(result))\n\n    @patch('solution.time')\n    def test_unhashable_customer_id(self, mock_time):\n        # Test unhashable customer_id (list)\n        mock_time.return_value = 100.0\n        customer_id = [1, 2, 3]\n        api_tracker = {}\n        result = solution.enforce_api_rate_cap(customer_id, api_tracker)\n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Error in processing request:\", str(result))", "num_test_cases": 10, "task_id": "60f6e29e"}
{"test": "import unittest\nfrom unittest.mock import patch\n\n# Global constants for the test\nMAX_REQUESTS_PER_CLIENT = 5\nTIME_WINDOW = 10\n\n# Note: The function 'check_api_throttle_limit' is assumed to be defined in the same module (__main__)\n# If defined elsewhere, adjust the patch target accordingly (e.g., 'module_name.time')\n\n@patch('__main__.time')\nclass TestCheckApiThrottleLimit(unittest.TestCase):\n\n    def test_first_request_accepted(self, mock_time):\n        # Test that a first request from a new user is accepted\n        mock_time.return_value = 0.0\n        tracker = {}\n        user_id = \"user1\"\n        result = check_api_throttle_limit(user_id, tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(tracker[user_id], (1, 0.0))\n\n    def test_multiple_requests_within_limit(self, mock_time):\n        # Test multiple requests within the limit in the same time window\n        mock_time.return_value = 0.0\n        tracker = {\"user1\": (3, 0.0)}  # Existing user with 3 requests\n        mock_time.return_value = 5.0  # Within TIME_WINDOW\n        result = check_api_throttle_limit(\"user1\", tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(tracker[\"user1\"], (4, 0.0))\n\n    def test_request_exceeding_limit_denied(self, mock_time):\n        # Test that a request exceeding the limit is denied\n        mock_time.return_value = 0.0\n        tracker = {\"user1\": (MAX_REQUESTS_PER_CLIENT, 0.0)}  # At limit\n        mock_time.return_value = 1.0  # Within TIME_WINDOW\n        result = check_api_throttle_limit(\"user1\", tracker)\n        self.assertEqual(result, \"Rate limit exceeded for client\")\n        self.assertEqual(tracker[\"user1\"], (MAX_REQUESTS_PER_CLIENT, 0.0))  # Tracker unchanged\n\n    def test_reset_after_time_window(self, mock_time):\n        # Test that the count resets after the time window expires\n        mock_time.return_value = 0.0\n        tracker = {\"user1\": (MAX_REQUESTS_PER_CLIENT, 0.0)}\n        mock_time.return_value = TIME_WINDOW + 1  # Outside TIME_WINDOW\n        result = check_api_throttle_limit(\"user1\", tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(tracker[\"user1\"], (1, TIME_WINDOW + 1))  # Reset count\n\n    def test_exactly_max_requests_accepted(self, mock_time):\n        # Test that exactly MAX_REQUESTS_PER_CLIENT requests are accepted\n        mock_time.return_value = 0.0\n        tracker = {}\n        user_id = \"user1\"\n        for i in range(MAX_REQUESTS_PER_CLIENT):\n            result = check_api_throttle_limit(user_id, tracker)\n            self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(tracker[user_id], (MAX_REQUESTS_PER_CLIENT, 0.0))\n\n    def test_boundary_time_window_resets(self, mock_time):\n        # Test reset at exact boundary of time window (current_time - first_request_time == TIME_WINDOW)\n        mock_time.return_value = 0.0\n        tracker = {\"user1\": (3, 0.0)}\n        mock_time.return_value = TIME_WINDOW  # Exactly TIME_WINDOW seconds later\n        result = check_api_throttle_limit(\"user1\", tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(tracker[\"user1\"], (1, TIME_WINDOW))  # Reset\n\n    def test_multiple_users_independent(self, mock_time):\n        # Test that users are tracked independently\n        mock_time.return_value = 0.0\n        tracker = {}\n        # User1 makes MAX_REQUESTS_PER_CLIENT requests\n        for _ in range(MAX_REQUESTS_PER_CLIENT):\n            check_api_throttle_limit(\"user1\", tracker)\n        # User2 makes one request\n        check_api_throttle_limit(\"user2\", tracker)\n        \n        mock_time.return_value = 1.0  # Within window\n        # User1 is over limit, User2 is under\n        result1 = check_api_throttle_limit(\"user1\", tracker)\n        result2 = check_api_throttle_limit(\"user2\", tracker)\n        self.assertEqual(result1, \"Rate limit exceeded for client\")\n        self.assertEqual(result2, \"Request accepted\")\n        self.assertEqual(tracker[\"user1\"], (MAX_REQUESTS_PER_CLIENT, 0.0))\n        self.assertEqual(tracker[\"user2\"], (2, 0.0))\n\n    def test_invalid_tracker_type(self, mock_time):\n        # Test error handling when tracker is not a dictionary\n        mock_time.return_value = 0.0\n        user_id = \"user1\"\n        tracker = None  # Invalid type\n        result = check_api_throttle_limit(user_id, tracker)\n        self.assertTrue(result.startswith(\"Error in processing request:\"))\n\n    def test_unhashable_user_id(self, mock_time):\n        # Test error handling for unhashable user_id (like a list)\n        mock_time.return_value = 0.0\n        user_id = [1, 2, 3]  # Unhashable\n        tracker = {}\n        result = check_api_throttle_limit(user_id, tracker)\n        self.assertTrue(result.startswith(\"Error in processing request:\"))\n\n    def test_none_user_id_accepted(self, mock_time):\n        # Test that None as user_id is hashable and handled\n        mock_time.return_value = 0.0\n        user_id = None\n        tracker = {}\n        result = check_api_throttle_limit(user_id, tracker)\n        self.assertEqual(result, \"Request accepted\")\n        self.assertEqual(tracker[None], (1, 0.0))\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 10, "task_id": "a728a350"}
{"test": "import unittest\nfrom unittest.mock import patch\nimport api_rate_limiter\nfrom api_rate_limiter import limit_api_usage\n\n@patch('api_rate_limiter.time')\nclass TestRateLimiting(unittest.TestCase):\n    def setUp(self):\n        # Backup original constants\n        self.orig_max = api_rate_limiter.MAX_REQUESTS_PER_CLIENT\n        self.orig_window = api_rate_limiter.TIME_WINDOW\n        # Set test-specific rate limiting values\n        api_rate_limiter.MAX_REQUESTS_PER_CLIENT = 3\n        api_rate_limiter.TIME_WINDOW = 10\n    \n    def tearDown(self):\n        # Restore original constants\n        api_rate_limiter.MAX_REQUESTS_PER_CLIENT = self.orig_max\n        api_rate_limiter.TIME_WINDOW = self.orig_window\n    \n    def test_first_request(self, mock_time):\n        # Test initial request is accepted\n        mock_time.return_value = 0\n        usage_log = {}\n        result = limit_api_usage('client1', usage_log)\n        self.assertEqual(result, \"Request accepted\")\n    \n    def test_second_request_within_window(self, mock_time):\n        # Test subsequent request within time window is accepted\n        mock_time.return_value = 0\n        usage_log = {}\n        limit_api_usage('client1', usage_log)  # First request\n        mock_time.return_value = 5\n        result = limit_api_usage('client1', usage_log)\n        self.assertEqual(result, \"Request accepted\")\n    \n    def test_exceeding_limit(self, mock_time):\n        # Test request exceeding limit is denied\n        mock_time.return_value = 0\n        usage_log = {}\n        for _ in range(3):\n            limit_api_usage('client1', usage_log)  # First 3 requests\n        result = limit_api_usage('client1', usage_log)  # Fourth request\n        self.assertEqual(result, \"Rate limit exceeded for client\")\n    \n    def test_reset_after_window(self, mock_time):\n        # Test count resets after time window expires\n        mock_time.return_value = 0\n        usage_log = {}\n        limit_api_usage('client1', usage_log)  # First request\n        mock_time.return_value = 11  # Beyond TIME_WINDOW\n        result = limit_api_usage('client1', usage_log)\n        self.assertEqual(result, \"Request accepted\")\n    \n    def test_two_accounts(self, mock_time):\n        # Test rate limits applied per account\n        mock_time.return_value = 0\n        usage_log = {}\n        for _ in range(3):\n            limit_api_usage('account1', usage_log)  # account1 at limit\n        result1 = limit_api_usage('account2', usage_log)  # account2 first request\n        result2 = limit_api_usage('account1', usage_log)  # account1 over limit\n        result3 = limit_api_usage('account2', usage_log)  # account2 second request\n        self.assertEqual(result1, \"Request accepted\")\n        self.assertEqual(result2, \"Rate limit exceeded for client\")\n        self.assertEqual(result3, \"Request accepted\")\n    \n    def test_empty_account_id(self, mock_time):\n        # Test empty string account_id is handled\n        mock_time.return_value = 0\n        usage_log = {}\n        result = limit_api_usage('', usage_log)\n        self.assertEqual(result, \"Request accepted\")\n    \n    def test_exactly_window(self, mock_time):\n        # Test count reset when time difference equals TIME_WINDOW\n        mock_time.return_value = 0\n        usage_log = {}\n        limit_api_usage('client1', usage_log)\n        mock_time.return_value = 10  # Exactly TIME_WINDOW\n        result = limit_api_usage('client1', usage_log)\n        self.assertEqual(result, \"Request accepted\")\n    \n    def test_just_below_window(self, mock_time):\n        # Test count increments when within TIME_WINDOW\n        mock_time.return_value = 0\n        usage_log = {}\n        limit_api_usage('client1', usage_log)\n        mock_time.return_value = 9.9  # Just below TIME_WINDOW\n        result = limit_api_usage('client1', usage_log)\n        self.assertEqual(result, \"Request accepted\")\n    \n    def test_just_above_window(self, mock_time):\n        # Test count resets just beyond TIME_WINDOW\n        mock_time.return_value = 0\n        usage_log = {}\n        limit_api_usage('client1', usage_log)\n        mock_time.return_value = 10.1  # Just above TIME_WINDOW\n        result = limit_api_usage('client1', usage_log)\n        self.assertEqual(result, \"Request accepted\")\n    \n    def test_invalid_usage_log_non_dict(self, mock_time):\n        # Test error when usage_log is not a dictionary\n        mock_time.return_value = 0\n        result = limit_api_usage('client1', None)\n        self.assertTrue(result.startswith(\"Error in processing request: \"))\n    \n    def test_invalid_usage_log_malformed_entry(self, mock_time):\n        # Test error when usage_log has malformed entry\n        mock_time.return_value = 0\n        usage_log = {'client1': (1, 2, 3)}  # Invalid tuple length\n        result = limit_api_usage('client1', usage_log)\n        self.assertTrue(result.startswith(\"Error in processing request: \"))\n    \n    def test_account_id_none(self, mock_time):\n        # Test None account_id is handled as hashable key\n        mock_time.return_value = 0\n        usage_log = {}\n        result = limit_api_usage(None, usage_log)\n        self.assertEqual(result, \"Request accepted\")\n\nif __name__ == \"__main__\":\n    unittest.main()", "num_test_cases": 12, "task_id": "2295c0f1"}
{"test": "import unittest\nimport io\n\n# Define the global FORM_CHUNK_SIZE that the function expects\nFORM_CHUNK_SIZE = 1024  # 1KB\n\n# Import the function to test - replace 'solution' with actual module name\nfrom solution import process_form_data\n\n\nclass TestProcessFormData(unittest.TestCase):\n\n    def test_small_binary_input(self):\n        \"\"\"Test with small binary input that fits in one chunk.\"\"\"\n        data = b\"Binary data \\x00\\x01\\x02\"\n        input_stream = io.BytesIO(data)\n        output_stream = io.BytesIO()\n        result = process_form_data(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(output_stream.getvalue(), data)\n\n    def test_small_text_input(self):\n        \"\"\"Test with text input (converted to bytes) in one chunk.\"\"\"\n        data = \"Text data\".encode('utf-8')\n        input_stream = io.BytesIO(data)\n        output_stream = io.BytesIO()\n        result = process_form_data(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(output_stream.getvalue(), data)\n\n    def test_multiple_chunks_under_limit(self):\n        \"\"\"Test with multiple chunks totaling under the 10MB limit.\"\"\"\n        data = b'A' * (3 * FORM_CHUNK_SIZE)\n        input_stream = io.BytesIO(data)\n        output_stream = io.BytesIO()\n        result = process_form_data(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(output_stream.getvalue(), data)\n\n    def test_input_at_max_limit(self):\n        \"\"\"Test with input exactly at the 10MB limit.\"\"\"\n        MAX_SIZE = 10 * 1024 * 1024  # 10MB\n        data = b'X' * MAX_SIZE\n        input_stream = io.BytesIO(data)\n        output_stream = io.BytesIO()\n        result = process_form_data(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(output_stream.getvalue(), data)\n\n    def test_input_exceeds_limit(self):\n        \"\"\"Test with input exceeding the 10MB limit by one byte.\"\"\"\n        MAX_SIZE = 10 * 1024 * 1024  # 10MB\n        data = b'Y' * (MAX_SIZE + 1)\n        input_stream = io.BytesIO(data)\n        output_stream = io.BytesIO()\n        result = process_form_data(input_stream, output_stream)\n        self.assertEqual(result, \"User input exceeds the allowable size\")\n        self.assertEqual(len(output_stream.getvalue()), MAX_SIZE)\n\n    def test_empty_input(self):\n        \"\"\"Test with empty input stream.\"\"\"\n        input_stream = io.BytesIO(b\"\")\n        output_stream = io.BytesIO()\n        result = process_form_data(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(output_stream.getvalue(), b\"\")\n\n    def test_general_exception_handling(self):\n        \"\"\"Test handling of general exceptions during read operation.\"\"\"\n        class FaultyStream(io.BytesIO):\n            def read(self, size):\n                raise IOError(\"Simulated I/O error\")\n                \n        input_stream = FaultyStream(b\"data\")\n        output_stream = io.BytesIO()\n        result = process_form_data(input_stream, output_stream)\n        self.assertTrue(result.startswith(\"Error processing input:\"))\n        self.assertIn(\"Simulated I/O error\", result)", "num_test_cases": 7, "task_id": "32dab65a"}
{"test": "import unittest\nimport io\nfrom unittest.mock import patch, Mock\nfrom solution import handle_web_data\n\nclass TestHandleWebData(unittest.TestCase):\n    def test_empty_input(self):\n        # Test with empty source stream\n        with patch('solution.FORM_CHUNK_SIZE', 1024):\n            source = io.BytesIO(b'')\n            target = io.BytesIO()\n            result = handle_web_data(source, target)\n            self.assertEqual(result, 'Input processed successfully')\n            self.assertEqual(target.getvalue(), b'')\n\n    def test_small_input(self):\n        # Test small input within one chunk\n        with patch('solution.FORM_CHUNK_SIZE', 1024):\n            data = b'a' * 500\n            source = io.BytesIO(data)\n            target = io.BytesIO()\n            result = handle_web_data(source, target)\n            self.assertEqual(result, 'Input processed successfully')\n            self.assertEqual(target.getvalue(), data)\n\n    def test_two_chunks(self):\n        # Test input spanning two chunks\n        with patch('solution.FORM_CHUNK_SIZE', 1024):\n            data = b'a' * 1024 + b'b' * 1024\n            source = io.BytesIO(data)\n            target = io.BytesIO()\n            result = handle_web_data(source, target)\n            self.assertEqual(result, 'Input processed successfully')\n            self.assertEqual(target.getvalue(), data)\n\n    def test_exceed_max_size(self):\n        # Test input exceeding 10MB limit\n        with patch('solution.FORM_CHUNK_SIZE', 1024):\n            max_size = 10 * 1024 * 1024  # 10MB\n            data = b'x' * (max_size + 1)\n            source = io.BytesIO(data)\n            target = io.BytesIO()\n            result = handle_web_data(source, target)\n            self.assertEqual(result, 'User input exceeds the allowable size')\n            self.assertEqual(len(target.getvalue()), max_size)\n\n    def test_exact_max_size(self):\n        # Test input exactly at 10MB limit\n        with patch('solution.FORM_CHUNK_SIZE', 1024):\n            max_size = 10 * 1024 * 1024  # 10MB\n            data = b'x' * max_size\n            source = io.BytesIO(data)\n            target = io.BytesIO()\n            result = handle_web_data(source, target)\n            self.assertEqual(result, 'Input processed successfully')\n            self.assertEqual(len(target.getvalue()), max_size)\n\n    def test_source_stream_exception(self):\n        # Test exception during read\n        with patch('solution.FORM_CHUNK_SIZE', 1024):\n            source = Mock()\n            source.read.side_effect = IOError('Simulated I/O error')\n            target = io.BytesIO()\n            result = handle_web_data(source, target)\n            self.assertIsInstance(result, Exception)\n            self.assertEqual(str(result), 'Error processing input: Simulated I/O error')\n\n    def test_non_uniform_data(self):\n        # Test non-uniform data with small chunk size\n        with patch('solution.FORM_CHUNK_SIZE', 100):\n            data = b'123abc' * 100  # 600 bytes\n            source = io.BytesIO(data)\n            target = io.BytesIO()\n            result = handle_web_data(source, target)\n            self.assertEqual(result, 'Input processed successfully')\n            self.assertEqual(target.getvalue(), data)\n", "num_test_cases": 7, "task_id": "26e66401"}
{"test": "import unittest\nimport io\n\n# Define FORM_CHUNK_SIZE as used in the function\nFORM_CHUNK_SIZE = 1024  # 1 KB\n\nclass TestManageFormSubmission(unittest.TestCase):\n\n    def test_small_data_within_limit(self):\n        \"\"\"Test processing small data within the 10 MB limit.\"\"\"\n        source = io.BytesIO(b\"Hello, World!\")\n        dest = io.BytesIO()\n        result = manage_form_submission(source, dest)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(dest.getvalue(), b\"Hello, World!\")\n\n    def test_exactly_10mb_data(self):\n        \"\"\"Test processing data exactly at the 10 MB limit.\"\"\"\n        data = b\"a\" * (10 * 1024 * 1024)  # Exactly 10 MB\n        source = io.BytesIO(data)\n        dest = io.BytesIO()\n        result = manage_form_submission(source, dest)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(dest.getvalue(), data)\n\n    def test_one_byte_over_10mb(self):\n        \"\"\"Test data exceeding the limit by 1 byte raises MemoryError.\"\"\"\n        data = b\"a\" * (10 * 1024 * 1024 + 1)  # 10 MB + 1 byte\n        source = io.BytesIO(data)\n        dest = io.BytesIO()\n        with self.assertRaises(MemoryError) as context:\n            manage_form_submission(source, dest)\n        self.assertEqual(str(context.exception), \"User input exceeds the allowable size\")\n        # Verify only the first 10 MB were written\n        self.assertEqual(len(dest.getvalue()), 10 * 1024 * 1024)\n\n    def test_multiple_chunks_exactly_10mb(self):\n        \"\"\"Test multiple chunks totaling exactly 10 MB.\"\"\"\n        chunk = b\"a\" * FORM_CHUNK_SIZE\n        num_chunks = (10 * 1024 * 1024) // FORM_CHUNK_SIZE  # 10240 chunks\n        data = chunk * num_chunks\n        self.assertEqual(len(data), 10 * 1024 * 1024)\n        source = io.BytesIO(data)\n        dest = io.BytesIO()\n        result = manage_form_submission(source, dest)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(dest.getvalue(), data)\n\n    def test_multiple_chunks_one_byte_over(self):\n        \"\"\"Test multiple chunks totaling 10 MB + 1 byte raises MemoryError.\"\"\"\n        chunk = b\"a\" * FORM_CHUNK_SIZE\n        num_chunks = (10 * 1024 * 1024) // FORM_CHUNK_SIZE  # 10240 chunks\n        data = chunk * num_chunks\n        data += b\"a\"  # Add one extra byte\n        source = io.BytesIO(data)\n        dest = io.BytesIO()\n        with self.assertRaises(MemoryError) as context:\n            manage_form_submission(source, dest)\n        self.assertEqual(str(context.exception), \"User input exceeds the allowable size\")\n        # Verify only the first 10 MB were written\n        self.assertEqual(len(dest.getvalue()), 10 * 1024 * 1024)\n\n    def test_empty_input(self):\n        \"\"\"Test processing an empty input stream.\"\"\"\n        source = io.BytesIO(b\"\")\n        dest = io.BytesIO()\n        result = manage_form_submission(source, dest)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(dest.getvalue(), b\"\")\n\n    def test_one_full_chunk(self):\n        \"\"\"Test processing exactly one full chunk of data.\"\"\"\n        data = b\"a\" * FORM_CHUNK_SIZE\n        source = io.BytesIO(data)\n        dest = io.BytesIO()\n        result = manage_form_submission(source, dest)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(dest.getvalue(), data)\n\n    def test_invalid_source(self):\n        \"\"\"Test invalid source stream (None) raises AttributeError.\"\"\"\n        dest = io.BytesIO()\n        with self.assertRaises(AttributeError):\n            manage_form_submission(None, dest)\n\n    def test_invalid_destination(self):\n        \"\"\"Test invalid destination stream (None) raises AttributeError during write.\"\"\"\n        source = io.BytesIO(b\"data\")\n        with self.assertRaises(AttributeError):\n            manage_form_submission(source, None)\n\n    def test_varying_chunk_sizes(self):\n        \"\"\"Test processing chunks of varying sizes within the limit.\"\"\"\n        data = b\"a\" * (FORM_CHUNK_SIZE * 10 + 500)  # 10 full chunks + 500 bytes\n        source = io.BytesIO(data)\n        dest = io.BytesIO()\n        result = manage_form_submission(source, dest)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(dest.getvalue(), data)\n\n    def test_last_chunk_causes_overflow(self):\n        \"\"\"Test that the chunk causing overflow is not written.\"\"\"\n        # Create data that is 10 MB - 512 bytes, then add a 513-byte chunk\n        base_data = b\"a\" * (10 * 1024 * 1024 - 512)\n        overflow_chunk = b\"b\" * 513\n        source = io.BytesIO(base_data + overflow_chunk)\n        dest = io.BytesIO()\n        with self.assertRaises(MemoryError):\n            manage_form_submission(source, dest)\n        # Only base_data should be written (10 MB - 512 bytes)\n        self.assertEqual(len(dest.getvalue()), 10 * 1024 * 1024 - 512)\n        self.assertTrue(dest.getvalue().endswith(b\"a\" * 512))\n        self.assertNotIn(b\"b\", dest.getvalue())", "num_test_cases": 11, "task_id": "c721b01c"}
{"test": "import io\nimport unittest\nfrom unittest.mock import patch\nimport solution\n\nsolution.FORM_CHUNK_SIZE = 4096  # 4KB\n\nfrom solution import handle_user_data\n\nMAX_SIZE = 10 * 1024 * 1024  # 10 MB\n\nclass TestHandleUserData(unittest.TestCase):\n\n    def test_small_input(self):\n        # Test with a small input that fits in one chunk.\n        input_data = b\"Hello, World!\"\n        input_stream = io.BytesIO(input_data)\n        output_stream = io.BytesIO()\n        result = handle_user_data(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(output_stream.getvalue(), input_data)\n\n    def test_multiple_chunks(self):\n        # Test with input that requires multiple chunks (3 chunks) and under 10 MB.\n        chunk = b\"A\" * 4096\n        input_data = chunk * 3\n        input_stream = io.BytesIO(input_data)\n        output_stream = io.BytesIO()\n        result = handle_user_data(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(output_stream.getvalue(), input_data)\n\n    def test_empty_input(self):\n        # Test with empty input.\n        input_stream = io.BytesIO(b\"\")\n        output_stream = io.BytesIO()\n        result = handle_user_data(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(output_stream.getvalue(), b\"\")\n\n    def test_exactly_10MB(self):\n        # Test with input exactly at the limit (10 MB).\n        input_data = b\"A\" * MAX_SIZE\n        input_stream = io.BytesIO(input_data)\n        output_stream = io.BytesIO()\n        result = handle_user_data(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(output_stream.getvalue(), input_data)\n\n    def test_10MB_plus_one_byte(self):\n        # Test with input exceeding the limit by one byte (using default chunk size).\n        input_data = b\"A\" * (MAX_SIZE + 1)\n        input_stream = io.BytesIO(input_data)\n        output_stream = io.BytesIO()\n        result = handle_user_data(input_stream, output_stream)\n        self.assertEqual(result, \"User input exceeds the allowable size\")\n        # The function should not write the last chunk that causes the overflow.\n        self.assertEqual(len(output_stream.getvalue()), MAX_SIZE)\n\n    def test_exception_during_read(self):\n        # Simulate an exception during reading.\n        class FaultyStream:\n            def read(self, size):\n                raise IOError(\"Simulated I/O error\")\n        input_stream = FaultyStream()\n        output_stream = io.BytesIO()\n        result = handle_user_data(input_stream, output_stream)\n        self.assertTrue(result.startswith(\"Error processing input: \"))\n\n    def test_non_aligned_chunk_size(self):\n        # Test with a different chunk size (1024) and input exactly at the limit.\n        input_data = b\"A\" * MAX_SIZE\n        input_stream = io.BytesIO(input_data)\n        output_stream = io.BytesIO()\n        with patch('solution.FORM_CHUNK_SIZE', 1024):\n            result = handle_user_data(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(output_stream.getvalue(), input_data)\n\n    def test_10MB_plus_one_byte_in_two_chunks(self):\n        # Test exceeding the limit in two chunks: first chunk exactly 10 MB, second chunk 1 byte.\n        input_data = b\"A\" * (MAX_SIZE + 1)\n        input_stream = io.BytesIO(input_data)\n        output_stream = io.BytesIO()\n        with patch('solution.FORM_CHUNK_SIZE', MAX_SIZE):\n            result = handle_user_data(input_stream, output_stream)\n        self.assertEqual(result, \"User input exceeds the allowable size\")\n        # The function should have written the first chunk (10 MB) and then encountered the error on the second.\n        self.assertEqual(len(output_stream.getvalue()), MAX_SIZE)\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 8, "task_id": "a4c1b092"}
{"test": "import unittest\nfrom io import BytesIO\nfrom unittest.mock import patch, Mock\n\n# Define the constant used by the function\nFORM_CHUNK_SIZE = 1024  # 1 KB\n\nclass TestProcessFormData(unittest.TestCase):\n\n    def test_normal_operation_small_data(self):\n        # Test with small valid input under the size limit\n        input_data = b'Hello, world!'\n        input_stream = BytesIO(input_data)\n        output_stream = BytesIO()\n        result = process_form_data(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(output_stream.getvalue(), input_data)\n\n    def test_empty_input(self):\n        # Test with empty input stream\n        input_stream = BytesIO(b'')\n        output_stream = BytesIO()\n        result = process_form_data(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(output_stream.getvalue(), b'')\n\n    def test_exact_size_limit(self):\n        # Test input exactly at the 10 MB limit\n        input_data = b'x' * (10 * 1024 * 1024)\n        input_stream = BytesIO(input_data)\n        output_stream = BytesIO()\n        result = process_form_data(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(output_stream.getvalue(), input_data)\n\n    def test_exceeds_by_one_byte(self):\n        # Test input exceeding limit by 1 byte\n        input_data = b'x' * (10 * 1024 * 1024 + 1)\n        input_stream = BytesIO(input_data)\n        output_stream = BytesIO()\n        result = process_form_data(input_stream, output_stream)\n        self.assertEqual(result, \"User input exceeds the allowable size\")\n        self.assertEqual(len(output_stream.getvalue()), 10 * 1024 * 1024)\n\n    def test_large_exceed_limit(self):\n        # Test large input well over the 10 MB limit\n        input_data = b'x' * (11 * 1024 * 1024)\n        input_stream = BytesIO(input_data)\n        output_stream = BytesIO()\n        result = process_form_data(input_stream, output_stream)\n        self.assertEqual(result, \"User input exceeds the allowable size\")\n        self.assertEqual(len(output_stream.getvalue()), 10 * 1024 * 1024)\n\n    def test_read_error(self):\n        # Test exception during read operation\n        input_stream = Mock()\n        input_stream.read.side_effect = [b'valid chunk', IOError(\"Read error\")]\n        output_stream = BytesIO()\n        result = process_form_data(input_stream, output_stream)\n        self.assertTrue(result.startswith(\"Error processing input: \"))\n        self.assertIn(\"Read error\", result)\n        self.assertEqual(output_stream.getvalue(), b'valid chunk')\n\n    def test_write_error(self):\n        # Test exception during write operation\n        input_stream = Mock()\n        input_stream.read.side_effect = [b'first chunk', b'second chunk']\n        output_stream = Mock()\n        output_stream.write.side_effect = [None, IOError(\"Write error\")]\n        result = process_form_data(input_stream, output_stream)\n        self.assertTrue(result.startswith(\"Error processing input: \"))\n        self.assertIn(\"Write error\", result)\n        self.assertEqual(output_stream.write.call_count, 2)\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 7, "task_id": "6ca74d53"}
{"test": "import io\nimport unittest\nimport solution\n\nsolution.FORM_CHUNK_SIZE = 4096\n\nclass TestManageUserInput(unittest.TestCase):\n    def test_small_input(self):\n        # Test with small input under the limit\n        input_data = b\"Hello, World!\"\n        input_stream = io.BytesIO(input_data)\n        output_stream = io.BytesIO()\n        result = solution.manage_user_input(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(output_stream.getvalue(), input_data)\n\n    def test_empty_input(self):\n        # Test with empty input\n        input_data = b\"\"\n        input_stream = io.BytesIO(input_data)\n        output_stream = io.BytesIO()\n        result = solution.manage_user_input(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(output_stream.getvalue(), input_data)\n\n    def test_exactly_10mb(self):\n        # Test with input exactly at the 10MB limit\n        input_data = b\"A\" * (10 * 1024 * 1024)\n        input_stream = io.BytesIO(input_data)\n        output_stream = io.BytesIO()\n        result = solution.manage_user_input(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(output_stream.getvalue(), input_data)\n\n    def test_exceeds_10mb(self):\n        # Test with input exceeding 10MB by one byte\n        input_data = b\"A\" * (10 * 1024 * 1024 + 1)\n        input_stream = io.BytesIO(input_data)\n        output_stream = io.BytesIO()\n        with self.assertRaises(MemoryError) as context:\n            solution.manage_user_input(input_stream, output_stream)\n        self.assertEqual(str(context.exception), \"User input exceeds the allowable size\")\n        self.assertEqual(len(output_stream.getvalue()), 10 * 1024 * 1024)\n\n    def test_chunk_boundary_exceed(self):\n        # Test chunk boundary where last read causes limit exceed\n        data_part = b\"A\" * (10 * 1024 * 1024 - 2048)\n        excess_data = b\"B\" * 2049  # Total becomes 10MB + 1\n        input_data = data_part + excess_data\n        input_stream = io.BytesIO(input_data)\n        output_stream = io.BytesIO()\n        with self.assertRaises(MemoryError):\n            solution.manage_user_input(input_stream, output_stream)\n        self.assertEqual(output_stream.getvalue(), data_part)\n", "num_test_cases": 5, "task_id": "ae37d7b9"}
{"test": "import unittest\nimport io\n\n# Define the constant FORM_CHUNK_SIZE as used in the function\nFORM_CHUNK_SIZE = 1024  # 1 KB\n\nclass TestHandleUserData(unittest.TestCase):\n    \n    def test_small_input(self):\n        # Test processing a small input within the memory limit (single chunk)\n        data = b'Hello, World!'\n        data_stream = io.BytesIO(data)\n        result_stream = io.BytesIO()\n        ret = handle_user_data(data_stream, result_stream)\n        self.assertEqual(ret, \"Input processed successfully\")\n        self.assertEqual(result_stream.getvalue(), data)\n    \n    def test_multiple_chunks_within_limit(self):\n        # Test processing input in multiple chunks within memory limit (5 MB)\n        data = b'a' * (5 * 1024 * 1024)  # 5 MB\n        data_stream = io.BytesIO(data)\n        result_stream = io.BytesIO()\n        ret = handle_user_data(data_stream, result_stream)\n        self.assertEqual(ret, \"Input processed successfully\")\n        self.assertEqual(result_stream.getvalue(), data)\n    \n    def test_exactly_max_size(self):\n        # Test input exactly at the 10 MB memory limit\n        data = b'a' * (10 * 1024 * 1024)  # Exactly 10 MB\n        data_stream = io.BytesIO(data)\n        result_stream = io.BytesIO()\n        ret = handle_user_data(data_stream, result_stream)\n        self.assertEqual(ret, \"Input processed successfully\")\n        self.assertEqual(result_stream.getvalue(), data)\n    \n    def test_exceed_max_size(self):\n        # Test input exceeding 10 MB limit by 1 byte\n        data = b'a' * (10 * 1024 * 1024 + 1)  # 10 MB + 1 byte\n        data_stream = io.BytesIO(data)\n        result_stream = io.BytesIO()\n        ret = handle_user_data(data_stream, result_stream)\n        self.assertEqual(ret, \"User input exceeds the allowable size\")\n        # Verify only the first 10 MB was written before error\n        self.assertEqual(len(result_stream.getvalue()), 10 * 1024 * 1024)\n    \n    def test_empty_input(self):\n        # Test processing an empty input stream\n        data = b''\n        data_stream = io.BytesIO(data)\n        result_stream = io.BytesIO()\n        ret = handle_user_data(data_stream, result_stream)\n        self.assertEqual(ret, \"Input processed successfully\")\n        self.assertEqual(result_stream.getvalue(), data)\n    \n    def test_read_error(self):\n        # Test error during read operation\n        class FaultyStream:\n            def read(self, size):\n                raise IOError(\"Simulated read error\")\n        data_stream = FaultyStream()\n        result_stream = io.BytesIO()\n        ret = handle_user_data(data_stream, result_stream)\n        self.assertIsInstance(ret, Exception)\n        self.assertEqual(str(ret), \"Error processing input: Simulated read error\")\n    \n    def test_write_error(self):\n        # Test error during write operation (fails on second chunk)\n        data = b'a' * 1024 + b'b' * 1024  # Two chunks\n        data_stream = io.BytesIO(data)\n        \n        class FaultyWriteStream:\n            def __init__(self):\n                self.write_count = 0\n            def write(self, chunk):\n                self.write_count += 1\n                if self.write_count == 2:\n                    raise IOError(\"Simulated write error\")\n        \n        result_stream = FaultyWriteStream()\n        ret = handle_user_data(data_stream, result_stream)\n        self.assertIsInstance(ret, Exception)\n        self.assertEqual(str(ret), \"Error processing input: Simulated write error\")", "num_test_cases": 7, "task_id": "928a39f2"}
{"test": "import unittest\nimport io\n\n# We assume FORM_CHUNK_SIZE is defined as 1024 in the module where process_form_data resides\n# For testing, we'll create test data based on this assumption\nFORM_CHUNK_SIZE = 1024\n\nclass TestProcessFormData(unittest.TestCase):\n\n    def test_small_data_within_one_chunk(self):\n        \"\"\"Test processing data smaller than one chunk and under 10MB limit.\"\"\"\n        data = b'x' * 500  # 500 bytes\n        form_stream = io.BytesIO(data)\n        storage_stream = io.BytesIO()\n        \n        result = process_form_data(form_stream, storage_stream)\n        \n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(storage_stream.getvalue(), data)\n\n    def test_data_multiple_chunks_within_limit(self):\n        \"\"\"Test processing data spanning multiple chunks under 10MB limit.\"\"\"\n        data = b'x' * (2 * FORM_CHUNK_SIZE + 512)  # 2.5 chunks (2560 bytes)\n        form_stream = io.BytesIO(data)\n        storage_stream = io.BytesIO()\n        \n        result = process_form_data(form_stream, storage_stream)\n        \n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(storage_stream.getvalue(), data)\n\n    def test_exact_size_limit(self):\n        \"\"\"Test processing data exactly at 10MB limit.\"\"\"\n        data = b'x' * (10 * 1024 * 1024)  # Exactly 10MB\n        form_stream = io.BytesIO(data)\n        storage_stream = io.BytesIO()\n        \n        result = process_form_data(form_stream, storage_stream)\n        \n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(storage_stream.getvalue(), data)\n\n    def test_exceed_size_by_one_byte(self):\n        \"\"\"Test processing data exceeding 10MB limit by one byte.\"\"\"\n        data = b'x' * (10 * 1024 * 1024 + 1)  # 10MB + 1 byte\n        form_stream = io.BytesIO(data)\n        storage_stream = io.BytesIO()\n        \n        result = process_form_data(form_stream, storage_stream)\n        \n        self.assertEqual(result, \"Form data exceeds the allowable size\")\n\n    def test_empty_input(self):\n        \"\"\"Test processing empty input data.\"\"\"\n        form_stream = io.BytesIO(b'')\n        storage_stream = io.BytesIO()\n        \n        result = process_form_data(form_stream, storage_stream)\n        \n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(storage_stream.getvalue(), b'')\n\n    def test_read_operation_failure(self):\n        \"\"\"Test handling of exception during read operation.\"\"\"\n        class FaultyStream:\n            def read(self, size):\n                raise IOError(\"Simulated read error\")\n                \n        form_stream = FaultyStream()\n        storage_stream = io.BytesIO()\n        \n        result = process_form_data(form_stream, storage_stream)\n        \n        self.assertTrue(result.startswith(\"Error processing input:\"))\n\n    def test_text_stream_with_binary_storage(self):\n        \"\"\"Test passing text stream to form_stream and binary to storage_stream.\"\"\"\n        form_stream = io.StringIO(\"text data\")\n        storage_stream = io.BytesIO()\n        \n        result = process_form_data(form_stream, storage_stream)\n        \n        self.assertTrue(result.startswith(\"Error processing input:\"))\n\n    def test_write_to_closed_storage(self):\n        \"\"\"Test writing to a closed storage stream.\"\"\"\n        data = b'sample data'\n        form_stream = io.BytesIO(data)\n        storage_stream = io.BytesIO()\n        storage_stream.close()  # Close the stream to make writes fail\n        \n        result = process_form_data(form_stream, storage_stream)\n        \n        self.assertTrue(result.startswith(\"Error processing input:\"))\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 8, "task_id": "967d1089"}
{"test": "import io\nimport unittest\n\n# Define the global chunk size for the tests\nFORM_CHUNK_SIZE = 1024  # 1KB\n\nclass TestManageUserData(unittest.TestCase):\n    \n    def test_small_data(self):\n        \"\"\"Test processing small data within the limit.\"\"\"\n        data = b'x' * 100\n        user_stream = io.BytesIO(data)\n        buffer_stream = io.BytesIO()\n        result = manage_user_data(user_stream, buffer_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(buffer_stream.getvalue(), data)\n    \n    def test_multiple_chunks_under_limit(self):\n        \"\"\"Test multiple chunks under the size limit.\"\"\"\n        data = b'x' * (2 * FORM_CHUNK_SIZE)\n        user_stream = io.BytesIO(data)\n        buffer_stream = io.BytesIO()\n        result = manage_user_data(user_stream, buffer_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(buffer_stream.getvalue(), data)\n    \n    def test_exact_limit(self):\n        \"\"\"Test data exactly at the size limit (should succeed).\"\"\"\n        MAX_SIZE_LIMIT = 10 * 1024 * 1024\n        original_chunk_size = FORM_CHUNK_SIZE\n        global FORM_CHUNK_SIZE\n        FORM_CHUNK_SIZE = MAX_SIZE_LIMIT\n        try:\n            data = b'x' * MAX_SIZE_LIMIT\n            user_stream = io.BytesIO(data)\n            buffer_stream = io.BytesIO()\n            result = manage_user_data(user_stream, buffer_stream)\n            self.assertEqual(result, \"Input processed successfully\")\n            self.assertEqual(buffer_stream.getvalue(), data)\n        finally:\n            FORM_CHUNK_SIZE = original_chunk_size\n    \n    def test_one_byte_over(self):\n        \"\"\"Test data exceeding the limit by one byte.\"\"\"\n        MAX_SIZE_LIMIT = 10 * 1024 * 1024\n        original_chunk_size = FORM_CHUNK_SIZE\n        global FORM_CHUNK_SIZE\n        FORM_CHUNK_SIZE = MAX_SIZE_LIMIT\n        try:\n            data = b'x' * (MAX_SIZE_LIMIT + 1)\n            user_stream = io.BytesIO(data)\n            buffer_stream = io.BytesIO()\n            result = manage_user_data(user_stream, buffer_stream)\n            self.assertEqual(result, \"User input exceeds the allowable size\")\n            self.assertEqual(buffer_stream.getvalue(), b'x' * MAX_SIZE_LIMIT)\n        finally:\n            FORM_CHUNK_SIZE = original_chunk_size\n    \n    def test_faulty_stream(self):\n        \"\"\"Test a stream that raises an exception during read.\"\"\"\n        class FaultyStream:\n            def read(self, size):\n                raise IOError(\"Simulated I/O error\")\n        buffer_stream = io.BytesIO()\n        result = manage_user_data(FaultyStream(), buffer_stream)\n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Simulated I/O error\", str(result))\n    \n    def test_empty_stream(self):\n        \"\"\"Test an empty input stream.\"\"\"\n        user_stream = io.BytesIO(b'')\n        buffer_stream = io.BytesIO()\n        result = manage_user_data(user_stream, buffer_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(buffer_stream.getvalue(), b'')\n    \n    def test_uneven_chunks(self):\n        \"\"\"Test data not divisible by the chunk size.\"\"\"\n        data = b'x' * 1025  # 1024 + 1 bytes\n        user_stream = io.BytesIO(data)\n        buffer_stream = io.BytesIO()\n        result = manage_user_data(user_stream, buffer_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(buffer_stream.getvalue(), data)\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 7, "task_id": "db5b5e17"}
{"test": "import unittest\nfrom unittest import mock\nimport requests\nfrom requests import exceptions as requests_exceptions\n\n# Import the function to be tested. Replace 'my_module' with the actual module name.\nfrom my_module import fetch_large_document\n\nclass TestFetchLargeDocument(unittest.TestCase):\n    def test_happy_path(self):\n        # Test successful download of a small file within size limit.\n        mock_response = mock.Mock()\n        chunks = [b'chunk1', b'chunk2']\n        mock_response.iter_content.return_value = chunks\n        mock_response.__enter__.return_value = mock_response\n        \n        with mock.patch('requests.get', return_value=mock_response):\n            with mock.patch('builtins.open', mock.mock_open()) as mocked_open:\n                result = fetch_large_document('http://example.com', 'test_file.txt')\n                self.assertIsNone(result)\n                mocked_open.assert_called_once_with('test_file.txt', 'wb')\n                handle = mocked_open()\n                self.assertEqual(handle.write.call_count, len(chunks))\n                for i, chunk in enumerate(chunks):\n                    self.assertEqual(handle.write.call_args_list[i][0][0], chunk)\n\n    def test_file_exceeds_max_size(self):\n        # Test file download exceeding the 20MB limit.\n        mock_response = mock.Mock()\n        chunk1 = b'a' * (15 * 1024 * 1024)  # 15MB\n        chunk2 = b'a' * (6 * 1024 * 1024)   # 6MB -> total 21MB\n        chunks = [chunk1, chunk2]\n        mock_response.iter_content.return_value = chunks\n        mock_response.__enter__.return_value = mock_response\n        \n        with mock.patch('requests.get', return_value=mock_response):\n            with mock.patch('builtins.open', mock.mock_open()) as mocked_open:\n                result = fetch_large_document('http://example.com', 'test_file.txt')\n                self.assertEqual(result, \"Downloaded file exceeds the allowable size limit\")\n                # Verify only first chunk written before exceeding limit\n                handle = mocked_open()\n                handle.write.assert_called_once_with(chunk1)\n\n    def test_io_error(self):\n        # Test IOError during file writing.\n        mock_response = mock.Mock()\n        chunks = [b'data']\n        mock_response.iter_content.return_value = chunks\n        mock_response.__enter__.return_value = mock_response\n        \n        with mock.patch('requests.get', return_value=mock_response):\n            with mock.patch('builtins.open') as mocked_open:\n                mocked_open.side_effect = IOError(\"Disk full\")\n                result = fetch_large_document('http://example.com', 'test_file.txt')\n                self.assertIsInstance(result, Exception)\n                self.assertTrue(str(result).startswith(\"Disk Error: \"))\n\n    def test_network_error(self):\n        # Test network error (ConnectionError) during request.\n        with mock.patch('requests.get', side_effect=requests_exceptions.ConnectionError(\"Network error\")):\n            result = fetch_large_document('http://example.com', 'test_file.txt')\n            self.assertIsInstance(result, Exception)\n            self.assertTrue(str(result).startswith(\"Error downloading file: \"))\n\n    def test_exactly_20mb(self):\n        # Test file download exactly at the 20MB limit.\n        mock_response = mock.Mock()\n        chunk_size = 10 * 1024 * 1024  # 10MB\n        chunks = [b'a' * chunk_size, b'a' * chunk_size]  # Total 20MB\n        mock_response.iter_content.return_value = chunks\n        mock_response.__enter__.return_value = mock_response\n        \n        with mock.patch('requests.get', return_value=mock_response):\n            with mock.patch('builtins.open', mock.mock_open()) as mocked_open:\n                result = fetch_large_document('http://example.com', 'test_file.txt')\n                self.assertIsNone(result)\n                handle = mocked_open()\n                self.assertEqual(handle.write.call_count, len(chunks))\n\n    def test_empty_file(self):\n        # Test downloading an empty file.\n        mock_response = mock.Mock()\n        chunks = []\n        mock_response.iter_content.return_value = chunks\n        mock_response.__enter__.return_value = mock_response\n        \n        with mock.patch('requests.get', return_value=mock_response):\n            with mock.patch('builtins.open', mock.mock_open()) as mocked_open:\n                result = fetch_large_document('http://example.com', 'test_file.txt')\n                self.assertIsNone(result)\n                handle = mocked_open()\n                handle.write.assert_not_called()\n\n    def test_invalid_source_url_type(self):\n        # Test invalid source_url type (None).\n        with mock.patch('requests.get', side_effect=TypeError(\"URL must be a string\")):\n            result = fetch_large_document(None, 'test_file.txt')\n            self.assertIsInstance(result, Exception)\n            self.assertTrue(str(result).startswith(\"Error downloading file: \"))\n\n    def test_invalid_destination_filepath_type(self):\n        # Test invalid destination_filepath type (None).\n        mock_response = mock.Mock()\n        chunks = [b'data']\n        mock_response.iter_content.return_value = chunks\n        mock_response.__enter__.return_value = mock_response\n        \n        with mock.patch('requests.get', return_value=mock_response):\n            with mock.patch('builtins.open', side_effect=TypeError(\"path must be a string\")):\n                result = fetch_large_document('http://example.com', None)\n                self.assertIsInstance(result, Exception)\n                self.assertTrue(str(result).startswith(\"Error downloading file: \"))\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 8, "task_id": "41add9d4"}
{"test": "import unittest\nfrom unittest.mock import patch, MagicMock, mock_open, call\nimport requests\nfrom solution import retrieve_large_data\n\nclass TestRetrieveLargeData(unittest.TestCase):\n    def test_happy_path_small_chunks(self):\n        # Test with two small chunks under size limit\n        with patch('requests.get') as mock_get:\n            mock_response = MagicMock()\n            mock_response.iter_content.return_value = [b'chunk1', b'chunk2']\n            mock_get.return_value = mock_response\n            with patch('builtins.open', mock_open()) as mock_file:\n                result = retrieve_large_data('http://example.com', 'test.bin')\n                self.assertIsNone(result)\n                mock_file().write.assert_has_calls([call(b'chunk1'), call(b'chunk2')])\n\n    def test_exact_size_limit(self):\n        # Test with chunks totaling exactly 20 MB\n        chunk1 = b'a' * (10 * 1024 * 1024)\n        chunk2 = b'b' * (10 * 1024 * 1024)\n        with patch('requests.get') as mock_get:\n            mock_response = MagicMock()\n            mock_response.iter_content.return_value = [chunk1, chunk2]\n            mock_get.return_value = mock_response\n            with patch('builtins.open', mock_open()) as mock_file:\n                result = retrieve_large_data('http://example.com', 'test.bin')\n                self.assertIsNone(result)\n                mock_file().write.assert_has_calls([call(chunk1), call(chunk2)])\n\n    def test_exceed_size_limit_two_chunks(self):\n        # Test exceeding limit with two chunks (10MB + 11MB)\n        chunk1 = b'a' * (10 * 1024 * 1024)\n        chunk2 = b'b' * (11 * 1024 * 1024)\n        with patch('requests.get') as mock_get:\n            mock_response = MagicMock()\n            mock_response.iter_content.return_value = [chunk1, chunk2]\n            mock_get.return_value = mock_response\n            with patch('builtins.open', mock_open()) as mock_file:\n                result = retrieve_large_data('http://example.com', 'test.bin')\n                self.assertEqual(result, 'Downloaded file exceeds the allowable size limit')\n                mock_file().write.assert_called_once_with(chunk1)\n\n    def test_empty_chunk(self):\n        # Test with empty chunk causing early termination\n        with patch('requests.get') as mock_get:\n            mock_response = MagicMock()\n            mock_response.iter_content.return_value = [b'']\n            mock_get.return_value = mock_response\n            with patch('builtins.open', mock_open()) as mock_file:\n                result = retrieve_large_data('http://example.com', 'test.bin')\n                self.assertIsNone(result)\n                mock_file().write.assert_not_called()\n\n    def test_single_chunk_under_limit(self):\n        # Test single chunk under size limit\n        with patch('requests.get') as mock_get:\n            mock_response = MagicMock()\n            mock_response.iter_content.return_value = [b'single chunk']\n            mock_get.return_value = mock_response\n            with patch('builtins.open', mock_open()) as mock_file:\n                result = retrieve_large_data('http://example.com', 'test.bin')\n                self.assertIsNone(result)\n                mock_file().write.assert_called_once_with(b'single chunk')\n\n    def test_io_error_handling(self):\n        # Test IOError during file write\n        with patch('requests.get') as mock_get:\n            mock_response = MagicMock()\n            mock_response.iter_content.return_value = [b'chunk1']\n            mock_get.return_value = mock_response\n            with patch('builtins.open', mock_open()) as mock_file:\n                mock_file.side_effect = IOError('Disk full')\n                result = retrieve_large_data('http://example.com', 'test.bin')\n                self.assertIsInstance(result, Exception)\n                self.assertIn('Disk Error: Disk full', str(result))\n\n    def test_connection_error_handling(self):\n        # Test ConnectionError during request\n        with patch('requests.get') as mock_get:\n            mock_get.side_effect = requests.exceptions.ConnectionError('Connection error')\n            result = retrieve_large_data('http://example.com', 'test.bin')\n            self.assertIsInstance(result, Exception)\n            self.assertIn('Error downloading file: Connection error', str(result))\n\n    def test_timeout_error_handling(self):\n        # Test Timeout during request\n        with patch('requests.get') as mock_get:\n            mock_get.side_effect = requests.exceptions.Timeout('Timeout')\n            result = retrieve_large_data('http://example.com', 'test.bin')\n            self.assertIsInstance(result, Exception)\n            self.assertIn('Error downloading file: Timeout', str(result))\n\n    def test_single_chunk_exceeds_limit(self):\n        # Test single chunk exceeding size limit (21MB)\n        chunk = b'a' * (21 * 1024 * 1024)\n        with patch('requests.get') as mock_get:\n            mock_response = MagicMock()\n            mock_response.iter_content.return_value = [chunk]\n            mock_get.return_value = mock_response\n            with patch('builtins.open', mock_open()) as mock_file:\n                result = retrieve_large_data('http://example.com', 'test.bin')\n                self.assertEqual(result, 'Downloaded file exceeds the allowable size limit')\n                mock_file().write.assert_not_called()\n\n    def test_empty_url_handling(self):\n        # Test empty URL causing MissingSchema error\n        with patch('requests.get') as mock_get:\n            mock_get.side_effect = requests.exceptions.MissingSchema('Invalid URL')\n            result = retrieve_large_data('', 'test.bin')\n            self.assertIsInstance(result, Exception)\n            self.assertIn('Error downloading file: Invalid URL', str(result))\n\n    def test_empty_chunk_in_middle(self):\n        # Test empty chunk in middle of stream terminates early\n        with patch('requests.get') as mock_get:\n            mock_response = MagicMock()\n            mock_response.iter_content.return_value = [b'chunk1', b'', b'chunk2']\n            mock_get.return_value = mock_response\n            with patch('builtins.open', mock_open()) as mock_file:\n                result = retrieve_large_data('http://example.com', 'test.bin')\n                self.assertIsNone(result)\n                mock_file().write.assert_called_once_with(b'chunk1')\n\n    def test_many_small_chunks_exact_limit(self):\n        # Test many small chunks totaling exactly 20MB\n        chunk_size = 1 * 1024 * 1024\n        chunks = [b'a' * chunk_size for _ in range(20)]\n        with patch('requests.get') as mock_get:\n            mock_response = MagicMock()\n            mock_response.iter_content.return_value = chunks\n            mock_get.return_value = mock_response\n            with patch('builtins.open', mock_open()) as mock_file:\n                result = retrieve_large_data('http://example.com', 'test.bin')\n                self.assertIsNone(result)\n                self.assertEqual(mock_file().write.call_count, 20)\n                expected_calls = [call(chunk) for chunk in chunks]\n                mock_file().write.assert_has_calls(expected_calls)\n", "num_test_cases": 12, "task_id": "17c97b3a"}
{"test": "import unittest\nfrom unittest.mock import patch, mock_open, MagicMock\nimport requests\nfrom requests.exceptions import RequestException, MissingSchema\n\nclass TestAcquireLargeData(unittest.TestCase):\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_small_file_success(self, mock_file, mock_get):\n        # Test successful download with small file (under 20 MB)\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = [b'chunk1', b'chunk2']\n        mock_get.return_value = mock_response\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        result = acquire_large_data('http://valid.com', 'test.bin')\n        self.assertIsNone(result)\n        mock_file().write.assert_any_call(b'chunk1')\n        mock_file().write.assert_any_call(b'chunk2')\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_exactly_20mb_success(self, mock_file, mock_get):\n        # Test exactly 20 MB file (boundary condition)\n        chunk_size = 1024\n        num_chunks = 20 * 1024  # 20*1024 chunks of 1024 bytes = 20 MB\n        chunks = [b'x' * chunk_size] * num_chunks\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = chunks\n        mock_get.return_value = mock_response\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        result = acquire_large_data('http://valid.com', 'test.bin')\n        self.assertIsNone(result)\n        self.assertEqual(mock_file().write.call_count, num_chunks)\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_exceed_20mb_failure(self, mock_file, mock_get):\n        # Test file exceeding 20 MB raises ValueError\n        chunks = [b'x' * 1024] * (20 * 1024)  # 20 MB\n        chunks.append(b'extra')  # 20 MB + 5 bytes\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = chunks\n        mock_get.return_value = mock_response\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        with self.assertRaises(ValueError) as context:\n            acquire_large_data('http://valid.com', 'test.bin')\n        self.assertEqual(str(context.exception), 'Downloaded file exceeds the allowable size limit')\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_disk_error_handling(self, mock_file, mock_get):\n        # Test IOError during file write\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = [b'data']\n        mock_get.return_value = mock_response\n        mock_get.return_value.__enter__.return_value = mock_response\n        mock_file().write.side_effect = IOError('Disk error')\n        \n        with self.assertRaises(IOError) as context:\n            acquire_large_data('http://valid.com', 'test.bin')\n        self.assertIn('Disk error', str(context.exception))\n\n    @patch('requests.get')\n    def test_network_error_handling(self, mock_get):\n        # Test RequestException during download\n        mock_get.side_effect = RequestException('Network failure')\n        \n        with self.assertRaises(RequestException) as context:\n            acquire_large_data('http://invalid.com', 'test.bin')\n        self.assertEqual(str(context.exception), 'Network failure')\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_empty_file_success(self, mock_file, mock_get):\n        # Test download of empty file (handles empty chunks)\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = [b'']\n        mock_get.return_value = mock_response\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        result = acquire_large_data('http://empty.com', 'test.bin')\n        self.assertIsNone(result)\n        mock_file().write.assert_not_called()\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_varying_chunk_sizes(self, mock_file, mock_get):\n        # Test non-standard chunk sizes (less than CHUNK_SIZE)\n        chunks = [b'abc', b'de', b'fghij']\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = chunks\n        mock_get.return_value = mock_response\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        result = acquire_large_data('http://valid.com', 'test.bin')\n        self.assertIsNone(result)\n        mock_file().write.assert_any_call(b'abc')\n        mock_file().write.assert_any_call(b'de')\n        mock_file().write.assert_any_call(b'fghij')\n\n    @patch('requests.get')\n    def test_empty_source_link(self, mock_get):\n        # Test empty source_link parameter\n        mock_get.side_effect = MissingSchema('Invalid URL')\n        \n        with self.assertRaises(MissingSchema) as context:\n            acquire_large_data('', 'test.bin')\n        self.assertIn('Invalid URL', str(context.exception))\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_empty_target_path(self, mock_file, mock_get):\n        # Test empty target_path parameter\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = [b'data']\n        mock_get.return_value = mock_response\n        mock_get.return_value.__enter__.return_value = mock_response\n        mock_file.side_effect = IOError('Invalid path')\n        \n        with self.assertRaises(IOError) as context:\n            acquire_large_data('http://valid.com', '')\n        self.assertIn('Invalid path', str(context.exception))\n\n    @patch('requests.get')\n    def test_source_link_none(self, mock_get):\n        # Test None source_link parameter\n        mock_get.side_effect = TypeError('URL must be string')\n        \n        with self.assertRaises(TypeError) as context:\n            acquire_large_data(None, 'test.bin')\n        self.assertIn('URL must be string', str(context.exception))\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_target_path_none(self, mock_file, mock_get):\n        # Test None target_path parameter\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = [b'data']\n        mock_get.return_value = mock_response\n        mock_get.return_value.__enter__.return_value = mock_response\n        mock_file.side_effect = TypeError('Path must be string')\n        \n        with self.assertRaises(TypeError) as context:\n            acquire_large_data('http://valid.com', None)\n        self.assertIn('Path must be string', str(context.exception))\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 12, "task_id": "660776c2"}
{"test": "import unittest\nfrom unittest.mock import patch, mock_open, MagicMock\nfrom solution import retrieve_large_file\n\nclass TestRetrieveLargeFile(unittest.TestCase):\n    \n    def test_happy_path_small_file(self):\n        \"\"\"Test successful download within size limit.\"\"\"\n        chunks = [b'Hello', b' ', b'World!']\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = iter(chunks)\n        \n        with patch('requests.get', return_value=mock_response) as mock_get, \\\n             patch('builtins.open', mock_open()) as mock_file:\n            \n            result = retrieve_large_file('http://valid.endpoint', 'test_small.txt')\n            \n            self.assertIsNone(result)\n            mock_get.assert_called_once_with('http://valid.endpoint', stream=True)\n            mock_file.assert_called_once_with('test_small.txt', 'wb')\n            file_handle = mock_file()\n            expected_calls = [call(chunk) for chunk in chunks]\n            file_handle.write.assert_has_calls(expected_calls)\n\n    def test_exact_size_limit(self):\n        \"\"\"Test download exactly at 20 MB limit.\"\"\"\n        max_size = 20 * 1024 * 1024\n        chunks = [b'x' * max_size]\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = iter(chunks)\n        \n        with patch('requests.get', return_value=mock_response) as mock_get, \\\n             patch('builtins.open', mock_open()) as mock_file:\n            \n            result = retrieve_large_file('http://exact.endpoint', 'test_exact.txt')\n            \n            self.assertIsNone(result)\n            mock_get.assert_called_once_with('http://exact.endpoint', stream=True)\n            file_handle = mock_file()\n            file_handle.write.assert_called_once_with(chunks[0])\n\n    def test_exceed_size_limit(self):\n        \"\"\"Test download exceeding 20 MB by one byte.\"\"\"\n        chunk1 = b'x' * (10 * 1024 * 1024)\n        chunk2 = b'x' * (10 * 1024 * 1024)\n        chunk3 = b'x'  # One byte over\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = iter([chunk1, chunk2, chunk3])\n        \n        with patch('requests.get', return_value=mock_response) as mock_get, \\\n             patch('builtins.open', mock_open()):\n            \n            result = retrieve_large_file('http://exceed.endpoint', 'test_exceed.txt')\n            \n            self.assertEqual(result, \"Downloaded file exceeds the allowable size limit\")\n            mock_get.assert_called_once_with('http://exceed.endpoint', stream=True)\n\n    def test_empty_file(self):\n        \"\"\"Test downloading an empty file (0 bytes).\"\"\"\n        chunks = []\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = iter(chunks)\n        \n        with patch('requests.get', return_value=mock_response) as mock_get, \\\n             patch('builtins.open', mock_open()) as mock_file:\n            \n            result = retrieve_large_file('http://empty.endpoint', 'test_empty.txt')\n            \n            self.assertIsNone(result)\n            mock_get.assert_called_once_with('http://empty.endpoint', stream=True)\n            file_handle = mock_file()\n            file_handle.write.assert_not_called()\n\n    def test_io_error_handling(self):\n        \"\"\"Test IOError during file write.\"\"\"\n        chunks = [b'data']\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = iter(chunks)\n        \n        with patch('requests.get', return_value=mock_response) as mock_get, \\\n             patch('builtins.open', mock_open()) as mock_file:\n            \n            mock_file.return_value.write.side_effect = IOError(\"Disk full\")\n            result = retrieve_large_file('http://valid.endpoint', 'test_ioerror.txt')\n            \n            self.assertIsInstance(result, Exception)\n            self.assertIn(\"Disk Error: Disk full\", str(result))\n            mock_get.assert_called_once_with('http://valid.endpoint', stream=True)\n\n    def test_network_error_handling(self):\n        \"\"\"Test handling of network errors.\"\"\"\n        with patch('requests.get', side_effect=ConnectionError(\"Network down\")) as mock_get:\n            result = retrieve_large_file('http://invalid.endpoint', 'test_network.txt')\n            \n            self.assertIsInstance(result, Exception)\n            self.assertIn(\"Error downloading file: Network down\", str(result))\n            mock_get.assert_called_once_with('http://invalid.endpoint', stream=True)\n\n    def test_varying_chunk_sizes(self):\n        \"\"\"Test multiple chunks of varying sizes under limit.\"\"\"\n        chunks = [b'a'*512, b'b'*1024, b'c'*2048, b'd'*4096]\n        total_size = sum(len(chunk) for chunk in chunks)\n        self.assertLess(total_size, 20 * 1024 * 1024)  # Ensure test is valid\n        \n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = iter(chunks)\n        \n        with patch('requests.get', return_value=mock_response) as mock_get, \\\n             patch('builtins.open', mock_open()) as mock_file:\n            \n            result = retrieve_large_file('http://chunked.endpoint', 'test_chunks.txt')\n            \n            self.assertIsNone(result)\n            mock_get.assert_called_once_with('http://chunked.endpoint', stream=True)\n            file_handle = mock_file()\n            expected_calls = [call(chunk) for chunk in chunks]\n            file_handle.write.assert_has_calls(expected_calls)\n\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 7, "task_id": "82bba9dc"}
{"test": "import unittest\nimport os\nimport tempfile\nfrom unittest import mock\nimport requests\nfrom solution import fetch_large_file\n\n\nclass TestFetchLargeFile(unittest.TestCase):\n    def test_small_file(self):\n        # Test downloading a small file (under 20 MB)\n        with tempfile.TemporaryDirectory() as temp_dir:\n            storage_path = os.path.join(temp_dir, 'file.txt')\n            mock_response = mock.Mock()\n            chunks = [b'Hello', b' ', b'World!']\n            mock_response.iter_content.return_value = iter(chunks)\n            with mock.patch('requests.get', return_value=mock_response):\n                result = fetch_large_file('http://example.com', storage_path)\n                self.assertIsNone(result)\n            with open(storage_path, 'rb') as f:\n                content = f.read()\n            self.assertEqual(content, b'Hello World!')\n\n    def test_exact_size(self):\n        # Test downloading a file of exactly 20 MB\n        with tempfile.TemporaryDirectory() as temp_dir:\n            storage_path = os.path.join(temp_dir, 'file.txt')\n            mock_response = mock.Mock()\n            chunk_size = 20 * 1024 * 1024\n            chunks = [b'a' * chunk_size]\n            mock_response.iter_content.return_value = iter(chunks)\n            with mock.patch('requests.get', return_value=mock_response):\n                result = fetch_large_file('http://example.com', storage_path)\n                self.assertIsNone(result)\n            self.assertEqual(os.path.getsize(storage_path), chunk_size)\n\n    def test_exceed_size(self):\n        # Test downloading a file that exceeds 20 MB by 1 byte\n        with tempfile.TemporaryDirectory() as temp_dir:\n            storage_path = os.path.join(temp_dir, 'file.txt')\n            mock_response = mock.Mock()\n            chunk1_size = 20 * 1024 * 1024 - 100\n            chunk2_size = 101\n            chunks = [b'a' * chunk1_size, b'b' * chunk2_size]\n            mock_response.iter_content.return_value = iter(chunks)\n            with mock.patch('requests.get', return_value=mock_response):\n                result = fetch_large_file('http://example.com', storage_path)\n                self.assertEqual(result, 'Downloaded file exceeds the allowable size limit')\n            self.assertEqual(os.path.getsize(storage_path), chunk1_size + chunk2_size)\n\n    def test_io_error(self):\n        # Test that an IOError during writing is handled\n        with tempfile.TemporaryDirectory() as temp_dir:\n            storage_path = os.path.join(temp_dir, 'file.txt')\n            mock_response = mock.Mock()\n            chunks = [b'Hello']\n            mock_response.iter_content.return_value = iter(chunks)\n            with mock.patch('requests.get', return_value=mock_response), \\\n                 mock.patch('builtins.open', side_effect=IOError('Disk full')):\n                result = fetch_large_file('http://example.com', storage_path)\n                self.assertIsInstance(result, Exception)\n                self.assertIn('Disk Error: Disk full', str(result))\n\n    def test_network_error(self):\n        # Test that a network error (ConnectionError) is handled\n        with tempfile.TemporaryDirectory() as temp_dir:\n            storage_path = os.path.join(temp_dir, 'file.txt')\n            with mock.patch('requests.get', side_effect=requests.exceptions.ConnectionError('Network error')):\n                result = fetch_large_file('http://example.com', storage_path)\n                self.assertIsInstance(result, Exception)\n                self.assertIn('Error downloading file: Network error', str(result))\n\n    def test_empty_file(self):\n        # Test downloading an empty file\n        with tempfile.TemporaryDirectory() as temp_dir:\n            storage_path = os.path.join(temp_dir, 'file.txt')\n            mock_response = mock.Mock()\n            chunks = []\n            mock_response.iter_content.return_value = iter(chunks)\n            with mock.patch('requests.get', return_value=mock_response):\n                result = fetch_large_file('http://example.com', storage_path)\n                self.assertIsNone(result)\n            self.assertEqual(os.path.getsize(storage_path), 0)\n\n    def test_one_chunk(self):\n        # Test downloading a file of exactly one chunk (arbitrary size, say 1024 bytes)\n        with tempfile.TemporaryDirectory() as temp_dir:\n            storage_path = os.path.join(temp_dir, 'file.txt')\n            mock_response = mock.Mock()\n            chunk_size = 1024\n            chunks = [b'a' * chunk_size]\n            mock_response.iter_content.return_value = iter(chunks)\n            with mock.patch('requests.get', return_value=mock_response):\n                result = fetch_large_file('http://example.com', storage_path)\n                self.assertIsNone(result)\n            self.assertEqual(os.path.getsize(storage_path), chunk_size)\n\n    def test_two_chunks_second_causes_exceed(self):\n        # Test two chunks: the first is 20 MB, the second causes exceed and is written\n        with tempfile.TemporaryDirectory() as temp_dir:\n            storage_path = os.path.join(temp_dir, 'file.txt')\n            mock_response = mock.Mock()\n            chunk1 = b'a' * (20 * 1024 * 1024)\n            chunk2 = b'b'\n            chunks = [chunk1, chunk2]\n            mock_response.iter_content.return_value = iter(chunks)\n            with mock.patch('requests.get', return_value=mock_response):\n                result = fetch_large_file('http://example.com', storage_path)\n                self.assertEqual(result, 'Downloaded file exceeds the allowable size limit')\n            with open(storage_path, 'rb') as f:\n                content = f.read()\n            self.assertEqual(content, chunk1 + chunk2)\n", "num_test_cases": 8, "task_id": "73c5c7e1"}
{"test": "import unittest\nfrom unittest.mock import patch, MagicMock, mock_open, call\nimport requests\nimport solution\n\nclass TestRetrieveBigFile(unittest.TestCase):\n    CHUNK_SIZE = 1024\n\n    @classmethod\n    def setUpClass(cls):\n        solution.CHUNK_SIZE = cls.CHUNK_SIZE\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_success_within_limit(self, mock_file, mock_get):\n        # Test successful download within size limit\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = [b'a'*1024, b'b'*1024]\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        result = solution.retrieve_big_file('http://example.com/file', '/path/to/file')\n        self.assertIsNone(result)\n        \n        file_handle = mock_file()\n        expected_calls = [call(b'a'*1024), call(b'b'*1024)]\n        file_handle.write.assert_has_calls(expected_calls)\n        self.assertEqual(file_handle.write.call_count, 2)\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_exactly_20mb(self, mock_file, mock_get):\n        # Test file download of exactly 20MB (limit edge case)\n        num_chunks = 20 * 1024\n        chunk_data = b'a' * 1024\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = [chunk_data] * num_chunks\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        result = solution.retrieve_big_file('http://example.com/file', '/path/to/file')\n        self.assertIsNone(result)\n        \n        file_handle = mock_file()\n        self.assertEqual(file_handle.write.call_count, num_chunks)\n        total_written = sum(len(call[0][0]) for call in file_handle.write.call_args_list)\n        self.assertEqual(total_written, 20 * 1024 * 1024)\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_exceeds_20mb(self, mock_file, mock_get):\n        # Test file download exceeding 20MB\n        num_chunks = 20 * 1024\n        chunk_data = b'a' * 1024\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = [chunk_data] * num_chunks + [b'x']\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        result = solution.retrieve_big_file('http://example.com/file', '/path/to/file')\n        self.assertEqual(result, 'Downloaded file exceeds the allowable size limit')\n        \n        file_handle = mock_file()\n        self.assertEqual(file_handle.write.call_count, num_chunks)\n        total_written = sum(len(call[0][0]) for call in file_handle.write.call_args_list)\n        self.assertEqual(total_written, 20 * 1024 * 1024)\n\n    @patch('requests.get')\n    @patch('builtins.open')\n    def test_io_error(self, mock_open, mock_get):\n        # Test IOError during file write\n        mock_open.side_effect = IOError('Permission denied')\n        mock_get.return_value.__enter__.return_value = MagicMock()\n        \n        result = solution.retrieve_big_file('http://example.com/file', '/invalid/path')\n        self.assertIsInstance(result, Exception)\n        self.assertIn('Disk Error: Permission denied', str(result))\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_network_error(self, mock_file, mock_get):\n        # Test network error during download\n        mock_get.side_effect = requests.exceptions.RequestException('Connection failed')\n        \n        result = solution.retrieve_big_file('http://example.com/file', '/path/to/file')\n        self.assertIsInstance(result, Exception)\n        self.assertIn('Error downloading file: Connection failed', str(result))\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_empty_file(self, mock_file, mock_get):\n        # Test empty file download\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = []\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        result = solution.retrieve_big_file('http://example.com/empty', '/path/to/file')\n        self.assertIsNone(result)\n        \n        file_handle = mock_file()\n        file_handle.write.assert_not_called()\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_chunk_size_passed(self, mock_file, mock_get):\n        # Test chunk size passed to iter_content\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = []\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        solution.retrieve_big_file('http://example.com/file', '/path/to/file')\n        mock_response.iter_content.assert_called_once_with(1024)\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 7, "task_id": "686a34c5"}
{"test": "import unittest\nfrom unittest.mock import patch, MagicMock, mock_open\nimport requests\n\nclass TestFetchLargeFile(unittest.TestCase):\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_successful_download_small(self, mock_file, mock_get):\n        # Test successful download of a small file within size limit\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = [b'small_chunk'] * 3\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        result = fetch_large_file('http://example.com/small', 'small.txt')\n        \n        self.assertIsNone(result)\n        self.assertEqual(mock_file().write.call_count, 3)\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_empty_file(self, mock_file, mock_get):\n        # Test downloading an empty file (0 bytes)\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = []\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        result = fetch_large_file('http://example.com/empty', 'empty.txt')\n        \n        self.assertIsNone(result)\n        mock_file().write.assert_not_called()\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_exact_20mb_file(self, mock_file, mock_get):\n        # Test downloading a file exactly at the 20MB limit\n        chunk = b'x' * 1024\n        num_chunks = 20 * 1024  # 20 MB in 1KB chunks\n        chunks = [chunk] * num_chunks\n        \n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = iter(chunks)\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        result = fetch_large_file('http://example.com/exact', 'exact.txt')\n        \n        self.assertIsNone(result)\n        self.assertEqual(mock_file().write.call_count, num_chunks)\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_exceed_20mb_file(self, mock_file, mock_get):\n        # Test file download exceeding the 20MB limit\n        chunk = b'x' * 1024\n        num_chunks = 20 * 1024  # 20 MB in 1KB chunks\n        chunks = [chunk] * num_chunks + [b'x']  # One extra byte\n        \n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = iter(chunks)\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        result = fetch_large_file('http://example.com/large', 'large.txt')\n        \n        self.assertEqual(result, \"Downloaded file exceeds the allowable size limit\")\n        self.assertEqual(mock_file().write.call_count, num_chunks)  # Writes until limit exceeded\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_io_error_during_write(self, mock_file, mock_get):\n        # Test IOError during file write operation\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = [b'data']\n        mock_get.return_value.__enter__.return_value = mock_response\n        mock_file().write.side_effect = IOError(\"Disk full\")\n        \n        result = fetch_large_file('http://example.com/ioerror', 'ioerror.txt')\n        \n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Disk Error\", str(result))\n\n    @patch('requests.get')\n    def test_network_error(self, mock_get):\n        # Test network error during download\n        mock_get.side_effect = requests.exceptions.RequestException(\"Connection failed\")\n        \n        result = fetch_large_file('http://example.com/error', 'error.txt')\n        \n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Error downloading file\", str(result))\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_chunk_size_variation(self, mock_file, mock_get):\n        # Test handling of variable-sized chunks\n        chunks = [b'chunk1', b'chunk22', b'chunk333']  # Different sizes\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = iter(chunks)\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        result = fetch_large_file('http://example.com/variable', 'variable.txt')\n        \n        self.assertIsNone(result)\n        self.assertEqual(mock_file().write.call_count, len(chunks))", "num_test_cases": 7, "task_id": "e3ed6250"}
{"test": "import unittest\nfrom unittest.mock import patch, MagicMock, mock_open\n\nclass TestLargeFileTransfer(unittest.TestCase):\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_successful_small_file(self, mock_file, mock_get):\n        # Test downloading a small file under size limit\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = [b'small data']\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        result = transfer_large_file('http://example.com/small', 'small.txt')\n        self.assertIsNone(result)\n        mock_file().write.assert_called_with(b'small data')\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_exact_size_limit(self, mock_file, mock_get):\n        # Test file exactly at 20MB limit\n        mock_response = MagicMock()\n        exact_size = 20 * 1024 * 1024\n        mock_response.iter_content.return_value = [b'a' * exact_size]\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        result = transfer_large_file('http://example.com/exact', 'exact.bin')\n        self.assertIsNone(result)\n        mock_file().write.assert_called_with(b'a' * exact_size)\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_exceeds_size_limit(self, mock_file, mock_get):\n        # Test file exceeding 20MB limit\n        mock_response = MagicMock()\n        chunk1 = b'a' * (10 * 1024 * 1024)\n        chunk2 = b'a' * (10 * 1024 * 1024)\n        chunk3 = b'a' * (1024 * 1024 + 1)  # Total: 21MB + 1 byte\n        mock_response.iter_content.return_value = [chunk1, chunk2, chunk3]\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        result = transfer_large_file('http://example.com/large', 'large.bin')\n        self.assertEqual(result, \"Transferred file exceeds the allowable size limit\")\n        \n        # Verify first two chunks were written\n        mock_file().write.assert_any_call(chunk1)\n        mock_file().write.assert_any_call(chunk2)\n        # Third chunk should be written and then trigger the error\n        mock_file().write.assert_any_call(chunk3)\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_empty_file(self, mock_file, mock_get):\n        # Test downloading an empty file\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = []\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        result = transfer_large_file('http://example.com/empty', 'empty.txt')\n        self.assertIsNone(result)\n        mock_file().write.assert_not_called()\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_io_error(self, mock_file, mock_get):\n        # Test IOError during file write\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = [b'data1', b'data2']\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        # Make file.write raise IOError on second chunk\n        mock_file().write.side_effect = [None, IOError('disk full')]\n        \n        result = transfer_large_file('http://example.com/ioerror', 'error.txt')\n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Disk Error: disk full\", str(result))\n\n    @patch('requests.get')\n    def test_network_error(self, mock_get):\n        # Test network exception during request\n        mock_get.side_effect = Exception(\"Connection failed\")\n        \n        result = transfer_large_file('http://example.com/error', 'fail.txt')\n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Error during file transfer: Connection failed\", str(result))\n\n    @patch('requests.get')\n    @patch('builtins.open', new_callable=mock_open)\n    def test_single_large_chunk_exceeds_limit(self, mock_file, mock_get):\n        # Test single chunk that exceeds 20MB\n        mock_response = MagicMock()\n        large_chunk = b'a' * (20 * 1024 * 1024 + 1)\n        mock_response.iter_content.return_value = [large_chunk]\n        mock_get.return_value.__enter__.return_value = mock_response\n        \n        result = transfer_large_file('http://example.com/huge', 'huge.bin')\n        self.assertEqual(result, \"Transferred file exceeds the allowable size limit\")\n        mock_file().write.assert_called_with(large_chunk)\n\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 7, "task_id": "3007a9e0"}
{"test": "import unittest\nfrom unittest.mock import patch, Mock, mock_open\nimport solution\nfrom requests.exceptions import RequestException\n\n# Set the chunk size for testing\nsolution.CHUNK_SIZE = 1024  # 1KB chunks\n\nclass TestReceiveLargeFile(unittest.TestCase):\n\n    def test_success_within_limit(self):\n        \"\"\"Test successful download within file size limit.\"\"\"\n        mock_response = Mock()\n        chunks = [b'a' * 1024] * 10  # 10 chunks of 1KB\n        chunks.append(b'')  # Ending empty chunk\n        mock_response.iter_content.return_value = iter(chunks)\n        mock_response.raise_for_status = Mock()\n        \n        with patch('requests.get', return_value=mock_response):\n            with patch('builtins.open', mock_open()) as mock_file:\n                result = solution.receive_large_file('http://example.com', 'test.bin')\n                \n        self.assertIsNone(result)\n        self.assertEqual(mock_file().write.call_count, 10)\n        for call in mock_file().write.call_args_list:\n            self.assertEqual(call[0][0], b'a'*1024)\n\n    def test_exactly_at_limit(self):\n        \"\"\"Test download exactly at the file size limit (20MB).\"\"\"\n        n_chunks = 20480  # 20MB in 1KB chunks (20*1024)\n        mock_response = Mock()\n        chunks = [b'b' * 1024] * n_chunks\n        chunks.append(b'')\n        mock_response.iter_content.return_value = iter(chunks)\n        mock_response.raise_for_status = Mock()\n        \n        with patch('requests.get', return_value=mock_response):\n            with patch('builtins.open', mock_open()) as mock_file:\n                result = solution.receive_large_file('http://example.com', 'test.bin')\n                \n        self.assertIsNone(result)\n        self.assertEqual(mock_file().write.call_count, n_chunks)\n\n    def test_exceeds_limit(self):\n        \"\"\"Test download exceeding file size limit (20MB + 1 byte).\"\"\"\n        n_chunks = 20481  # 20MB + 1KB\n        mock_response = Mock()\n        chunks = [b'c' * 1024] * n_chunks\n        mock_response.iter_content.return_value = iter(chunks)\n        mock_response.raise_for_status = Mock()\n        \n        with patch('requests.get', return_value=mock_response):\n            with patch('builtins.open', mock_open()) as mock_file:\n                result = solution.receive_large_file('http://example.com', 'test.bin')\n                \n        self.assertEqual(result, \"Downloaded file exceeds the allowable size limit\")\n        self.assertEqual(mock_file().write.call_count, 20480)  # Last block not written\n\n    def test_empty_file(self):\n        \"\"\"Test downloading an empty file.\"\"\"\n        mock_response = Mock()\n        chunks = [b'']  # Only an empty chunk\n        mock_response.iter_content.return_value = iter(chunks)\n        mock_response.raise_for_status = Mock()\n        \n        with patch('requests.get', return_value=mock_response):\n            with patch('builtins.open', mock_open()) as mock_file:\n                result = solution.receive_large_file('http://example.com', 'test.bin')\n                \n        self.assertIsNone(result)\n        mock_file().write.assert_not_called()\n\n    def test_io_error(self):\n        \"\"\"Test file write operation raising IOError.\"\"\"\n        mock_response = Mock()\n        chunks = [b'd' * 1024] * 5\n        chunks.append(b'')\n        mock_response.iter_content.return_value = iter(chunks)\n        mock_response.raise_for_status = Mock()\n        \n        m = mock_open()\n        m().write.side_effect = IOError('Disk full')\n        \n        with patch('requests.get', return_value=mock_response):\n            with patch('builtins.open', m):\n                result = solution.receive_large_file('http://example.com', 'test.bin')\n                \n        self.assertIsInstance(result, Exception)\n        self.assertTrue(str(result).startswith(\"Storage Error: \"))\n\n    def test_network_error(self):\n        \"\"\"Test network error during request.\"\"\"\n        with patch('requests.get', side_effect=RequestException('Connection error')):\n            result = solution.receive_large_file('http://example.com', 'test.bin')\n            \n        self.assertIsInstance(result, Exception)\n        self.assertTrue(str(result).startswith(\"Download failed: \"))\n\n    def test_chunk_size_variation(self):\n        \"\"\"Test handling of varying chunk sizes.\"\"\"\n        mock_response = Mock()\n        chunks = [b'e'*1024, b'f'*512, b'g'*256, b'']\n        mock_response.iter_content.return_value = iter(chunks)\n        mock_response.raise_for_status = Mock()\n        \n        with patch('requests.get', return_value=mock_response):\n            with patch('builtins.open', mock_open()) as mock_file:\n                result = solution.receive_large_file('http://example.com', 'test.bin')\n                \n        self.assertIsNone(result)\n        expected_writes = [b'e'*1024, b'f'*512, b'g'*256]\n        actual_writes = [call[0][0] for call in mock_file().write.call_args_list]\n        self.assertEqual(actual_writes, expected_writes)\n\n    def test_iter_content_exception(self):\n        \"\"\"Test exception during content iteration.\"\"\"\n        mock_response = Mock()\n        mock_response.iter_content.side_effect = Exception('Unexpected error')\n        mock_response.raise_for_status = Mock()\n        \n        with patch('requests.get', return_value=mock_response):\n            result = solution.receive_large_file('http://example.com', 'test.bin')\n            \n        self.assertIsInstance(result, Exception)\n        self.assertTrue(str(result).startswith(\"Download failed: \"))", "num_test_cases": 8, "task_id": "516ddcfd"}
{"test": "import unittest\nfrom unittest.mock import patch, mock_open\nfrom io import BytesIO\n\n# Define maximum file size constant as in the function\nMAX_FILE_SIZE = 50 * 1024 * 1024  # 50 MB\n\n# Import the function from solution module (assumed to be available)\nfrom solution import handle_file_upload\n\n# Helper class to simulate large streams without allocating memory\nclass LargeStream:\n    def __init__(self, size):\n        self.size = size\n        self.pos = 0\n\n    def read(self, chunk_size):\n        if self.pos >= self.size:\n            return b''\n        to_read = min(chunk_size, self.size - self.pos)\n        self.pos += to_read\n        return b'a' * to_read\n\n# Patch FILE_CHUNK_SIZE globally for the test class\n@patch('solution.FILE_CHUNK_SIZE', 1024)\nclass TestCases(unittest.TestCase):\n    \n    def test_small_file_within_limit(self):\n        \"\"\"Test successful upload of a small file within size limit.\"\"\"\n        m = mock_open()\n        with patch('builtins.open', m):\n            stream = BytesIO(b'Hello, World!')\n            result = handle_file_upload(stream, 'test_path')\n            self.assertIsNone(result)\n            handle = m()\n            handle.write.assert_called_once_with(b'Hello, World!')\n    \n    def test_empty_file(self):\n        \"\"\"Test successful upload of an empty file.\"\"\"\n        m = mock_open()\n        with patch('builtins.open', m):\n            stream = BytesIO(b'')\n            result = handle_file_upload(stream, 'test_path')\n            self.assertIsNone(result)\n            handle = m()\n            handle.write.assert_not_called()\n    \n    def test_file_exactly_max_size(self):\n        \"\"\"Test file of exactly MAX_FILE_SIZE (edge case).\"\"\"\n        stream = LargeStream(MAX_FILE_SIZE)\n        m = mock_open()\n        with patch('builtins.open', m):\n            result = handle_file_upload(stream, 'test_path')\n            self.assertIsNone(result)\n    \n    def test_file_exceeds_size_limit(self):\n        \"\"\"Test file exceeding MAX_FILE_SIZE returns an Exception.\"\"\"\n        stream = LargeStream(MAX_FILE_SIZE + 1)\n        m = mock_open()\n        with patch('builtins.open', m):\n            result = handle_file_upload(stream, 'test_path')\n            self.assertIsInstance(result, Exception)\n            self.assertIn('Uploaded file exceeds size limit', str(result))\n    \n    def test_multiple_chunks_written_correctly(self):\n        \"\"\"Test reading/writing multiple chunks with custom chunk size.\"\"\"\n        # Temporarily set FILE_CHUNK_SIZE to 2 for this test\n        with patch('solution.FILE_CHUNK_SIZE', 2):\n            m = mock_open()\n            with patch('builtins.open', m):\n                stream = BytesIO(b'data')\n                result = handle_file_upload(stream, 'test_path')\n                self.assertIsNone(result)\n                handle = m()\n                expected_calls = [unittest.mock.call(b'da'), unittest.mock.call(b'ta')]\n                handle.write.assert_has_calls(expected_calls)\n    \n    def test_io_error_during_write(self):\n        \"\"\"Test IOError during file write returns an Exception.\"\"\"\n        m = mock_open()\n        m.return_value.write.side_effect = IOError('Disk full')\n        with patch('builtins.open', m):\n            stream = BytesIO(b'data')\n            result = handle_file_upload(stream, 'test_path')\n            self.assertIsInstance(result, Exception)\n            self.assertEqual(str(result), 'Error: Disk full')\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 6, "task_id": "9fdca0c8"}
{"test": "import unittest\nimport io\n\n# Define BUFFER_SIZE as a constant used by the function\nBUFFER_SIZE = 4096\n\n# Custom stream class for generating large amounts of data without excessive memory usage\nclass LargeStream:\n    def __init__(self, total_size, chunk_size=4096):\n        self.total_size = total_size\n        self.chunk_size = chunk_size\n        self.remaining = total_size\n    \n    def read(self, size=-1):\n        if size == -1:\n            size = self.remaining\n        to_read = min(size, self.remaining, self.chunk_size)\n        if to_read == 0:\n            return b''\n        self.remaining -= to_read\n        return b'x' * to_read\n\nclass TestProcessDataStream(unittest.TestCase):\n    \n    def test_normal_small_stream(self):\n        \"\"\"Test with a small binary stream within the limit.\"\"\"\n        data = b\"Sample data for testing\"\n        stream = io.BytesIO(data)\n        result = process_data_stream(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_empty_stream(self):\n        \"\"\"Test with an empty binary stream.\"\"\"\n        stream = io.BytesIO(b\"\")\n        result = process_data_stream(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_exactly_100mb(self):\n        \"\"\"Test with a stream exactly at the 100 MB limit.\"\"\"\n        size = 100 * 1024 * 1024  # 100 MB\n        stream = LargeStream(size, BUFFER_SIZE)\n        result = process_data_stream(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_100mb_plus_one_byte(self):\n        \"\"\"Test with a stream exceeding the limit by one byte.\"\"\"\n        size = 100 * 1024 * 1024 + 1  # 100 MB + 1 byte\n        stream = LargeStream(size, BUFFER_SIZE)\n        result = process_data_stream(stream)\n        self.assertIsInstance(result, Exception)\n        self.assertEqual(str(result), \"Error: Data stream exceeds maximum allowed size.\")\n    \n    def test_one_chunk(self):\n        \"\"\"Test with a stream of one BUFFER_SIZE chunk.\"\"\"\n        stream = LargeStream(BUFFER_SIZE, BUFFER_SIZE)\n        result = process_data_stream(stream)\n        self.assertEqual(result, \"Processing complete\")\n    \n    def test_large_stream_200mb(self):\n        \"\"\"Test with a stream of 200 MB (exceeding limit).\"\"\"\n        size = 200 * 1024 * 1024  # 200 MB\n        stream = LargeStream(size, BUFFER_SIZE)\n        result = process_data_stream(stream)\n        self.assertIsInstance(result, Exception)\n        self.assertEqual(str(result), \"Error: Data stream exceeds maximum allowed size.\")\n    \n    def test_invalid_none(self):\n        \"\"\"Test with None as stream (invalid input).\"\"\"\n        result = process_data_stream(None)\n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Unexpected Error\", str(result))\n    \n    def test_invalid_integer(self):\n        \"\"\"Test with an integer instead of a stream (invalid input).\"\"\"\n        result = process_data_stream(123)\n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Unexpected Error\", str(result))\n    \n    def test_closed_stream(self):\n        \"\"\"Test with a closed stream (invalid state).\"\"\"\n        stream = io.BytesIO(b\"Initial data\")\n        stream.close()\n        result = process_data_stream(stream)\n        self.assertIsInstance(result, Exception)\n        self.assertIn(\"Unexpected Error\", str(result))", "num_test_cases": 9, "task_id": "dd2b4a8c"}
{"test": "import unittest\nfrom unittest.mock import patch\n\n# Global constants for the rate limiter\nMAX_REQUESTS_PER_CLIENT = 5\nTIME_WINDOW = 60\n\nclass TestHandleApiRateLimit(unittest.TestCase):\n\n    def test_new_client(self):\n        \"\"\"Test first request from a new client is accepted.\"\"\"\n        with patch('time.time', return_value=1000.0):\n            request_tracker = {}\n            result = handle_api_rate_limit(\"client1\", request_tracker)\n            self.assertEqual(result, \"Request accepted\")\n            self.assertEqual(request_tracker, {\"client1\": (1, 1000.0)})\n\n    def test_request_within_window_under_limit(self):\n        \"\"\"Test subsequent request within time window and under limit is accepted.\"\"\"\n        with patch('time.time', return_value=1000.0):\n            request_tracker = {\"client1\": (1, 999.0)}  # 1 second before\n            result = handle_api_rate_limit(\"client1\", request_tracker)\n            self.assertEqual(result, \"Request accepted\")\n            self.assertEqual(request_tracker, {\"client1\": (2, 999.0)})\n\n    def test_request_at_limit(self):\n        \"\"\"Test request at the limit within time window is accepted.\"\"\"\n        with patch('time.time', return_value=1000.0):\n            request_tracker = {\"client1\": (4, 999.0)}\n            result = handle_api_rate_limit(\"client1\", request_tracker)\n            self.assertEqual(result, \"Request accepted\")\n            self.assertEqual(request_tracker, {\"client1\": (5, 999.0)})\n\n    def test_request_exceed_limit(self):\n        \"\"\"Test request exceeding limit within time window returns error.\"\"\"\n        with patch('time.time', return_value=1000.0):\n            request_tracker = {\"client1\": (5, 999.0)}\n            result = handle_api_rate_limit(\"client1\", request_tracker)\n            self.assertEqual(result, \"Rate limit exceeded for client\")\n\n    def test_request_after_window_reset(self):\n        \"\"\"Test request after time window resets the counter and is accepted.\"\"\"\n        with patch('time.time', return_value=1060.0):  # Exactly 60 seconds later\n            request_tracker = {\"client1\": (5, 1000.0)}\n            result = handle_api_rate_limit(\"client1\", request_tracker)\n            self.assertEqual(result, \"Request accepted\")\n            self.assertEqual(request_tracker, {\"client1\": (1, 1060.0)})\n\n    def test_multiple_clients(self):\n        \"\"\"Test rate limiting works independently for multiple clients.\"\"\"\n        request_tracker = {}\n        with patch('time.time', return_value=1000.0):\n            result1 = handle_api_rate_limit(\"client1\", request_tracker)\n            self.assertEqual(result1, \"Request accepted\")\n            result2 = handle_api_rate_limit(\"client2\", request_tracker)\n            self.assertEqual(result2, \"Request accepted\")\n            self.assertEqual(request_tracker, {\"client1\": (1, 1000.0), \"client2\": (1, 1000.0)})\n        \n        with patch('time.time', return_value=1000.0 + 10):\n            for _ in range(4):\n                handle_api_rate_limit(\"client1\", request_tracker)\n            result = handle_api_rate_limit(\"client1\", request_tracker)  # 6th request for client1\n            self.assertEqual(result, \"Rate limit exceeded for client\")\n            result = handle_api_rate_limit(\"client2\", request_tracker)  # 2nd request for client2\n            self.assertEqual(result, \"Request accepted\")\n\n    def test_non_string_client_id(self):\n        \"\"\"Test non-string but hashable client ID (e.g., integer) is accepted.\"\"\"\n        with patch('time.time', return_value=1000.0):\n            request_tracker = {}\n            result = handle_api_rate_limit(12345, request_tracker)\n            self.assertEqual(result, \"Request accepted\")\n            self.assertEqual(request_tracker, {12345: (1, 1000.0)})\n\n    def test_unhashable_client_id(self):\n        \"\"\"Test unhashable client ID (e.g., list) returns an error.\"\"\"\n        request_tracker = {}\n        result = handle_api_rate_limit([1, 2, 3], request_tracker)\n        self.assertTrue(result.startswith(\"Error in processing request: \"))\n\n    def test_invalid_request_tracker_none(self):\n        \"\"\"Test request_tracker as None returns an error.\"\"\"\n        result = handle_api_rate_limit(\"client1\", None)\n        self.assertTrue(result.startswith(\"Error in processing request: \"))\n\n    def test_invalid_request_tracker_list(self):\n        \"\"\"Test non-dict request_tracker (e.g., list) returns an error.\"\"\"\n        request_tracker = []\n        result = handle_api_rate_limit(\"client1\", request_tracker)\n        self.assertTrue(result.startswith(\"Error in processing request: \"))\n\n\nif __name__ == \"__main__\":\n    unittest.main()", "num_test_cases": 10, "task_id": "a0774ee5"}
{"test": "import unittest\nimport io\n\nclass GeneratedInputStream:\n    def __init__(self, total_size):\n        self.total_size = total_size\n        self.pos = 0\n    \n    def read(self, size=-1):\n        if size < 0:\n            size = self.total_size - self.pos\n        to_read = min(size, self.total_size - self.pos)\n        if to_read <= 0:\n            return b''\n        chunk = b'x' * to_read\n        self.pos += to_read\n        return chunk\n\nclass FaultyInputStream:\n    def read(self, size=-1):\n        raise IOError(\"Simulated read error\")\n\nclass FaultyOutputStream:\n    def write(self, data):\n        raise IOError(\"Simulated write error\")\n\nclass TestParseUserInput(unittest.TestCase):\n    def test_empty_input(self):\n        # Test processing an empty input stream\n        input_stream = io.BytesIO(b'')\n        output_stream = io.BytesIO()\n        result = parse_user_input(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(output_stream.getvalue(), b'')\n\n    def test_small_input(self):\n        # Test processing a small input (5 bytes)\n        input_data = b'hello'\n        input_stream = io.BytesIO(input_data)\n        output_stream = io.BytesIO()\n        result = parse_user_input(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(output_stream.getvalue(), input_data)\n\n    def test_medium_input(self):\n        # Test processing a medium-sized input (100 KB)\n        input_size = 100 * 1024  # 100 KB\n        input_stream = GeneratedInputStream(input_size)\n        output_stream = io.BytesIO()\n        result = parse_user_input(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(len(output_stream.getvalue()), input_size)\n\n    def test_exact_max_size(self):\n        # Test input exactly at the maximum allowed size (10 MB)\n        max_size = 10 * 1024 * 1024  # 10 MB\n        input_stream = GeneratedInputStream(max_size)\n        output_stream = io.BytesIO()\n        result = parse_user_input(input_stream, output_stream)\n        self.assertEqual(result, \"Input processed successfully\")\n        self.assertEqual(len(output_stream.getvalue()), max_size)\n\n    def test_exceed_max_size(self):\n        # Test input exceeding maximum size by 1 byte (10 MB + 1)\n        max_size = 10 * 1024 * 1024  # 10 MB\n        input_size = max_size + 1\n        input_stream = GeneratedInputStream(input_size)\n        output_stream = io.BytesIO()\n        result = parse_user_input(input_stream, output_stream)\n        self.assertEqual(result, \"User input exceeds the allowable size\")\n\n    def test_faulty_input_stream(self):\n        # Test when input stream raises an exception during read\n        input_stream = FaultyInputStream()\n        output_stream = io.BytesIO()\n        result = parse_user_input(input_stream, output_stream)\n        self.assertIsInstance(result, Exception)\n        self.assertEqual(str(result), \"Error processing input: Simulated read error\")\n\n    def test_faulty_output_stream(self):\n        # Test when output stream raises an exception during write\n        input_stream = io.BytesIO(b'test data')\n        output_stream = FaultyOutputStream()\n        result = parse_user_input(input_stream, output_stream)\n        self.assertIsInstance(result, Exception)\n        self.assertEqual(str(result), \"Error processing input: Simulated write error\")", "num_test_cases": 7, "task_id": "fc096060"}
{"test": "import unittest\nfrom unittest.mock import patch, MagicMock\nimport os\nimport tempfile\nimport requests\n\nclass TestDownloadLargeFile(unittest.TestCase):\n\n    @patch('requests.get')\n    def test_normal_download(self, mock_get):\n        \"\"\"Test successful download within size limit.\"\"\"\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = iter([b'chunk1', b'chunk2'])\n        mock_get.return_value.__enter__.return_value = mock_response\n        with tempfile.TemporaryDirectory() as temp_dir:\n            local_file = os.path.join(temp_dir, 'testfile')\n            result = download_large_file('http://example.com', local_file)\n            self.assertIsNone(result)\n            with open(local_file, 'rb') as f:\n                content = f.read()\n            self.assertEqual(content, b'chunk1chunk2')\n\n    @patch('requests.get')\n    def test_exact_size(self, mock_get):\n        \"\"\"Test download of exactly 20MB file.\"\"\"\n        chunk_size = 10 * 1024 * 1024\n        chunk1 = b'a' * chunk_size\n        chunk2 = b'b' * chunk_size\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = iter([chunk1, chunk2])\n        mock_get.return_value.__enter__.return_value = mock_response\n        with tempfile.TemporaryDirectory() as temp_dir:\n            local_file = os.path.join(temp_dir, 'testfile')\n            result = download_large_file('http://example.com', local_file)\n            self.assertIsNone(result)\n            with open(local_file, 'rb') as f:\n                content = f.read()\n            self.assertEqual(content, chunk1 + chunk2)\n            self.assertEqual(len(content), 20 * 1024 * 1024)\n\n    @patch('requests.get')\n    def test_exceed_size(self, mock_get):\n        \"\"\"Test file exceeding 20MB limit.\"\"\"\n        chunk1 = b'a' * (10 * 1024 * 1024)\n        chunk2 = b'b' * (10 * 1024 * 1024)\n        chunk3 = b'c' * 1\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = iter([chunk1, chunk2, chunk3])\n        mock_get.return_value.__enter__.return_value = mock_response\n        with tempfile.TemporaryDirectory() as temp_dir:\n            local_file = os.path.join(temp_dir, 'testfile')\n            result = download_large_file('http://example.com', local_file)\n            self.assertEqual(result, \"Downloaded file exceeds the allowable size limit\")\n            with open(local_file, 'rb') as f:\n                content = f.read()\n            self.assertEqual(content, chunk1 + chunk2)\n\n    @patch('requests.get')\n    def test_empty_file(self, mock_get):\n        \"\"\"Test downloading zero-length file.\"\"\"\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = iter([])\n        mock_get.return_value.__enter__.return_value = mock_response\n        with tempfile.TemporaryDirectory() as temp_dir:\n            local_file = os.path.join(temp_dir, 'testfile')\n            result = download_large_file('http://example.com', local_file)\n            self.assertIsNone(result)\n            self.assertTrue(os.path.exists(local_file))\n            self.assertEqual(os.path.getsize(local_file), 0)\n\n    @patch('requests.get')\n    @patch('builtins.open')\n    def test_io_error_open(self, mock_open, mock_get):\n        \"\"\"Test IOError when opening local file.\"\"\"\n        mock_open.side_effect = IOError(\"Disk full\")\n        mock_response = MagicMock()\n        mock_get.return_value.__enter__.return_value = mock_response\n        with tempfile.TemporaryDirectory() as temp_dir:\n            local_file = os.path.join(temp_dir, 'testfile')\n            result = download_large_file('http://example.com', local_file)\n            self.assertIsInstance(result, Exception)\n            self.assertTrue(str(result).startswith(\"Disk Error:\"))\n\n    @patch('requests.get')\n    def test_network_error(self, mock_get):\n        \"\"\"Test network connection error.\"\"\"\n        mock_get.side_effect = requests.exceptions.ConnectionError(\"Network problem\")\n        with tempfile.TemporaryDirectory() as temp_dir:\n            local_file = os.path.join(temp_dir, 'testfile')\n            result = download_large_file('http://example.com', local_file)\n            self.assertIsInstance(result, Exception)\n            self.assertTrue(str(result).startswith(\"Error downloading file:\"))\n\n    @patch('requests.get')\n    def test_generic_exception(self, mock_get):\n        \"\"\"Test generic exception during download.\"\"\"\n        mock_response = MagicMock()\n        mock_response.iter_content.side_effect = Exception(\"Unexpected error\")\n        mock_get.return_value.__enter__.return_value = mock_response\n        with tempfile.TemporaryDirectory() as temp_dir:\n            local_file = os.path.join(temp_dir, 'testfile')\n            result = download_large_file('http://example.com', local_file)\n            self.assertIsInstance(result, Exception)\n            self.assertTrue(str(result).startswith(\"Error downloading file:\"))\n\n    @patch('requests.get')\n    @patch('builtins.open')\n    def test_io_error_during_write(self, mock_open, mock_get):\n        \"\"\"Test IOError during file write operation.\"\"\"\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = iter([b'chunk1', b'chunk2'])\n        mock_get.return_value.__enter__.return_value = mock_response\n        mock_file = MagicMock()\n        mock_open.return_value.__enter__.return_value = mock_file\n        mock_file.write.side_effect = [None, IOError(\"Disk write error\")]\n        with tempfile.TemporaryDirectory() as temp_dir:\n            local_file = os.path.join(temp_dir, 'testfile')\n            result = download_large_file('http://example.com', local_file)\n            self.assertIsInstance(result, Exception)\n            self.assertTrue(str(result).startswith(\"Disk Error:\"))\n\n    @patch('requests.get')\n    def test_non_empty_then_empty_chunk(self, mock_get):\n        \"\"\"Test download ending with empty chunk.\"\"\"\n        mock_response = MagicMock()\n        mock_response.iter_content.return_value = iter([b'data', b''])\n        mock_get.return_value.__enter__.return_value = mock_response\n        with tempfile.TemporaryDirectory() as temp_dir:\n            local_file = os.path.join(temp_dir, 'testfile')\n            result = download_large_file('http://example.com', local_file)\n            self.assertIsNone(result)\n            with open(local_file, 'rb') as f:\n                content = f.read()\n            self.assertEqual(content, b'data')\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 9, "task_id": "abe36070"}
{"test": "import unittest\nimport io\nfrom solution import process_request\nimport solution\n\nclass TestProcessRequest(unittest.TestCase):\n    def setUp(self):\n        \"\"\"Save the original CHUNK_SIZE and set up common test data.\"\"\"\n        self.orig_chunk_size = solution.CHUNK_SIZE\n\n    def tearDown(self):\n        \"\"\"Restore the original CHUNK_SIZE after each test.\"\"\"\n        solution.CHUNK_SIZE = self.orig_chunk_size\n\n    def test_empty_stream(self):\n        \"\"\"Test processing an empty request stream.\"\"\"\n        solution.CHUNK_SIZE = 4\n        stream = io.BytesIO(b'')\n        result = process_request(stream)\n        self.assertEqual(result, b'')\n\n    def test_stream_smaller_than_chunk(self):\n        \"\"\"Test a stream smaller than CHUNK_SIZE.\"\"\"\n        solution.CHUNK_SIZE = 4\n        stream = io.BytesIO(b'abc')\n        result = process_request(stream)\n        self.assertEqual(result, b'')\n\n    def test_stream_exactly_one_chunk(self):\n        \"\"\"Test a stream exactly matching CHUNK_SIZE.\"\"\"\n        solution.CHUNK_SIZE = 4\n        stream = io.BytesIO(b'abcd')\n        result = process_request(stream)\n        self.assertEqual(result, b'')\n\n    def test_stream_multiple_chunks(self):\n        \"\"\"Test a stream requiring multiple chunks.\"\"\"\n        solution.CHUNK_SIZE = 4\n        stream = io.BytesIO(b'abcdefghij')\n        result = process_request(stream)\n        self.assertEqual(result, b'')\n\n    def test_stream_variable_chunk_sizes(self):\n        \"\"\"Test a stream with chunks of varying sizes.\"\"\"\n        solution.CHUNK_SIZE = 4\n        chunks = [b'123', b'45', b'6789', b'0']\n        class CustomStream:\n            def read(self, size):\n                if chunks:\n                    return chunks.pop(0)\n                return b''\n        stream = CustomStream()\n        result = process_request(stream)\n        self.assertEqual(result, b'')\n\n    def test_stream_15mb(self):\n        \"\"\"Test a stream under the 16MB limit.\"\"\"\n        solution.CHUNK_SIZE = 1024 * 1024  # 1MB\n        data = b'a' * (15 * 1024 * 1024)   # 15MB\n        stream = io.BytesIO(data)\n        result = process_request(stream)\n        self.assertEqual(result, b'')\n\n    def test_stream_exactly_16mb(self):\n        \"\"\"Test a stream exactly at the 16MB limit.\"\"\"\n        solution.CHUNK_SIZE = 1024 * 1024  # 1MB\n        data = b'a' * (16 * 1024 * 1024)   # 16MB\n        stream = io.BytesIO(data)\n        result = process_request(stream)\n        self.assertEqual(result, b'')\n\n    def test_stream_exceeds_16mb(self):\n        \"\"\"Test a stream exceeding the 16MB limit.\"\"\"\n        solution.CHUNK_SIZE = 1024 * 1024  # 1MB\n        data = b'a' * (16 * 1024 * 1024 + 1)   # 16MB + 1 byte\n        stream = io.BytesIO(data)\n        result = process_request(stream)\n        self.assertIsInstance(result, Exception)\n        self.assertEqual(str(result), \"Error: Payload Too Large\")\n\n    def test_stream_raises_io_error(self):\n        \"\"\"Test a stream that raises an IOError during read.\"\"\"\n        solution.CHUNK_SIZE = 4\n        class FaultyStream:\n            def read(self, size):\n                raise IOError(\"Simulated read error\")\n        stream = FaultyStream()\n        result = process_request(stream)\n        self.assertIsInstance(result, Exception)\n        self.assertEqual(str(result), \"Error: Simulated read error\")", "num_test_cases": 10, "task_id": "6a0aed20"}
{"test": "import unittest\nimport json\nimport xml.etree.ElementTree as ET\n\nclass TestDeserializeData(unittest.TestCase):\n\n    def test_valid_json(self):\n        # Test deserialization of valid JSON data.\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = deserialize_data(data, 'json')\n        self.assertEqual(result, {'name': 'Alice', 'age': 30})\n\n    def test_valid_xml(self):\n        # Test deserialization of valid XML data (flat structure).\n        data = b'<person><name>Alice</name><age>30</age></person>'\n        result = deserialize_data(data, 'xml')\n        self.assertEqual(result, {'name': 'Alice', 'age': '30'})\n\n    def test_json_empty(self):\n        # Test deserialization of empty data for JSON (should fail).\n        data = b''\n        with self.assertRaises(json.JSONDecodeError):\n            deserialize_data(data, 'json')\n\n    def test_xml_empty(self):\n        # Test deserialization of empty data for XML (should fail).\n        data = b''\n        with self.assertRaises(ET.ParseError):\n            deserialize_data(data, 'xml')\n\n    def test_unsupported_format(self):\n        # Test an unsupported format (yaml).\n        data = b'...'\n        with self.assertRaises(ValueError) as context:\n            deserialize_data(data, 'yaml')\n        self.assertEqual(str(context.exception), 'Format \\'yaml\\' is not supported.')\n\n    def test_pickle_format(self):\n        # Test that pickle format is explicitly blocked.\n        data = b'...'\n        with self.assertRaises(ValueError) as context:\n            deserialize_data(data, 'pickle')\n        self.assertEqual(str(context.exception), 'Deserialization using pickle is prohibited due to security concerns.')\n\n    def test_non_string_format(self):\n        # Test non-string format argument.\n        data = b'{}'\n        with self.assertRaises(ValueError) as context:\n            deserialize_data(data, 123)\n        self.assertEqual(str(context.exception), 'Format \\'123\\' is not supported.')\n\n    def test_uppercase_format(self):\n        # Test format string in uppercase (should be unsupported).\n        data = b'{}'\n        with self.assertRaises(ValueError) as context:\n            deserialize_data(data, 'JSON')\n        self.assertEqual(str(context.exception), 'Format \\'JSON\\' is not supported.')\n\n    def test_format_with_whitespace(self):\n        # Test format string with surrounding whitespace (should be unsupported).\n        data = b'{}'\n        with self.assertRaises(ValueError) as context:\n            deserialize_data(data, ' json ')\n        self.assertEqual(str(context.exception), 'Format \\' json \\' is not supported.')\n\n    def test_xml_invalid_structure(self):\n        # Test XML data that is not well-formed (unclosed tag).\n        data = b'<root>'\n        with self.assertRaises(ET.ParseError):\n            deserialize_data(data, 'xml')\n\n    def test_json_invalid_structure(self):\n        # Test invalid JSON data.\n        data = b'{invalid}'\n        with self.assertRaises(json.JSONDecodeError):\n            deserialize_data(data, 'json')\n\n    def test_xml_duplicate_tags(self):\n        # Test XML with duplicate tags (should take the last one).\n        data = b'<root><item>1</item><item>2</item></root>'\n        result = deserialize_data(data, 'xml')\n        self.assertEqual(result, {'item': '2'})\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 12, "task_id": "59493053"}
{"test": "import unittest\n\nclass TestDecodeSerializedData(unittest.TestCase):\n\n    def test_json_valid_dict(self):\n        # Test JSON deserialization with a valid dictionary\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = decode_serialized_data(data, 'json')\n        self.assertEqual(result, {'name': 'Alice', 'age': 30})\n\n    def test_json_valid_list(self):\n        # Test JSON deserialization with a valid list\n        data = b'[1, 2, 3]'\n        result = decode_serialized_data(data, 'json')\n        self.assertEqual(result, [1, 2, 3])\n\n    def test_xml_valid_one_element(self):\n        # Test XML deserialization with one child element\n        data = b'<root><name>Alice</name></root>'\n        result = decode_serialized_data(data, 'xml')\n        self.assertEqual(result, {'name': 'Alice'})\n\n    def test_xml_valid_multiple_elements(self):\n        # Test XML deserialization with multiple child elements\n        data = b'<root><name>Alice</name><age>30</age></root>'\n        result = decode_serialized_data(data, 'xml')\n        self.assertEqual(result, {'name': 'Alice', 'age': '30'})\n\n    def test_xml_duplicate_tags(self):\n        # Test XML with duplicate tags (last occurrence should overwrite)\n        data = b'<root><item>apple</item><item>banana</item></root>'\n        result = decode_serialized_data(data, 'xml')\n        self.assertEqual(result, {'item': 'banana'})\n\n    def test_xml_element_with_no_text(self):\n        # Test XML element with no text content (should be None)\n        data = b'<root><a></a><b>text</b></root>'\n        result = decode_serialized_data(data, 'xml')\n        self.assertEqual(result, {'a': None, 'b': 'text'})\n\n    def test_pickle_method_raises_valueerror(self):\n        # Test that 'pickle' method raises ValueError with security message\n        with self.assertRaises(ValueError) as context:\n            decode_serialized_data(b'anydata', 'pickle')\n        self.assertEqual(str(context.exception), \"Deserialization using pickle is prohibited due to security concerns.\")\n\n    def test_unsupported_method_raises_valueerror(self):\n        # Test unsupported method (yaml) raises ValueError\n        with self.assertRaises(ValueError) as context:\n            decode_serialized_data(b'anydata', 'yaml')\n        self.assertEqual(str(context.exception), \"Format 'yaml' is not supported.\")\n\n    def test_method_none_raises_valueerror(self):\n        # Test method as None raises ValueError\n        with self.assertRaises(ValueError) as context:\n            decode_serialized_data(b'anydata', None)\n        self.assertEqual(str(context.exception), \"Format 'None' is not supported.\")\n\n    def test_method_integer_raises_valueerror(self):\n        # Test method as integer raises ValueError\n        with self.assertRaises(ValueError) as context:\n            decode_serialized_data(b'anydata', 123)\n        self.assertEqual(str(context.exception), \"Format '123' is not supported.\")\n\n    def test_method_empty_string_raises_valueerror(self):\n        # Test method as empty string raises ValueError\n        with self.assertRaises(ValueError) as context:\n            decode_serialized_data(b'anydata', '')\n        self.assertEqual(str(context.exception), \"Format '' is not supported.\")\n\n    def test_default_method_json(self):\n        # Test default method (json) with valid data\n        data = b'{\"key\": \"value\"}'\n        result = decode_serialized_data(data)\n        self.assertEqual(result, {'key': 'value'})\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 12, "task_id": "84d3c8b6"}
{"test": "import unittest\n\nclass TestObjectifyData(unittest.TestCase):\n    \n    def test_valid_json(self):\n        # Test deserialization with valid JSON data\n        data = b'{\\\"name\\\": \\\"Alice\\\", \\\"age\\\": 30}'\n        result = objectify_data(data, 'json')\n        self.assertEqual(result, {'name': 'Alice', 'age': 30})\n    \n    def test_valid_xml(self):\n        # Test deserialization with valid XML data\n        data = b'<root><name>Alice</name><age>30</age></root>'\n        result = objectify_data(data, 'xml')\n        self.assertEqual(result, {'name': 'Alice', 'age': '30'})\n    \n    def test_json_empty(self):\n        # Test deserialization with empty JSON object\n        data = b'{}'\n        result = objectify_data(data, 'json')\n        self.assertEqual(result, {})\n    \n    def test_xml_empty(self):\n        # Test deserialization with empty XML\n        data = b'<root></root>'\n        result = objectify_data(data, 'xml')\n        self.assertEqual(result, {})\n    \n    def test_xml_nested(self):\n        # Test XML with nested elements (only direct children)\n        data = b'<root><person><name>Alice</name><age>30</age></person></root>'\n        result = objectify_data(data, 'xml')\n        self.assertEqual(result, {'person': None})\n    \n    def test_pickle_blocked(self):\n        # Test that pickle format raises ValueError\n        data = b'any_data'\n        with self.assertRaises(ValueError) as context:\n            objectify_data(data, 'pickle')\n        self.assertEqual(str(context.exception), \"Deserialization using pickle is prohibited due to security concerns.\")\n    \n    def test_unsupported_format(self):\n        # Test unsupported format (yaml)\n        data = b''\n        with self.assertRaises(ValueError) as context:\n            objectify_data(data, 'yaml')\n        self.assertEqual(str(context.exception), \"Format 'yaml' is not supported.\")\n    \n    def test_none_format(self):\n        # Test None as method_name\n        data = b''\n        with self.assertRaises(ValueError) as context:\n            objectify_data(data, None)\n        self.assertEqual(str(context.exception), \"Format 'None' is not supported.\")\n    \n    def test_uppercase_json(self):\n        # Test case sensitivity (uppercase JSON)\n        data = b'{}'\n        with self.assertRaises(ValueError) as context:\n            objectify_data(data, 'JSON')\n        self.assertEqual(str(context.exception), \"Format 'JSON' is not supported.\")\n    \n    def test_xml_mixed_content(self):\n        # Test XML element with text and nested elements\n        data = b'<root><a>Text <b>content</b></a></root>'\n        result = objectify_data(data, 'xml')\n        self.assertEqual(result, {'a': 'Text '})\n", "num_test_cases": 10, "task_id": "4225a5a8"}
{"test": "import unittest\\nfrom solution import deserialize_data\\n\\nclass TestDeserializeData(unittest.TestCase):\\n    def test_case_1(self):\\n        # Test with default format (json) and a simple object.\\n        raw_data = b'{\\\"key\\\": \\\"value\\\"}'\\n        expected = {\\\"key\\\": \\\"value\\\"}\\n        result = deserialize_data(raw_data)\\n        self.assertEqual(result, expected)\\n\\n    def test_case_2(self):\\n        # Test with explicit json and a non-empty object.\\n        raw_data = b'{\\\"name\\\": \\\"Alice\\\", \\\"age\\\": 30}'\\n        expected = {\\\"name\\\": \\\"Alice\\\", \\\"age\\\": 30}\\n        result = deserialize_data(raw_data, \\\"json\\\")\\n        self.assertEqual(result, expected)\\n\\n    def test_case_3(self):\\n        # Test with json and an empty object.\\n        raw_data = b'{}'\\n        expected = {}\\n        result = deserialize_data(raw_data, \\\"json\\\")\\n        self.assertEqual(result, expected)\\n\\n    def test_case_4(self):\\n        # Test with json and an array.\\n        raw_data = b'[1, 2, 3]'\\n        expected = [1, 2, 3]\\n        result = deserialize_data(raw_data, \\\"json\\\")\\n        self.assertEqual(result, expected)\\n\\n    def test_case_5(self):\\n        # Test with xml and one child.\\n        raw_data = b'<root><a>text</a></root>'\\n        expected = {'a': 'text'}\\n        result = deserialize_data(raw_data, \\\"xml\\\")\\n        self.assertEqual(result, expected)\\n\\n    def test_case_6(self):\\n        # Test with xml and multiple children.\\n        raw_data = b'<root><a>text</a><b>another</b></root>'\\n        expected = {'a': 'text', 'b': 'another'}\\n        result = deserialize_data(raw_data, \\\"xml\\\")\\n        self.assertEqual(result, expected)\\n\\n    def test_case_7(self):\\n        # Test with xml and empty element (root has no children).\\n        raw_data = b'<root></root>'\\n        expected = {}\\n        result = deserialize_data(raw_data, \\\"xml\\\")\\n        self.assertEqual(result, expected)\\n\\n    def test_case_8(self):\\n        # Test with xml that has a nested element: the child element has no direct text.\\n        raw_data = b'<root><a><b>text</b></a></root>'\\n        expected = {'a': None}\\n        result = deserialize_data(raw_data, \\\"xml\\\")\\n        self.assertEqual(result, expected)\\n\\n    def test_case_9(self):\\n        # Test with pickle - should raise ValueError.\\n        with self.assertRaises(ValueError) as context:\\n            deserialize_data(b'anything', \\\"pickle\\\")\\n        self.assertEqual(str(context.exception), \\\"Deserialization using pickle is prohibited due to security concerns.\\\")\\n\\n    def test_case_10(self):\\n        # Test with an unsupported format.\\n        with self.assertRaises(ValueError) as context:\\n            deserialize_data(b'anything', \\\"yaml\\\")\\n        self.assertEqual(str(context.exception), \\\"Format 'yaml' is not supported.\\\")\\n\\nif __name__ == '__main__':\\n    unittest.main()", "num_test_cases": 10, "task_id": "2ed054cc"}
{"test": "import unittest\nimport json\n\nclass TestLoadSerializedData(unittest.TestCase):\n    def test_json_happy_path(self):\n        \"\"\"Test JSON deserialization with valid data.\"\"\"\n        bytes_data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = load_serialized_data(bytes_data, 'json')\n        self.assertEqual(result, {\"name\": \"Alice\", \"age\": 30})\n\n    def test_json_default_format(self):\n        \"\"\"Test JSON deserialization using default format.\"\"\"\n        bytes_data = b'{\"key\": \"value\"}'\n        result = load_serialized_data(bytes_data)\n        self.assertEqual(result, {\"key\": \"value\"})\n\n    def test_json_empty_bytes(self):\n        \"\"\"Test JSON deserialization with empty bytes.\"\"\"\n        with self.assertRaises(json.JSONDecodeError):\n            load_serialized_data(b'', 'json')\n\n    def test_xml_deserialization(self):\n        \"\"\"Test XML deserialization (function expects string but gets bytes).\"\"\"\n        bytes_data = b'<root><name>Alice</name></root>'\n        with self.assertRaises(TypeError):\n            load_serialized_data(bytes_data, 'xml')\n\n    def test_pickle_format(self):\n        \"\"\"Test explicit pickle format prohibition.\"\"\"\n        with self.assertRaises(ValueError) as context:\n            load_serialized_data(b'any_data', 'pickle')\n        self.assertEqual(str(context.exception), \"Deserialization using pickle is prohibited due to security concerns.\")\n\n    def test_unsupported_format(self):\n        \"\"\"Test unsupported data format.\"\"\"\n        with self.assertRaises(ValueError) as context:\n            load_serialized_data(b'data', 'yaml')\n        self.assertEqual(str(context.exception), \"Format 'yaml' is not supported.\")\n\n    def test_empty_format_string(self):\n        \"\"\"Test empty format string.\"\"\"\n        with self.assertRaises(ValueError) as context:\n            load_serialized_data(b'data', '')\n        self.assertEqual(str(context.exception), \"Format '' is not supported.\")\n\n    def test_none_format(self):\n        \"\"\"Test None as format.\"\"\"\n        with self.assertRaises(ValueError) as context:\n            load_serialized_data(b'data', None)\n        self.assertEqual(str(context.exception), \"Format 'None' is not supported.\")\n\n    def test_non_string_format(self):\n        \"\"\"Test non-string format type.\"\"\"\n        with self.assertRaises(ValueError) as context:\n            load_serialized_data(b'data', 123)\n        self.assertEqual(str(context.exception), \"Format '123' is not supported.\")", "num_test_cases": 9, "task_id": "ded0eddb"}
{"test": "import unittest\nimport json\nimport xml.etree.ElementTree as ET\n\nclass TestCases(unittest.TestCase):\n    def test_case_1(self):\n        # Test valid JSON deserialization\n        result = safe_deserialize(b'{\"name\": \"John\", \"age\": 30}', 'json')\n        self.assertEqual(result, {'name': 'John', 'age': 30})\n    \n    def test_case_2(self):\n        # Test valid XML deserialization with distinct tags\n        data = b'<root><name>John</name><age>30</age></root>'\n        result = safe_deserialize(data, 'xml')\n        self.assertEqual(result, {'name': 'John', 'age': '30'})\n    \n    def test_case_3(self):\n        # Test XML with duplicate tags (last occurrence should persist)\n        data = b'<root><item>first</item><item>second</item></root>'\n        result = safe_deserialize(data, 'xml')\n        self.assertEqual(result, {'item': 'second'})\n    \n    def test_case_4(self):\n        # Test empty bytes input for JSON (should raise ValueError)\n        with self.assertRaises(ValueError):\n            safe_deserialize(b'', 'json')\n    \n    def test_case_5(self):\n        # Test empty bytes input for XML (should raise ET.ParseError)\n        with self.assertRaises(ET.ParseError):\n            safe_deserialize(b'', 'xml')\n    \n    def test_case_6(self):\n        # Test pickle format (should raise ValueError with specific message)\n        with self.assertRaises(ValueError) as context:\n            safe_deserialize(b'any_data', 'pickle')\n        self.assertEqual(str(context.exception), \"Deserialization using pickle is prohibited due to security concerns.\")\n    \n    def test_case_7(self):\n        # Test unsupported format (yaml) (should raise ValueError)\n        with self.assertRaises(ValueError) as context:\n            safe_deserialize(b'any_data', 'yaml')\n        self.assertEqual(str(context.exception), \"Format 'yaml' is not supported.\")\n    \n    def test_case_8(self):\n        # Test invalid JSON data (should raise ValueError)\n        with self.assertRaises(ValueError):\n            safe_deserialize(b'{invalid_json}', 'json')\n    \n    def test_case_9(self):\n        # Test invalid XML data (should raise ET.ParseError)\n        with self.assertRaises(ET.ParseError):\n            safe_deserialize(b'<root><child></root>', 'xml')\n    \n    def test_case_10(self):\n        # Test None input for JSON (should raise TypeError)\n        with self.assertRaises(TypeError):\n            safe_deserialize(None, 'json')\n    \n    def test_case_11(self):\n        # Test None input for XML (should raise TypeError)\n        with self.assertRaises(TypeError):\n            safe_deserialize(None, 'xml')\n    \n    def test_case_12(self):\n        # Test integer allowed_format (should raise ValueError)\n        with self.assertRaises(ValueError) as context:\n            safe_deserialize(b'data', 123)\n        self.assertEqual(str(context.exception), \"Format '123' is not supported.\")\n    \n    def test_case_13(self):\n        # Test very long unsupported format string (should raise ValueError)\n        long_format = 'a' * 1000\n        with self.assertRaises(ValueError) as context:\n            safe_deserialize(b'data', long_format)\n        self.assertEqual(str(context.exception), \"Format '\" + long_format + \"' is not supported.\")\n", "num_test_cases": 13, "task_id": "ecc887b3"}
{"test": "import unittest\nimport json\nimport xml.etree.ElementTree as ET\n\nclass TestDeserializeData(unittest.TestCase):\n    \n    def test_valid_json_simple(self):\n        # Test JSON deserialization with a simple key-value pair\n        input_data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = deserialize_data(input_data, 'json')\n        self.assertEqual(result, {\"name\": \"Alice\", \"age\": 30})\n    \n    def test_valid_json_complex(self):\n        # Test JSON deserialization with nested structures\n        input_data = b'{\"person\": {\"name\": \"Bob\", \"hobbies\": [\"reading\", \"swimming\"]}}'\n        result = deserialize_data(input_data, 'json')\n        expected = {\"person\": {\"name\": \"Bob\", \"hobbies\": [\"reading\", \"swimming\"]}}\n        self.assertEqual(result, expected)\n    \n    def test_invalid_json(self):\n        # Test with invalid JSON data (should raise JSONDecodeError which is a ValueError)\n        input_data = b'invalid json'\n        with self.assertRaises(ValueError):\n            deserialize_data(input_data, 'json')\n    \n    def test_json_empty_input(self):\n        # Test with empty bytes for JSON (invalid)\n        input_data = b''\n        with self.assertRaises(ValueError):\n            deserialize_data(input_data, 'json')\n    \n    def test_valid_xml_simple(self):\n        # Test XML deserialization with a single element\n        input_data = b'<root><name>Charlie</name></root>'\n        result = deserialize_data(input_data, 'xml')\n        self.assertEqual(result, {\"name\": \"Charlie\"})\n    \n    def test_valid_xml_multiple_unique(self):\n        # Test XML with multiple unique children\n        input_data = b'<root><name>Dana</name><age>25</age><city>Paris</city></root>'\n        result = deserialize_data(input_data, 'xml')\n        expected = {\"name\": \"Dana\", \"age\": \"25\", \"city\": \"Paris\"}\n        self.assertEqual(result, expected)\n    \n    def test_valid_xml_duplicate_tags(self):\n        # Test XML with duplicate tags (last one should overwrite)\n        input_data = b'<root><item>First</item><item>Second</item></root>'\n        result = deserialize_data(input_data, 'xml')\n        self.assertEqual(result, {\"item\": \"Second\"})\n    \n    def test_xml_empty_element(self):\n        # Test XML element with no text content\n        input_data = b'<root><empty></empty></root>'\n        result = deserialize_data(input_data, 'xml')\n        self.assertEqual(result, {\"empty\": None})\n    \n    def test_xml_invalid_data(self):\n        # Test invalid XML structure\n        input_data = b'<root><unclosed>'\n        with self.assertRaises(ET.ParseError):\n            deserialize_data(input_data, 'xml')\n    \n    def test_xml_empty_input(self):\n        # Test empty bytes for XML (invalid)\n        input_data = b''\n        with self.assertRaises(ET.ParseError):\n            deserialize_data(input_data, 'xml')\n    \n    def test_unsupported_format_yaml(self):\n        # Test unsupported 'yaml' format\n        with self.assertRaises(ValueError) as context:\n            deserialize_data(b'any data', 'yaml')\n        self.assertEqual(str(context.exception), \"Format 'yaml' is not supported.\")\n    \n    def test_unsupported_format_csv(self):\n        # Test unsupported 'csv' format\n        with self.assertRaises(ValueError) as context:\n            deserialize_data(b'any data', 'csv')\n        self.assertEqual(str(context.exception), \"Format 'csv' is not supported.\")\n    \n    def test_pickle_prohibited(self):\n        # Test that pickle format is explicitly prohibited\n        with self.assertRaises(ValueError) as context:\n            deserialize_data(b'any data', 'pickle')\n        self.assertEqual(str(context.exception), \"Deserialization using pickle is prohibited due to security concerns.\")\n", "num_test_cases": 13, "task_id": "e45e19a3"}
{"test": "import unittest\nimport xml.etree.ElementTree as ET\n\nclass TestDataToObject(unittest.TestCase):\n\n    def test_json_valid_dict(self):\n        # Test json with a valid dictionary\n        byte_data = b'{\"key\": \"value\"}'\n        result = data_to_object(byte_data, 'json')\n        self.assertEqual(result, {'key': 'value'})\n\n    def test_json_integer(self):\n        # Test json with an integer\n        byte_data = b'123'\n        result = data_to_object(byte_data, 'json')\n        self.assertEqual(result, 123)\n\n    def test_json_list(self):\n        # Test json with a list\n        byte_data = b'[1, 2, 3]'\n        result = data_to_object(byte_data, 'json')\n        self.assertEqual(result, [1, 2, 3])\n\n    def test_json_empty_bytes(self):\n        # Test json with empty bytes\n        byte_data = b''\n        with self.assertRaises(ValueError):\n            data_to_object(byte_data, 'json')\n\n    def test_json_none(self):\n        # Test json with None for byte_data\n        byte_data = None\n        with self.assertRaises(TypeError):\n            data_to_object(byte_data, 'json')\n\n    def test_xml_simple(self):\n        # Test xml with a simple element\n        byte_data = b'<root><name>John</name></root>'\n        result = data_to_object(byte_data, 'xml')\n        self.assertEqual(result, {'name': 'John'})\n\n    def test_xml_multiple_children(self):\n        # Test xml with multiple children\n        byte_data = b'<root><id>1</id><name>John</name></root>'\n        result = data_to_object(byte_data, 'xml')\n        self.assertEqual(result, {'id': '1', 'name': 'John'})\n\n    def test_xml_empty_bytes(self):\n        # Test xml with empty bytes\n        byte_data = b''\n        with self.assertRaises(ET.ParseError):\n            data_to_object(byte_data, 'xml')\n\n    def test_xml_none(self):\n        # Test xml with None for byte_data\n        byte_data = None\n        with self.assertRaises(TypeError):\n            data_to_object(byte_data, 'xml')\n\n    def test_pickle(self):\n        # Test that pickle format raises ValueError\n        byte_data = b'any_data'\n        with self.assertRaisesRegex(ValueError, 'Deserialization using pickle is prohibited due to security concerns.'):\n            data_to_object(byte_data, 'pickle')\n\n    def test_unsupported_format(self):\n        # Test unsupported format\n        byte_data = b'anything'\n        with self.assertRaises(ValueError) as context:\n            data_to_object(byte_data, 'invalid_format')\n        self.assertEqual(str(context.exception), 'Format \\'invalid_format\\' is not supported.')\n\n    def test_none_byte_data_unsupported_format(self):\n        # Test None for byte_data with unsupported format\n        byte_data = None\n        with self.assertRaises(ValueError) as context:\n            data_to_object(byte_data, 'invalid_format')\n        self.assertEqual(str(context.exception), 'Format \\'invalid_format\\' is not supported.')\n\n    def test_default_encoding(self):\n        # Test default encoding (json) with valid data\n        byte_data = b'{\"key\": \"value\"}'\n        result = data_to_object(byte_data)\n        self.assertEqual(result, {'key': 'value'})\n\n    def test_uppercase_json_unsupported(self):\n        # Test that 'JSON' (uppercase) is not supported\n        byte_data = b'{\"key\": \"value\"}'\n        with self.assertRaises(ValueError):\n            data_to_object(byte_data, 'JSON')\n\n    def test_uppercase_xml_unsupported(self):\n        # Test that 'Xml' (mixed case) is not supported\n        byte_data = b'<root/>'\n        with self.assertRaises(ValueError):\n            data_to_object(byte_data, 'Xml')\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 15, "task_id": "248d9c1f"}
{"test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_json_simple_dict(self):\n        \"\"\"Test JSON deserialization with a simple dictionary\"\"\"\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = bytes_to_obj(data, \"json\")\n        self.assertEqual(result, {\"name\": \"Alice\", \"age\": 30})\n\n    def test_json_list(self):\n        \"\"\"Test JSON deserialization with a list\"\"\"\n        data = b'[1, 2, 3]'\n        result = bytes_to_obj(data, \"json\")\n        self.assertEqual(result, [1, 2, 3])\n\n    def test_json_empty_dict(self):\n        \"\"\"Test JSON deserialization with an empty dictionary\"\"\"\n        data = b'{}'\n        result = bytes_to_obj(data, \"json\")\n        self.assertEqual(result, {})\n\n    def test_xml_simple(self):\n        \"\"\"Test XML deserialization with simple child elements\"\"\"\n        data = b'<root><name>Alice</name><age>30</age></root>'\n        result = bytes_to_obj(data, \"xml\")\n        self.assertEqual(result, {\"name\": \"Alice\", \"age\": \"30\"})\n\n    def test_xml_child_without_text(self):\n        \"\"\"Test XML deserialization with a self-closing child element\"\"\"\n        data = b'<root><name>Alice</name><profile/></root>'\n        result = bytes_to_obj(data, \"xml\")\n        self.assertEqual(result, {\"name\": \"Alice\", \"profile\": None})\n\n    def test_xml_empty_children(self):\n        \"\"\"Test XML deserialization with no child elements\"\"\"\n        data = b'<root></root>'\n        result = bytes_to_obj(data, \"xml\")\n        self.assertEqual(result, {})\n\n    def test_xml_nested_element(self):\n        \"\"\"Test XML deserialization with nested elements and text\"\"\"\n        data = b'<root><a>text</a><b>before<c>inside</c>after</b></root>'\n        result = bytes_to_obj(data, \"xml\")\n        self.assertEqual(result, {\"a\": \"text\", \"b\": \"before\"})\n\n    def test_pickle_format(self):\n        \"\"\"Test explicit prohibition of pickle deserialization\"\"\"\n        with self.assertRaises(ValueError) as context:\n            bytes_to_obj(b'any', \"pickle\")\n        self.assertEqual(str(context.exception), \"Deserialization using pickle is prohibited due to security concerns.\")\n\n    def test_unsupported_format(self):\n        \"\"\"Test unsupported format (yaml)\"\"\"\n        with self.assertRaises(ValueError) as context:\n            bytes_to_obj(b'any', \"yaml\")\n        self.assertEqual(str(context.exception), \"Format 'yaml' is not supported.\")\n\n    def test_none_format(self):\n        \"\"\"Test None as format\"\"\"\n        with self.assertRaises(ValueError) as context:\n            bytes_to_obj(b'any', None)\n        self.assertEqual(str(context.exception), \"Format 'None' is not supported.\")\n\n    def test_default_format(self):\n        \"\"\"Test default JSON deserialization without format specification\"\"\"\n        data = b'{\"key\": \"value\"}'\n        result = bytes_to_obj(data)\n        self.assertEqual(result, {\"key\": \"value\"})", "num_test_cases": 11, "task_id": "f2dfe127"}
{"test": "import unittest\\nimport json\\n\\nclass TestRecoverObj(unittest.TestCase):\\n    def test_json_happy_path(self):\\n        # Test valid JSON data\\n        data = b'{\\\"name\\\": \\\"Alice\\\", \\\"age\\\": 30}'\\n        result = recover_obj(data, \\\"json\\\")\\n        self.assertEqual(result, {\\\"name\\\": \\\"Alice\\\", \\\"age\\\": 30})\\n\\n    def test_csv_happy_path(self):\\n        # Test valid CSV data\\n        data = b'id,name\\\\n1,Alice\\\\n2,Bob'\\n        result = recover_obj(data, \\\"csv\\\")\\n        self.assertEqual(result, [[\\\"id\\\", \\\"name\\\"], [\\\"1\\\", \\\"Alice\\\"], [\\\"2\\\", \\\"Bob\\\"]])\\n\\n    def test_json_empty_bytes(self):\\n        # Test empty bytes input for JSON\\n        with self.assertRaises(json.JSONDecodeError):\\n            recover_obj(b'', \\\"json\\\")\\n\\n    def test_csv_empty_bytes(self):\\n        # Test empty bytes input for CSV\\n        result = recover_obj(b'', \\\"csv\\\")\\n        self.assertEqual(result, [])\\n\\n    def test_json_none_input(self):\\n        # Test None input for JSON\\n        with self.assertRaises(TypeError):\\n            recover_obj(None, \\\"json\\\")\\n\\n    def test_csv_none_input(self):\\n        # Test None input for CSV\\n        with self.assertRaises(AttributeError):\\n            recover_obj(None, \\\"csv\\\")\\n\\n    def test_pickle_method(self):\\n        # Test pickle method raises ValueError\\n        with self.assertRaises(ValueError) as context:\\n            recover_obj(b'any_data', \\\"pickle\\\")\\n        self.assertEqual(str(context.exception), \\\"Deserialization with pickle is not allowed due to security vulnerabilities.\\\")\\n\\n    def test_unsupported_method(self):\\n        # Test unsupported method raises ValueError\\n        with self.assertRaises(ValueError) as context:\\n            recover_obj(b'any_data', \\\"yaml\\\")\\n        self.assertEqual(str(context.exception), \\\"Unsupported serialization method: yaml\\\")\\n\\n    def test_pickle_none_input(self):\\n        # Test None input with pickle method\\n        with self.assertRaises(ValueError):\\n            recover_obj(None, \\\"pickle\\\")\\n\\n    def test_unsupported_none_input(self):\\n        # Test None input with unsupported method\\n        with self.assertRaises(ValueError):\\n            recover_obj(None, \\\"xml\\\")\\n\\n    def test_default_json(self):\\n        # Test default method (JSON) without specifying\\n        data = b'{\\\"key\\\": \\\"value\\\"}'\\n        result = recover_obj(data)\\n        self.assertEqual(result, {\\\"key\\\": \\\"value\\\"})\\n\\nif __name__ == '__main__':\\n    unittest.main()", "num_test_cases": 11, "task_id": "72d22631"}
{"test": "import unittest\n\nclass TestLoadObject(unittest.TestCase):\n\n    def test_json_dict(self):\n        # Test JSON deserialization with a dictionary\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = load_object(data, \"json\")\n        self.assertIsInstance(result, dict)\n        self.assertEqual(result, {\"name\": \"Alice\", \"age\": 30})\n\n    def test_json_list(self):\n        # Test JSON deserialization with a list\n        data = b'[1, 2, 3]'\n        result = load_object(data, \"json\")\n        self.assertIsInstance(result, list)\n        self.assertEqual(result, [1, 2, 3])\n\n    def test_json_string(self):\n        # Test JSON deserialization with a string\n        data = b'\"hello\"'\n        result = load_object(data, \"json\")\n        self.assertIsInstance(result, str)\n        self.assertEqual(result, \"hello\")\n\n    def test_json_empty(self):\n        # Test JSON deserialization with empty bytes\n        data = b''\n        with self.assertRaises(ValueError):\n            load_object(data, \"json\")\n\n    def test_json_invalid(self):\n        # Test JSON deserialization with invalid data\n        data = b'invalid'\n        with self.assertRaises(ValueError):\n            load_object(data, \"json\")\n\n    def test_csv_valid(self):\n        # Test CSV deserialization with valid data (multiple rows)\n        data = b'''id,name\\n1,Alice'''\n        result = load_object(data, \"csv\")\n        expected = [[\"id\", \"name\"], [\"1\", \"Alice\"]]\n        self.assertEqual(result, expected)\n\n    def test_csv_empty(self):\n        # Test CSV deserialization with empty data\n        data = b''\n        result = load_object(data, \"csv\")\n        self.assertEqual(result, [])\n\n    def test_pickle_disallowed(self):\n        # Test that pickle deserialization raises ValueError\n        data = b'anything'\n        with self.assertRaises(ValueError) as context:\n            load_object(data, \"pickle\")\n        self.assertEqual(str(context.exception), \"Deserialization with pickle is not allowed due to security vulnerabilities.\")\n\n    def test_unsupported_method_string(self):\n        # Test unsupported deserialization method (string)\n        data = b'data'\n        with self.assertRaises(ValueError) as context:\n            load_object(data, \"xml\")\n        self.assertEqual(str(context.exception), \"Unsupported serialization method: xml\")\n\n    def test_unsupported_method_non_string(self):\n        # Test unsupported deserialization method (non-string)\n        data = b'data'\n        with self.assertRaises(ValueError) as context:\n            load_object(data, 123)\n        self.assertEqual(str(context.exception), \"Unsupported serialization method: 123\")\n\nif __name__ == \"__main__\":\n    unittest.main()", "num_test_cases": 10, "task_id": "316ec039"}
{"test": "import unittest\nimport json\n\nclass TestDeserializeObj(unittest.TestCase):\n\n    def test_json_dict(self):\n        # Test JSON with valid dictionary data\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = deserialize_obj(data, \"json\")\n        self.assertEqual(result, {'name': 'Alice', 'age': 30})\n\n    def test_json_list(self):\n        # Test JSON with valid list data\n        data = b'[1, 2, 3]'\n        result = deserialize_obj(data, \"json\")\n        self.assertEqual(result, [1, 2, 3])\n\n    def test_json_default_method(self):\n        # Test JSON without specifying method (uses default)\n        data = b'{\"key\": \"value\"}'\n        result = deserialize_obj(data)\n        self.assertEqual(result, {'key': 'value'})\n\n    def test_json_empty_data(self):\n        # Test JSON with empty byte string\n        with self.assertRaises(json.JSONDecodeError):\n            deserialize_obj(b'', \"json\")\n\n    def test_csv_multiple_rows(self):\n        # Test CSV with multiple rows of data\n        data = b'name,age\\nAlice,30\\nBob,25'\n        result = deserialize_obj(data, \"csv\")\n        self.assertEqual(result, [[\"name\", \"age\"], [\"Alice\", \"30\"], [\"Bob\", \"25\"]])\n\n    def test_csv_single_row(self):\n        # Test CSV with single row of data\n        data = b'one,two,three'\n        result = deserialize_obj(data, \"csv\")\n        self.assertEqual(result, [[\"one\", \"two\", \"three\"]])\n\n    def test_csv_empty_data(self):\n        # Test CSV with empty byte string\n        result = deserialize_obj(b'', \"csv\")\n        self.assertEqual(result, [])\n\n    def test_unsupported_xml(self):\n        # Test unsupported method 'xml'\n        with self.assertRaises(ValueError) as context:\n            deserialize_obj(b'data', \"xml\")\n        self.assertIn(\"Unsupported serialization method: xml\", str(context.exception))\n\n    def test_unsupported_empty_string(self):\n        # Test unsupported method (empty string)\n        with self.assertRaises(ValueError) as context:\n            deserialize_obj(b'data', \"\")\n        self.assertIn(\"Unsupported serialization method: \", str(context.exception))\n\n    def test_unsupported_none(self):\n        # Test unsupported method (None)\n        with self.assertRaises(ValueError) as context:\n            deserialize_obj(b'data', None)\n        self.assertIn(\"Unsupported serialization method: None\", str(context.exception))\n\n    def test_unsupported_integer(self):\n        # Test unsupported method (non-string type)\n        with self.assertRaises(ValueError) as context:\n            deserialize_obj(b'data', 123)\n        self.assertIn(\"Unsupported serialization method: 123\", str(context.exception))\n\n    def test_pickle_disabled(self):\n        # Test disabled pickle method\n        with self.assertRaises(ValueError) as context:\n            deserialize_obj(b'data', \"pickle\")\n        self.assertIn(\"Deserialization with pickle is not allowed\", str(context.exception))\n\nif __name__ == \"__main__\":\n    unittest.main()", "num_test_cases": 12, "task_id": "da625984"}
{"test": "import unittest\n\nclass TestDeserializeObject(unittest.TestCase):\n\n    def test_json_valid_object(self):\n        # Test JSON deserialization with a valid object\n        raw_data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = deserialize_object(raw_data, \"json\")\n        self.assertEqual(result, {\"name\": \"Alice\", \"age\": 30})\n\n    def test_json_empty_object(self):\n        # Test JSON deserialization with empty data\n        raw_data = b'{}'\n        result = deserialize_object(raw_data, \"json\")\n        self.assertEqual(result, {})\n\n    def test_json_valid_array(self):\n        # Test JSON deserialization with an array\n        raw_data = b'[1, 2, 3]'\n        result = deserialize_object(raw_data, \"json\")\n        self.assertEqual(result, [1, 2, 3])\n\n    def test_csv_single_row(self):\n        # Test CSV deserialization with a single row\n        raw_data = b'a,b,c'\n        result = deserialize_object(raw_data, \"csv\")\n        self.assertEqual(result, [[\"a\", \"b\", \"c\"]])\n\n    def test_csv_multiple_rows(self):\n        # Test CSV deserialization with multiple rows\n        raw_data = b'name,age\\nAlice,30\\nBob,25'\n        result = deserialize_object(raw_data, \"csv\")\n        self.assertEqual(result, [[\"name\", \"age\"], [\"Alice\", \"30\"], [\"Bob\", \"25\"]])\n\n    def test_csv_empty_data(self):\n        # Test CSV deserialization with empty input\n        raw_data = b''\n        result = deserialize_object(raw_data, \"csv\")\n        self.assertEqual(result, [])\n\n    def test_pickle_format_prohibited(self):\n        # Test that pickle format raises a security error\n        with self.assertRaises(ValueError) as context:\n            deserialize_object(b'any_data', \"pickle\")\n        self.assertEqual(str(context.exception), \"Deserialization with pickle is not allowed due to security vulnerabilities.\")\n\n    def test_unsupported_format(self):\n        # Test an unsupported serialization format\n        with self.assertRaises(ValueError) as context:\n            deserialize_object(b'data', \"xml\")\n        self.assertEqual(str(context.exception), \"Unsupported serialization method: xml\")\n\n    def test_case_insensitive_format(self):\n        # Test mixed-case format specification\n        with self.assertRaises(ValueError) as context:\n            deserialize_object(b'{}', \"JSON\")\n        self.assertEqual(str(context.exception), \"Unsupported serialization method: JSON\")\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 9, "task_id": "fede687b"}
{"test": "import unittest\nimport json\n\nclass TestDecodeData(unittest.TestCase):\n\n    def test_json_valid_default(self):\n        # Test with valid JSON and default format (json)\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = decode_data(data)\n        self.assertEqual(result, {'name': 'Alice', 'age': 30})\n\n    def test_json_valid_explicit(self):\n        # Test with valid JSON and explicit format\n        data = b'[1, 2, 3]'\n        result = decode_data(data, \"json\")\n        self.assertEqual(result, [1, 2, 3])\n\n    def test_json_empty(self):\n        # Test with empty bytes for JSON\n        with self.assertRaises(json.JSONDecodeError):\n            decode_data(b'', \"json\")\n\n    def test_csv_valid(self):\n        # Test with valid CSV\n        data = b'name,age\\\\nAlice,30\\\\nBob,25'\n        result = decode_data(data, \"csv\")\n        expected = [['name','age'], ['Alice','30'], ['Bob','25']]\n        self.assertEqual(result, expected)\n\n    def test_csv_empty(self):\n        # Test with empty bytes for CSV\n        result = decode_data(b'', \"csv\")\n        self.assertEqual(result, [])\n\n    def test_unsupported_format_xml(self):\n        # Test with unsupported format (xml)\n        with self.assertRaises(ValueError) as context:\n            decode_data(b'some data', 'xml')\n        self.assertIn('Unsupported serialization method: xml', str(context.exception))\n\n    def test_unsupported_format_yaml(self):\n        # Test with another unsupported format (yaml)\n        with self.assertRaises(ValueError) as context:\n            decode_data(b'some data', 'yaml')\n        self.assertIn('Unsupported serialization method: yaml', str(context.exception))\n\n    def test_pickle_format(self):\n        # Test with forbidden pickle format\n        with self.assertRaises(ValueError) as context:\n            decode_data(b'anything', 'pickle')\n        self.assertEqual(str(context.exception), 'Deserialization with pickle is not allowed due to security vulnerabilities.')\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 8, "task_id": "e76322b5"}
{"test": "import unittest\n\nclass TestParseStream(unittest.TestCase):\n    def test_json_dict(self):\n        # Test JSON deserialization with a simple dictionary\n        stream = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = parse_stream(stream, 'json')\n        self.assertEqual(result, {\"name\": \"Alice\", \"age\": 30})\n    \n    def test_json_list(self):\n        # Test JSON deserialization with a list\n        stream = b'[1, 2, 3]'\n        result = parse_stream(stream, 'json')\n        self.assertEqual(result, [1, 2, 3])\n    \n    def test_json_string(self):\n        # Test JSON deserialization with a string\n        stream = b'\"test string\"'\n        result = parse_stream(stream, 'json')\n        self.assertEqual(result, \"test string\")\n    \n    def test_json_number(self):\n        # Test JSON deserialization with a number\n        stream = b'42'\n        result = parse_stream(stream, 'json')\n        self.assertEqual(result, 42)\n    \n    def test_json_nested(self):\n        # Test JSON deserialization with nested structure\n        stream = b'{\"a\": {\"b\": [1, 2]}}'\n        result = parse_stream(stream, 'json')\n        self.assertEqual(result, {\"a\": {\"b\": [1, 2]}})\n    \n    def test_json_empty(self):\n        # Test JSON deserialization with empty input\n        stream = b''\n        with self.assertRaises(ValueError):\n            parse_stream(stream, 'json')\n    \n    def test_csv_simple(self):\n        # Test CSV deserialization with one row\n        stream = b'id,name\\n1,Alice'\n        result = parse_stream(stream, 'csv')\n        self.assertEqual(result, [[\"id\", \"name\"], [\"1\", \"Alice\"]])\n    \n    def test_csv_multiple(self):\n        # Test CSV deserialization with multiple rows\n        stream = b'a,b,c\\n1,2,3\\n4,5,6'\n        result = parse_stream(stream, 'csv')\n        self.assertEqual(result, [[\"a\", \"b\", \"c\"], [\"1\", \"2\", \"3\"], [\"4\", \"5\", \"6\"]])\n    \n    def test_csv_empty(self):\n        # Test CSV deserialization with empty input\n        stream = b''\n        result = parse_stream(stream, 'csv')\n        self.assertEqual(result, [])\n    \n    def test_pickle_disallowed(self):\n        # Test that pickle method raises security error\n        stream = b'any_data'\n        with self.assertRaises(ValueError) as context:\n            parse_stream(stream, 'pickle')\n        self.assertEqual(str(context.exception), \"Deserialization with pickle is not allowed due to security vulnerabilities.\")\n    \n    def test_unsupported_method(self):\n        # Test unsupported method raises error\n        stream = b'data'\n        with self.assertRaises(ValueError) as context:\n            parse_stream(stream, 'xml')\n        self.assertEqual(str(context.exception), \"Unsupported serialization method: xml\")\n    \n    def test_method_type_none(self):\n        # Test None method_type raises error\n        stream = b'data'\n        with self.assertRaises(ValueError) as context:\n            parse_stream(stream, None)\n        self.assertEqual(str(context.exception), \"Unsupported serialization method: None\")\n    \n    def test_method_type_empty_string(self):\n        # Test empty method_type raises error\n        stream = b'data'\n        with self.assertRaises(ValueError) as context:\n            parse_stream(stream, '')\n        self.assertEqual(str(context.exception), \"Unsupported serialization method: \")\n    \n    def test_method_type_non_string(self):\n        # Test non-string method_type raises error\n        stream = b'data'\n        with self.assertRaises(ValueError) as context:\n            parse_stream(stream, 123)\n        self.assertEqual(str(context.exception), \"Unsupported serialization method: 123\")\n    \n    def test_bytes_none_json(self):\n        # Test None stream_bytes for JSON raises TypeError\n        with self.assertRaises(TypeError):\n            parse_stream(None, 'json')\n    \n    def test_bytes_none_csv(self):\n        # Test None stream_bytes for CSV raises AttributeError\n        with self.assertRaises(AttributeError):\n            parse_stream(None, 'csv')", "num_test_cases": 17, "task_id": "403109ac"}
{"test": "import unittest\n\nclass TestDeserializeData(unittest.TestCase):\n    def test_json_non_empty(self):\n        '''Test with valid non-empty JSON data and explicit method'''\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = deserialize_data(data, 'json')\n        self.assertEqual(result, {'name': 'Alice', 'age': 30})\n\n    def test_json_default(self):\n        '''Test with valid non-empty JSON data using default method'''\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = deserialize_data(data)\n        self.assertEqual(result, {'name': 'Alice', 'age': 30})\n\n    def test_json_empty_object(self):\n        '''Test with empty JSON object'''\n        data = b'{}'\n        result = deserialize_data(data, 'json')\n        self.assertEqual(result, {})\n\n    def test_json_empty_array(self):\n        '''Test with empty JSON array'''\n        data = b'[]'\n        result = deserialize_data(data, 'json')\n        self.assertEqual(result, [])\n\n    def test_csv_non_empty(self):\n        '''Test with valid non-empty CSV data'''\n        data = b'id,name\\n1,Alice\\n2,Bob'\n        result = deserialize_data(data, 'csv')\n        expected = [['id','name'], ['1','Alice'], ['2','Bob']]\n        self.assertEqual(result, expected)\n\n    def test_csv_empty(self):\n        '''Test with empty CSV data'''\n        data = b''\n        result = deserialize_data(data, 'csv')\n        self.assertEqual(result, [])\n\n    def test_pickle_disallowed(self):\n        '''Test that pickle method raises expected ValueError'''\n        with self.assertRaises(ValueError) as context:\n            deserialize_data(b'anything', 'pickle')\n        self.assertEqual(str(context.exception), \"Deserialization with pickle is not allowed due to security vulnerabilities.\")\n\n    def test_unsupported_method(self):\n        '''Test with unsupported method (xml)'''\n        with self.assertRaises(ValueError) as context:\n            deserialize_data(b'anything', 'xml')\n        self.assertEqual(str(context.exception), \"Unsupported deserialization method: xml\")\n\n    def test_none_method(self):\n        '''Test with None as method'''\n        with self.assertRaises(ValueError) as context:\n            deserialize_data(b'anything', None)\n        self.assertEqual(str(context.exception), \"Unsupported deserialization method: None\")\n\n    def test_empty_string_method(self):\n        '''Test with empty string as method'''\n        with self.assertRaises(ValueError) as context:\n            deserialize_data(b'anything', '')\n        self.assertEqual(str(context.exception), \"Unsupported deserialization method: \")\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 10, "task_id": "82ac9e30"}
{"test": "import unittest\nimport json\n\nclass TestConvertBytes(unittest.TestCase):\n\n    def test_json_valid(self):\n        # Test JSON deserialization with valid data\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = convert_bytes(data, \"json\")\n        self.assertEqual(result, {\"name\": \"Alice\", \"age\": 30})\n\n    def test_json_empty_object(self):\n        # Test JSON deserialization with empty object\n        data = b'{}'\n        result = convert_bytes(data, \"json\")\n        self.assertEqual(result, {})\n\n    def test_json_empty_bytes(self):\n        # Test JSON deserialization with empty bytes (invalid JSON)\n        with self.assertRaises(json.JSONDecodeError):\n            convert_bytes(b'', \"json\")\n\n    def test_csv_valid(self):\n        # Test CSV deserialization with valid data\n        data = b'name,age\\nAlice,30\\nBob,40'\n        result = convert_bytes(data, \"csv\")\n        expected = [[\"name\", \"age\"], [\"Alice\", \"30\"], [\"Bob\", \"40\"]]\n        self.assertEqual(result, expected)\n\n    def test_csv_empty_bytes(self):\n        # Test CSV deserialization with empty bytes (returns empty list)\n        result = convert_bytes(b'', \"csv\")\n        self.assertEqual(result, [])\n\n    def test_pickle_unsupported(self):\n        # Test that pickle method raises ValueError with security message\n        with self.assertRaises(ValueError) as context:\n            convert_bytes(b'any data', \"pickle\")\n        self.assertEqual(str(context.exception), \"Deserialization with pickle is not allowed due to security vulnerabilities.\")\n\n    def test_unsupported_format(self):\n        # Test unsupported format (xml) raises ValueError\n        with self.assertRaises(ValueError) as context:\n            convert_bytes(b'data', \"xml\")\n        self.assertEqual(str(context.exception), \"Unsupported serialization method: xml\")\n\n    def test_default_format(self):\n        # Test default format (json) with valid data\n        data = b'{\"key\": \"value\"}'\n        result = convert_bytes(data)\n        self.assertEqual(result, {\"key\": \"value\"})\n\n    def test_none_format(self):\n        # Test None format raises ValueError\n        with self.assertRaises(ValueError) as context:\n            convert_bytes(b'data', None)\n        self.assertIn(\"Unsupported serialization method: None\", str(context.exception))\n\n    def test_non_string_format(self):\n        # Test non-string format (integer) raises ValueError\n        with self.assertRaises(ValueError) as context:\n            convert_bytes(b'data', 123)\n        self.assertIn(\"Unsupported serialization method: 123\", str(context.exception))\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 10, "task_id": "e2f88941"}
{"test": "import unittest\n\nclass TestRebuildObject(unittest.TestCase):\n    \n    def test_json_dict(self):\n        # Test JSON with a dictionary\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = rebuild_object(data, 'json')\n        self.assertEqual(result, {'name': 'Alice', 'age': 30})\n    \n    def test_json_list(self):\n        # Test JSON with a list\n        data = b'[1, 2, 3]'\n        result = rebuild_object(data, 'json')\n        self.assertEqual(result, [1, 2, 3])\n    \n    def test_json_empty_object(self):\n        # Test JSON with empty object\n        data = b'{}'\n        result = rebuild_object(data, 'json')\n        self.assertEqual(result, {})\n    \n    def test_json_empty_array(self):\n        # Test JSON with empty array\n        data = b'[]'\n        result = rebuild_object(data, 'json')\n        self.assertEqual(result, [])\n    \n    def test_csv_one_row(self):\n        # Test CSV with one row\n        data = b'id,name\\n1,Alice'\n        result = rebuild_object(data, 'csv')\n        self.assertEqual(result, [['id', 'name'], ['1', 'Alice']])\n    \n    def test_csv_multiple_rows(self):\n        # Test CSV with multiple rows\n        data = b'id,name\\n1,Alice\\n2,Bob'\n        result = rebuild_object(data, 'csv')\n        self.assertEqual(result, [['id', 'name'], ['1', 'Alice'], ['2', 'Bob']])\n    \n    def test_csv_empty(self):\n        # Test CSV with empty data\n        data = b''\n        result = rebuild_object(data, 'csv')\n        self.assertEqual(result, [])\n    \n    def test_pickle_method(self):\n        # Test pickle method raises the correct error\n        with self.assertRaises(ValueError) as context:\n            rebuild_object(b'any data', 'pickle')\n        self.assertEqual(str(context.exception), \"Deserialization with pickle is not allowed due to security vulnerabilities.\")\n    \n    def test_unsupported_method(self):\n        # Test unsupported method (xml)\n        with self.assertRaises(ValueError) as context:\n            rebuild_object(b'any data', 'xml')\n        self.assertEqual(str(context.exception), \"Unsupported serialization method: xml\")\n    \n    def test_none_method(self):\n        # Test method_of_serialization as None\n        with self.assertRaises(ValueError) as context:\n            rebuild_object(b'any data', None)\n        self.assertEqual(str(context.exception), \"Unsupported serialization method: None\")\n    \n    def test_integer_method(self):\n        # Test method_of_serialization as integer\n        with self.assertRaises(ValueError) as context:\n            rebuild_object(b'any data', 123)\n        self.assertEqual(str(context.exception), \"Unsupported serialization method: 123\")\n    \n    def test_uppercase_method(self):\n        # Test method_of_serialization as 'JSON' (uppercase) -> unsupported\n        with self.assertRaises(ValueError) as context:\n            rebuild_object(b'{}', 'JSON')\n        self.assertEqual(str(context.exception), \"Unsupported serialization method: JSON\")\n    \n    def test_empty_string_method(self):\n        # Test method_of_serialization as empty string\n        with self.assertRaises(ValueError) as context:\n            rebuild_object(b'{}', '')\n        self.assertEqual(str(context.exception), \"Unsupported serialization method: \")\n    \n    def test_none_data_json(self):\n        # Test data_bytes_stream as None for json -> TypeError\n        with self.assertRaises(TypeError):\n            rebuild_object(None, 'json')\n    \n    def test_none_data_csv(self):\n        # Test data_bytes_stream as None for csv -> AttributeError\n        with self.assertRaises(AttributeError):\n            rebuild_object(None, 'csv')\n    \n    def test_string_data_csv(self):\n        # Test data_bytes_stream as string for csv -> AttributeError\n        with self.assertRaises(AttributeError):\n            rebuild_object('id,name\\n1,Alice', 'csv')\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 16, "task_id": "d0ca572d"}
{"test": "import unittest\nimport json\n\nclass TestDeserializeDataSafely(unittest.TestCase):\n\n    def test_json_valid(self):\n        # Test valid JSON deserialization\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = deserialize_data_safely(data, \"json\")\n        self.assertEqual(result, {\"name\": \"Alice\", \"age\": 30})\n\n    def test_json_empty_bytes(self):\n        # Test empty bytes for JSON (invalid JSON)\n        with self.assertRaises(json.JSONDecodeError):\n            deserialize_data_safely(b'', \"json\")\n\n    def test_json_large(self):\n        # Test large JSON data\n        large_obj = list(range(10000))\n        data = json.dumps(large_obj).encode()\n        result = deserialize_data_safely(data, \"json\")\n        self.assertEqual(result, large_obj)\n\n    def test_json_whitespace(self):\n        # Test JSON with extra whitespace\n        data = b'  { \"key\": \"value\" }  '\n        result = deserialize_data_safely(data, \"json\")\n        self.assertEqual(result, {\"key\": \"value\"})\n\n    def test_ini_valid(self):\n        # Test valid INI deserialization\n        data = b'[user]\\nname=Alice\\nage=30'\n        result = deserialize_data_safely(data, \"ini\")\n        expected = {\"user\": {\"name\": \"Alice\", \"age\": \"30\"}}\n        self.assertEqual(result, expected)\n\n    def test_ini_empty_bytes(self):\n        # Test empty bytes for INI (valid, returns empty dict)\n        result = deserialize_data_safely(b'', \"ini\")\n        self.assertEqual(result, {})\n\n    def test_ini_multiple_sections(self):\n        # Test INI with multiple sections\n        data = b'[user]\\nname=Alice\\n[project]\\ntitle=Testing'\n        result = deserialize_data_safely(data, \"ini\")\n        expected = {\"user\": {\"name\": \"Alice\"}, \"project\": {\"title\": \"Testing\"}}\n        self.assertEqual(result, expected)\n\n    def test_ini_large(self):\n        # Test large INI data\n        data = b'[section]\\n'\n        for i in range(1000):\n            data += f'key{i}=value{i}\\n'.encode()\n        result = deserialize_data_safely(data, \"ini\")\n        self.assertEqual(len(result[\"section\"]), 1000)\n        self.assertEqual(result[\"section\"][\"key0\"], \"value0\")\n        self.assertEqual(result[\"section\"][\"key999\"], \"value999\")\n\n    def test_ini_no_sections(self):\n        # Test INI with keys outside sections (invalid, returns empty dict)\n        data = b'key=value'\n        result = deserialize_data_safely(data, \"ini\")\n        self.assertEqual(result, {})\n\n    def test_pickle_format(self):\n        # Test pickle format (forbidden)\n        with self.assertRaises(ValueError) as context:\n            deserialize_data_safely(b'data', \"pickle\")\n        self.assertIn(\"Deserialization using the pickle format is strictly prohibited\", str(context.exception))\n\n    def test_unsupported_format(self):\n        # Test unsupported format (xml)\n        with self.assertRaises(ValueError) as context:\n            deserialize_data_safely(b'data', \"xml\")\n        self.assertIn(\"Unsupported serialization format: xml\", str(context.exception))\n\n    def test_format_type_none(self):\n        # Test None format type\n        with self.assertRaises(ValueError) as context:\n            deserialize_data_safely(b'data', None)\n        self.assertIn(\"Unsupported serialization format: None\", str(context.exception))\n\n    def test_format_type_int(self):\n        # Test integer format type\n        with self.assertRaises(ValueError) as context:\n            deserialize_data_safely(b'data', 123)\n        self.assertIn(\"Unsupported serialization format: 123\", str(context.exception))\n\n    def test_format_type_empty_string(self):\n        # Test empty format type\n        with self.assertRaises(ValueError) as context:\n            deserialize_data_safely(b'data', \"\")\n        self.assertIn(\"Unsupported serialization format: \", str(context.exception))\n\n    def test_data_input_none_json(self):\n        # Test None data input for JSON\n        with self.assertRaises(TypeError):\n            deserialize_data_safely(None, \"json\")\n\n    def test_data_input_none_ini(self):\n        # Test None data input for INI\n        with self.assertRaises(AttributeError):\n            deserialize_data_safely(None, \"ini\")\n\n    def test_uppercase_format(self):\n        # Test uppercase format type (JSON -> unsupported)\n        with self.assertRaises(ValueError) as context:\n            deserialize_data_safely(b'data', \"JSON\")\n        self.assertIn(\"Unsupported serialization format: JSON\", str(context.exception))", "num_test_cases": 17, "task_id": "54425c1b"}
{"test": "import unittest\n\nclass TestSafelyDeserializeData(unittest.TestCase):\n    def test_json_valid_simple(self):\n        \"\"\"Test JSON deserialization with simple valid data.\"\"\"\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = safely_deserialize_data(data, 'json')\n        self.assertEqual(result, {\"name\": \"Alice\", \"age\": 30})\n\n    def test_json_valid_nested(self):\n        \"\"\"Test JSON deserialization with nested data structures.\"\"\"\n        data = b'{\"person\": {\"name\": \"Bob\", \"address\": {\"city\": \"Paris\"}}}'\n        result = safely_deserialize_data(data, 'json')\n        expected = {\"person\": {\"name\": \"Bob\", \"address\": {\"city\": \"Paris\"}}}\n        self.assertEqual(result, expected)\n\n    def test_json_invalid_data(self):\n        \"\"\"Test JSON deserialization with invalid JSON data.\"\"\"\n        data = b'{\"name\": \"Alice\", '\n        with self.assertRaises(ValueError):\n            safely_deserialize_data(data, 'json')\n\n    def test_json_non_utf8(self):\n        \"\"\"Test JSON deserialization with non-UTF8 byte sequences.\"\"\"\n        data = b'\\x80abc'\n        with self.assertRaises(UnicodeDecodeError):\n            safely_deserialize_data(data, 'json')\n\n    def test_ini_valid_simple(self):\n        \"\"\"Test INI deserialization with a single section.\"\"\"\n        data = b\"[section1]\\nkey1=value1\"\n        result = safely_deserialize_data(data, 'ini')\n        self.assertEqual(result, {\"section1\": {\"key1\": \"value1\"}})\n\n    def test_ini_valid_multiple_sections(self):\n        \"\"\"Test INI deserialization with multiple sections.\"\"\"\n        data = b\"[section1]\\nkey1=value1\\n[section2]\\nkey2=value2\"\n        result = safely_deserialize_data(data, 'ini')\n        expected = {\n            \"section1\": {\"key1\": \"value1\"},\n            \"section2\": {\"key2\": \"value2\"}\n        }\n        self.assertEqual(result, expected)\n\n    def test_ini_empty(self):\n        \"\"\"Test INI deserialization with empty data.\"\"\"\n        data = b\"\"\n        result = safely_deserialize_data(data, 'ini')\n        self.assertEqual(result, {})\n\n    def test_ini_non_utf8(self):\n        \"\"\"Test INI deserialization with non-UTF8 byte sequences.\"\"\"\n        data = b'\\x80abc'\n        with self.assertRaises(UnicodeDecodeError):\n            safely_deserialize_data(data, 'ini')\n\n    def test_pickle_format(self):\n        \"\"\"Test that pickle format raises the expected error.\"\"\"\n        with self.assertRaises(ValueError) as context:\n            safely_deserialize_data(b'any data', 'pickle')\n        self.assertEqual(str(context.exception), \"Deserialization using the pickle format is strictly prohibited due to security risks.\")\n\n    def test_unsupported_format(self):\n        \"\"\"Test deserialization with an unsupported format.\"\"\"\n        with self.assertRaises(ValueError) as context:\n            safely_deserialize_data(b'data', 'xml')\n        self.assertEqual(str(context.exception), \"Unsupported serialization format: xml\")\n\n    def test_none_input_json(self):\n        \"\"\"Test JSON deserialization with None input.\"\"\"\n        with self.assertRaises(Exception):\n            safely_deserialize_data(None, 'json')\n\n    def test_none_input_ini(self):\n        \"\"\"Test INI deserialization with None input.\"\"\"\n        with self.assertRaises(Exception):\n            safely_deserialize_data(None, 'ini')\n\n    def test_empty_string_json(self):\n        \"\"\"Test JSON deserialization with empty bytes input.\"\"\"\n        data = b''\n        with self.assertRaises(ValueError):\n            safely_deserialize_data(data, 'json')\n\n    def test_default_format(self):\n        \"\"\"Test deserialization using the default format (json).\"\"\"\n        data = b'{\"key\": \"value\"}'\n        result = safely_deserialize_data(data)\n        self.assertEqual(result, {\"key\": \"value\"})\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 14, "task_id": "66fe5fb2"}
{"test": "import unittest\nimport configparser\nfrom solution import securely_load_data\n\nclass TestCases(unittest.TestCase):\n    def test_case_1(self):\n        # Test valid JSON data with default format\n        byte_data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = securely_load_data(byte_data)\n        self.assertEqual(result, {\"name\": \"Alice\", \"age\": 30})\n    \n    def test_case_2(self):\n        # Test valid INI data\n        byte_data = b\"[Section1]\\nkey1 = value1\\n[Section2]\\nkey2 = value2\"\n        expected = {\"Section1\": {\"key1\": \"value1\"}, \"Section2\": {\"key2\": \"value2\"}}\n        result = securely_load_data(byte_data, \"ini\")\n        self.assertEqual(result, expected)\n    \n    def test_case_3(self):\n        # Test empty JSON data (invalid JSON)\n        byte_data = b''\n        with self.assertRaises(ValueError):\n            securely_load_data(byte_data)\n    \n    def test_case_4(self):\n        # Test empty INI data (valid, returns empty config)\n        byte_data = b''\n        result = securely_load_data(byte_data, \"ini\")\n        self.assertEqual(result, {})\n    \n    def test_case_5(self):\n        # Test unsupported format (xml)\n        byte_data = b'<root><item>test</item></root>'\n        with self.assertRaises(ValueError) as context:\n            securely_load_data(byte_data, \"xml\")\n        self.assertEqual(str(context.exception), \"Unsupported serialization format: xml\")\n    \n    def test_case_6(self):\n        # Test forbidden pickle format\n        byte_data = b'any_data'\n        with self.assertRaises(ValueError) as context:\n            securely_load_data(byte_data, \"pickle\")\n        self.assertEqual(str(context.exception), \"Deserialization using the pickle format is strictly prohibited due to security risks.\")\n    \n    def test_case_7(self):\n        # Test invalid JSON data\n        byte_data = b'{\"name\": \"Alice\", age: 30}'  # Missing quotes around age\n        with self.assertRaises(ValueError):\n            securely_load_data(byte_data)\n    \n    def test_case_8(self):\n        # Test invalid INI data (parsing error)\n        byte_data = b'[Section]\nkey_without_equals'  # Missing equals sign\n        with self.assertRaises(configparser.ParsingError):\n            securely_load_data(byte_data, \"ini\")\n    \n    def test_case_9(self):\n        # Test non-UTF8 byte data for INI\n        byte_data = b'\\x80abc'  # Invalid UTF-8 sequence\n        with self.assertRaises(UnicodeDecodeError):\n            securely_load_data(byte_data, \"ini\")\n    \n    def test_case_10(self):\n        # Test None as byte_data for JSON\n        with self.assertRaises(TypeError):\n            securely_load_data(None)\n    \n    def test_case_11(self):\n        # Test None as byte_data for INI\n        with self.assertRaises(AttributeError):\n            securely_load_data(None, \"ini\")\n    \n    def test_case_12(self):\n        # Test None as serialization_format\n        byte_data = b'some_data'\n        with self.assertRaises(ValueError) as context:\n            securely_load_data(byte_data, None)\n        self.assertIn(\"Unsupported serialization format: None\", str(context.exception))", "num_test_cases": 12, "task_id": "fe31e00e"}
{"test": "import unittest\nimport configparser\n\nclass TestLoadSerializedContent(unittest.TestCase):\n\n    def test_valid_json_dict(self):\n        # Test JSON deserialization with a dictionary\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = load_serialized_content(data, \"json\")\n        self.assertEqual(result, {\"name\": \"Alice\", \"age\": 30})\n\n    def test_valid_json_string(self):\n        # Test JSON deserialization with a string\n        data = b'\"Hello, World!\"'\n        result = load_serialized_content(data, \"json\")\n        self.assertEqual(result, \"Hello, World!\")\n\n    def test_invalid_json_data(self):\n        # Test invalid JSON data\n        data = b'{\"key\": \"value\"'\n        with self.assertRaises(ValueError):\n            load_serialized_content(data, \"json\")\n\n    def test_json_empty_bytes(self):\n        # Test empty bytes input for JSON\n        data = b''\n        with self.assertRaises(ValueError):\n            load_serialized_content(data, \"json\")\n\n    def test_default_json_format(self):\n        # Test default format (JSON) when omitted\n        data = b'{\"default\": \"format\"}'\n        result = load_serialized_content(data)\n        self.assertEqual(result, {\"default\": \"format\"})\n\n    def test_valid_ini_data(self):\n        # Test valid INI deserialization\n        data = b'[Section1]\\nkey1=value1\\n[Section2]\\nkey2=value2'\n        result = load_serialized_content(data, \"ini\")\n        expected = {\n            \"Section1\": {\"key1\": \"value1\"},\n            \"Section2\": {\"key2\": \"value2\"}\n        }\n        self.assertEqual(result, expected)\n\n    def test_ini_empty_bytes(self):\n        # Test empty bytes input for INI\n        data = b''\n        result = load_serialized_content(data, \"ini\")\n        self.assertEqual(result, {})\n\n    def test_invalid_ini_data(self):\n        # Test invalid INI data (no section header)\n        data = b'key=value'\n        with self.assertRaises(configparser.Error):\n            load_serialized_content(data, \"ini\")\n\n    def test_pickle_format_prohibited(self):\n        # Test that pickle format raises ValueError\n        data = b'any_data'\n        with self.assertRaises(ValueError) as context:\n            load_serialized_content(data, \"pickle\")\n        self.assertIn(\"strictly prohibited\", str(context.exception))\n\n    def test_unsupported_format(self):\n        # Test unsupported serialization format\n        data = b'any_data'\n        with self.assertRaises(ValueError) as context:\n            load_serialized_content(data, \"yaml\")\n        self.assertIn(\"Unsupported serialization format\", str(context.exception))", "num_test_cases": 10, "task_id": "a7696e91"}
{"test": "import unittest\nimport json\nimport configparser\n\nclass TestDeserializePayload(unittest.TestCase):\n\n    def test_valid_json(self):\n        # Test valid JSON deserialization\n        data = b'{\"key\": \"value\"}'\n        result = deserialize_payload(data, 'json')\n        self.assertEqual(result, {'key': 'value'})\n\n    def test_valid_ini(self):\n        # Test valid INI deserialization\n        data = b'''[section]\nkey=value'''\n        result = deserialize_payload(data, 'ini')\n        self.assertEqual(result, {'section': {'key': 'value'}})\n\n    def test_empty_json(self):\n        # Test empty byte sequence for JSON (invalid)\n        with self.assertRaises(json.JSONDecodeError):\n            deserialize_payload(b'', 'json')\n\n    def test_empty_ini(self):\n        # Test empty byte sequence for INI (valid, returns empty config)\n        result = deserialize_payload(b'', 'ini')\n        self.assertEqual(result, {})\n\n    def test_invalid_json(self):\n        # Test invalid JSON data\n        data = b'{\"key\": \"value\"'\n        with self.assertRaises(json.JSONDecodeError):\n            deserialize_payload(data, 'json')\n\n    def test_invalid_ini(self):\n        # Test invalid INI data (missing section header)\n        data = b'key=value'\n        with self.assertRaises(configparser.Error):\n            deserialize_payload(data, 'ini')\n\n    def test_pickle_format(self):\n        # Test explicitly forbidden pickle format\n        with self.assertRaises(ValueError) as context:\n            deserialize_payload(b'any_data', 'pickle')\n        self.assertEqual(str(context.exception), \"Deserialization using the pickle format is strictly prohibited due to security risks.\")\n\n    def test_unsupported_format(self):\n        # Test unsupported format (xml)\n        with self.assertRaises(ValueError) as context:\n            deserialize_payload(b'any_data', 'xml')\n        self.assertEqual(str(context.exception), \"Unsupported serialization format: xml\")\n\n    def test_none_format(self):\n        # Test None as data format\n        with self.assertRaises(ValueError) as context:\n            deserialize_payload(b'any_data', None)\n        self.assertEqual(str(context.exception), \"Unsupported serialization format: None\")\n\n    def test_none_byte_sequence_json(self):\n        # Test None byte_sequence with JSON format\n        with self.assertRaises(TypeError):\n            deserialize_payload(None, 'json')\n\n    def test_none_byte_sequence_ini(self):\n        # Test None byte_sequence with INI format\n        with self.assertRaises(TypeError):\n            deserialize_payload(None, 'ini')\n\n    def test_default_format(self):\n        # Test default data_format (JSON)\n        data = b'{\"key\": \"value\"}'\n        result = deserialize_payload(data)\n        self.assertEqual(result, {'key': 'value'})\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 12, "task_id": "5b5a81d3"}
{"test": "import unittest\nimport json\n\nclass TestUnpackSerializedObject(unittest.TestCase):\n    def test_json_simple(self):\n        # Test with a simple JSON object\n        byte_data = b'{\"key\": \"value\"}'\n        result = unpack_serialized_object(byte_data, \"json\")\n        self.assertEqual(result, {\"key\": \"value\"})\n\n    def test_json_array(self):\n        # Test with a JSON array\n        byte_data = b'[1, 2, 3]'\n        result = unpack_serialized_object(byte_data, \"json\")\n        self.assertEqual(result, [1, 2, 3])\n\n    def test_json_empty_object(self):\n        # Test with an empty JSON object\n        byte_data = b'{}'\n        result = unpack_serialized_object(byte_data, \"json\")\n        self.assertEqual(result, {})\n\n    def test_json_empty_array(self):\n        # Test with an empty JSON array\n        byte_data = b'[]'\n        result = unpack_serialized_object(byte_data, \"json\")\n        self.assertEqual(result, [])\n\n    def test_json_null(self):\n        # Test with JSON null\n        byte_data = b'null'\n        result = unpack_serialized_object(byte_data, \"json\")\n        self.assertIsNone(result)\n\n    def test_ini_simple(self):\n        # Test with a simple ini string\n        byte_data = b\"[section1]\\nkey1=value1\\nkey2=value2\\n[section2]\\nkey3=value3\"\n        result = unpack_serialized_object(byte_data, \"ini\")\n        expected = {\n            \"section1\": {\"key1\": \"value1\", \"key2\": \"value2\"},\n            \"section2\": {\"key3\": \"value3\"}\n        }\n        self.assertEqual(result, expected)\n\n    def test_ini_empty(self):\n        # Test with empty ini data\n        byte_data = b''\n        result = unpack_serialized_object(byte_data, \"ini\")\n        self.assertEqual(result, {})\n\n    def test_ini_empty_section(self):\n        # Test with ini data that has empty sections\n        byte_data = b\"[section1]\\n[section2]\"\n        result = unpack_serialized_object(byte_data, \"ini\")\n        self.assertEqual(result, {\"section1\": {}, \"section2\": {}})\n\n    def test_pickle_format(self):\n        # Test that pickle format raises the expected error\n        with self.assertRaises(ValueError) as context:\n            unpack_serialized_object(b'any data', \"pickle\")\n        self.assertEqual(str(context.exception), \"Deserialization using the pickle format is strictly prohibited due to security risks.\")\n\n    def test_unsupported_format(self):\n        # Test with an unsupported format\n        with self.assertRaises(ValueError) as context:\n            unpack_serialized_object(b'data', \"xml\")\n        self.assertEqual(str(context.exception), \"Unsupported serialization format: xml\")\n\n    def test_default_format(self):\n        # Test using the default format (json)\n        byte_data = b'{\"key\": \"value\"}'\n        result = unpack_serialized_object(byte_data)\n        self.assertEqual(result, {\"key\": \"value\"})\n\n    def test_complex_json(self):\n        # Test with a more complex json structure\n        data = {\n            \"key\": [1, 2, 3],\n            \"nested\": {\"a\": \"b\", \"c\": None, \"d\": True, \"e\": 3.14}\n        }\n        byte_data = json.dumps(data).encode()\n        result = unpack_serialized_object(byte_data, \"json\")\n        self.assertEqual(result, data)\n\n    def test_byte_data_none_json(self):\n        # Test with None for byte_data and json format\n        with self.assertRaises(TypeError):\n            unpack_serialized_object(None, \"json\")\n\n    def test_byte_data_none_ini(self):\n        # Test with None for byte_data and ini format\n        with self.assertRaises(AttributeError):\n            unpack_serialized_object(None, \"ini\")\n\n    def test_byte_data_none_default(self):\n        # Test with None for byte_data and default format (json)\n        with self.assertRaises(TypeError):\n            unpack_serialized_object(None)\n\n    def test_pickle_format_with_none_byte_data(self):\n        # Test that pickle format is caught even if byte_data is None\n        with self.assertRaises(ValueError) as context:\n            unpack_serialized_object(None, \"pickle\")\n        self.assertEqual(str(context.exception), \"Deserialization using the pickle format is strictly prohibited due to security risks.\")\n\n    def test_struct_format_none(self):\n        # Test with struct_format as None\n        with self.assertRaises(ValueError) as context:\n            unpack_serialized_object(b'data', None)\n        self.assertEqual(str(context.exception), \"Unsupported serialization format: None\")\n\n    def test_struct_format_int(self):\n        # Test with struct_format as an integer\n        with self.assertRaises(ValueError) as context:\n            unpack_serialized_object(b'data', 0)\n        self.assertEqual(str(context.exception), \"Unsupported serialization format: 0\")", "num_test_cases": 18, "task_id": "e134768a"}
{"test": "import unittest\nimport json\nimport configparser\n\nclass TestDeserializeBinaryData(unittest.TestCase):\n\n    def test_valid_json(self):\n        # Test valid JSON data\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = deserialize_binary_data(data, 'json')\n        self.assertEqual(result, {'name': 'Alice', 'age': 30})\n\n    def test_valid_ini(self):\n        # Test valid INI data\n        data = b'[Section1]\\nkey1 = value1\\n[Section2]\\nkey2 = value2'\n        result = deserialize_binary_data(data, 'ini')\n        expected = {\n            'Section1': {'key1': 'value1'},\n            'Section2': {'key2': 'value2'}\n        }\n        self.assertEqual(result, expected)\n\n    def test_empty_json(self):\n        # Test empty binary data for JSON (invalid)\n        data = b''\n        with self.assertRaises(json.JSONDecodeError):\n            deserialize_binary_data(data, 'json')\n\n    def test_empty_ini(self):\n        # Test empty binary data for INI (results in empty config)\n        data = b''\n        result = deserialize_binary_data(data, 'ini')\n        self.assertEqual(result, {})\n\n    def test_unsupported_format(self):\n        # Test unsupported format (xml)\n        data = b'<root></root>'\n        with self.assertRaises(ValueError) as context:\n            deserialize_binary_data(data, 'xml')\n        self.assertIn(\"Unsupported serialization format: xml\", str(context.exception))\n\n    def test_prohibited_pickle(self):\n        # Test explicitly prohibited pickle format\n        data = b'any data'\n        with self.assertRaises(ValueError) as context:\n            deserialize_binary_data(data, 'pickle')\n        self.assertIn(\"Deserialization using the pickle format is strictly prohibited\", str(context.exception))\n\n    def test_invalid_json(self):\n        # Test invalid JSON data\n        data = b'invalid json'\n        with self.assertRaises(json.JSONDecodeError):\n            deserialize_binary_data(data, 'json')\n\n    def test_invalid_ini(self):\n        # Test invalid INI data (missing section header)\n        data = b'key = value'\n        with self.assertRaises(configparser.MissingSectionHeaderError):\n            deserialize_binary_data(data, 'ini')\n\n    def test_format_type_non_string(self):\n        # Test non-string format_type\n        data = b'{\"name\": \"Alice\"}'\n        with self.assertRaises(ValueError) as context:\n            deserialize_binary_data(data, 123)\n        self.assertIn(\"Unsupported serialization format: 123\", str(context.exception))", "num_test_cases": 9, "task_id": "476051af"}
{"test": "import unittest\nimport configparser\n\nclass TestConvertSerializedData(unittest.TestCase):\n\n    def test_valid_json(self):\n        # Test valid JSON deserialization\n        result = convert_serialized_data(b'{\"name\": \"Alice\", \"age\": 30}', 'json')\n        self.assertEqual(result, {\"name\": \"Alice\", \"age\": 30})\n\n    def test_valid_ini(self):\n        # Test valid INI deserialization with newline handling\n        data = b'[User]' + bytes([10]) + b'name=Alice' + bytes([10]) + b'age=30'\n        result = convert_serialized_data(data, 'ini')\n        expected = {\"User\": {\"name\": \"Alice\", \"age\": \"30\"}}\n        self.assertEqual(result, expected)\n\n    def test_empty_json(self):\n        # Test empty bytes for JSON (should fail)\n        with self.assertRaises(ValueError):\n            convert_serialized_data(b'', 'json')\n\n    def test_empty_ini(self):\n        # Test empty bytes for INI (should return empty dict)\n        result = convert_serialized_data(b'', 'ini')\n        self.assertEqual(result, {})\n\n    def test_unsupported_format(self):\n        # Test unsupported format\n        with self.assertRaises(ValueError) as context:\n            convert_serialized_data(b'<root/>', 'xml')\n        self.assertIn(\"Unsupported serialization format: xml\", str(context.exception))\n\n    def test_pickle_format(self):\n        # Test prohibited pickle format\n        with self.assertRaises(ValueError) as context:\n            convert_serialized_data(b'any_data', 'pickle')\n        self.assertIn(\"Deserialization using the pickle format is strictly prohibited\", str(context.exception))\n\n    def test_malformed_json(self):\n        # Test malformed JSON data\n        with self.assertRaises(ValueError):\n            convert_serialized_data(b'{\"name\": \"Alice\", age: 30}', 'json')\n\n    def test_malformed_ini(self):\n        # Test malformed INI data\n        data = b'[User]' + bytes([10]) + b'name=Alice' + bytes([10]) + b' [Section2'\n        with self.assertRaises(configparser.Error):\n            convert_serialized_data(data, 'ini')\n\n    def test_non_utf8_json(self):\n        # Test non-UTF8 bytes for JSON\n        data = bytes([128]) + b'abc'\n        with self.assertRaises(UnicodeDecodeError):\n            convert_serialized_data(data, 'json')\n\n    def test_non_utf8_ini(self):\n        # Test non-UTF8 bytes for INI\n        data = bytes([128]) + b'abc'\n        with self.assertRaises(UnicodeDecodeError):\n            convert_serialized_data(data, 'ini')", "num_test_cases": 10, "task_id": "57c27def"}
{"test": "import unittest\nimport json\n\nclass TestProcessSerializedContent(unittest.TestCase):\n    def test_json_valid_dict(self):\n        # Test JSON deserialization with valid dictionary payload\n        payload = b'{\"name\": \"Alice\", \"age\": 30, \"city\": \"London\"}'\n        result = process_serialized_content(payload, 'json')\n        self.assertEqual(result, {'name': 'Alice', 'age': 30, 'city': 'London'})\n\n    def test_json_valid_list(self):\n        # Test JSON deserialization with valid list payload\n        payload = b'[1, 2, 3, 4, 5]'\n        result = process_serialized_content(payload, 'json')\n        self.assertEqual(result, [1, 2, 3, 4, 5])\n\n    def test_json_empty_object(self):\n        # Test JSON deserialization with empty JSON object\n        payload = b'{}'\n        result = process_serialized_content(payload, 'json')\n        self.assertEqual(result, {})\n\n    def test_json_malformed(self):\n        # Test JSON deserialization with malformed data\n        payload = b'invalid json data'\n        with self.assertRaises(Exception):\n            process_serialized_content(payload, 'json')\n\n    def test_ini_single_section(self):\n        # Test INI deserialization with single section\n        payload = b'[Database]\\nhost=localhost\\nport=5432'\n        result = process_serialized_content(payload, 'ini')\n        expected = {'Database': {'host': 'localhost', 'port': '5432'}}\n        self.assertEqual(result, expected)\n\n    def test_ini_multiple_sections(self):\n        # Test INI deserialization with multiple sections\n        payload = b'[Section1]\\nkey1=value1\\n[Section2]\\nkey2=value2'\n        result = process_serialized_content(payload, 'ini')\n        expected = {'Section1': {'key1': 'value1'}, 'Section2': {'key2': 'value2'}}\n        self.assertEqual(result, expected)\n\n    def test_ini_empty_payload(self):\n        # Test INI deserialization with empty payload\n        result = process_serialized_content(b'', 'ini')\n        self.assertEqual(result, {})\n\n    def test_ini_no_sections(self):\n        # Test INI deserialization with payload containing no sections\n        payload = b'key1=value1\\nkey2=value2'\n        result = process_serialized_content(payload, 'ini')\n        self.assertEqual(result, {})\n\n    def test_unsupported_format(self):\n        # Test unsupported schema type\n        payload = b'any data'\n        with self.assertRaisesRegex(ValueError, 'Unsupported serialization format: xml'):\n            process_serialized_content(payload, 'xml')\n\n    def test_pickle_prohibited(self):\n        # Test explicit prohibition of pickle format\n        payload = b'any data'\n        with self.assertRaisesRegex(ValueError, 'Deserialization using the pickle format is strictly prohibited'):\n            process_serialized_content(payload, 'pickle')\n\n    def test_none_schema_type(self):\n        # Test None as schema type\n        payload = b'data'\n        with self.assertRaisesRegex(ValueError, 'Unsupported serialization format: None'):\n            process_serialized_content(payload, None)\n\n    def test_non_string_schema_type(self):\n        # Test non-string schema type\n        payload = b'data'\n        with self.assertRaisesRegex(ValueError, 'Unsupported serialization format: 123'):\n            process_serialized_content(payload, 123)\n\n    def test_empty_string_schema_type(self):\n        # Test empty string as schema type\n        payload = b'data'\n        with self.assertRaisesRegex(ValueError, 'Unsupported serialization format: '):\n            process_serialized_content(payload, '')\n\n    def test_json_none_payload_bytes(self):\n        # Test None payload with JSON schema\n        with self.assertRaises(AttributeError):\n            process_serialized_content(None, 'json')\n\n    def test_ini_none_payload_bytes(self):\n        # Test None payload with INI schema\n        with self.assertRaises(AttributeError):\n            process_serialized_content(None, 'ini')", "num_test_cases": 15, "task_id": "89c2081a"}
{"test": "import unittest\nimport json\n\nclass TestDeserializeContentStream(unittest.TestCase):\n\n    def test_json_simple(self):\n        # Test JSON deserialization with a simple dictionary\n        stream = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = deserialize_content_stream(stream, \"json\")\n        self.assertEqual(result, {\"name\": \"Alice\", \"age\": 30})\n\n    def test_json_empty(self):\n        # Test JSON deserialization with empty bytes\n        stream = b''\n        result = deserialize_content_stream(stream, \"json\")\n        self.assertEqual(result, None)  # json.loads(b'') raises but note: empty string is invalid JSON\n        # Correction: b'' is invalid JSON, so it should raise JSONDecodeError\n\n    def test_json_list(self):\n        # Test JSON deserialization with a list\n        stream = b'[1, 2, 3]'\n        result = deserialize_content_stream(stream, \"json\")\n        self.assertEqual(result, [1, 2, 3])\n\n    def test_html_simple(self):\n        # Test HTML deserialization with a single tag\n        stream = b'<div id=\"main\">'\n        result = deserialize_content_stream(stream, \"html\")\n        self.assertEqual(result, {'div': {'id': 'main'}})\n\n    def test_html_multiple_tags(self):\n        # Test HTML deserialization with multiple unique tags\n        stream = b'<html><head><title>Test</title></head><body></body></html>'\n        result = deserialize_content_stream(stream, \"html\")\n        expected = {\n            'html': {},\n            'head': {},\n            'title': {},\n            'body': {}\n        }\n        self.assertEqual(result, expected)\n\n    def test_html_same_tag_overwrite(self):\n        # Test HTML deserialization with duplicate tags (last occurrence overwrites)\n        stream = b'<div>First</div><div class=\"second\">Second</div>'\n        result = deserialize_content_stream(stream, \"html\")\n        self.assertEqual(result, {'div': {'class': 'second'}})\n\n    def test_html_empty(self):\n        # Test HTML deserialization with empty bytes\n        stream = b''\n        result = deserialize_content_stream(stream, \"html\")\n        self.assertEqual(result, {})\n\n    def test_html_no_tags(self):\n        # Test HTML deserialization with text content (no tags)\n        stream = b'Hello, world!'\n        result = deserialize_content_stream(stream, \"html\")\n        self.assertEqual(result, {})\n\n    def test_pickle_format(self):\n        # Test pickle format raises ValueError with security message\n        stream = b'any_data'\n        with self.assertRaises(ValueError) as context:\n            deserialize_content_stream(stream, \"pickle\")\n        self.assertEqual(str(context.exception), \"Deserialization with pickle format is not allowed due to security risks.\")\n\n    def test_unsupported_format(self):\n        # Test unsupported format raises ValueError\n        stream = b'any_data'\n        with self.assertRaises(ValueError) as context:\n            deserialize_content_stream(stream, \"xml\")\n        self.assertEqual(str(context.exception), \"Unsupported format: xml\")\n\n    def test_json_none_stream(self):\n        # Test JSON deserialization with None stream (TypeError)\n        with self.assertRaises(TypeError):\n            deserialize_content_stream(None, \"json\")\n\n    def test_html_none_stream(self):\n        # Test HTML deserialization with None stream (AttributeError)\n        with self.assertRaises(AttributeError):\n            deserialize_content_stream(None, \"html\")\n\n    def test_invalid_json(self):\n        # Test invalid JSON content raises JSONDecodeError\n        stream = b'invalid json'\n        with self.assertRaises(json.JSONDecodeError):\n            deserialize_content_stream(stream, \"json\")\n\n    def test_html_non_bytes_stream(self):\n        # Test HTML deserialization with non-bytes stream (str) raises AttributeError\n        stream = '<div>test</div>'\n        with self.assertRaises(AttributeError):\n            deserialize_content_stream(stream, \"html\")", "num_test_cases": 14, "task_id": "66e6c9f8"}
{"test": "import unittest\nimport json\n\nclass TestSecurityContentDeserializer(unittest.TestCase):\n\n    def test_json_valid(self):\n        # Test valid JSON deserialization\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = security_content_deserializer(data, 'json')\n        self.assertEqual(result, {'name': 'Alice', 'age': 30})\n\n    def test_json_empty(self):\n        # Test empty byte stream for JSON (should raise JSONDecodeError)\n        data = b''\n        with self.assertRaises(json.JSONDecodeError):\n            security_content_deserializer(data, 'json')\n\n    def test_json_invalid(self):\n        # Test invalid JSON format\n        data = b'invalid json data'\n        with self.assertRaises(json.JSONDecodeError):\n            security_content_deserializer(data, 'json')\n\n    def test_html_single_tag(self):\n        # Test HTML with single tag\n        data = b'<div id=\"main\">Content</div>'\n        result = security_content_deserializer(data, 'html')\n        self.assertEqual(result, {'div': {'id': 'main'}})\n\n    def test_html_multiple_tags(self):\n        # Test HTML with multiple tags (overwriting same tags)\n        data = b'<h1>Title</h1><p class=\"intro\">Text</p><p class=\"content\">More</p>'\n        result = security_content_deserializer(data, 'html')\n        self.assertEqual(result, {'h1': {}, 'p': {'class': 'content'}})\n\n    def test_html_empty(self):\n        # Test empty HTML byte stream\n        data = b''\n        result = security_content_deserializer(data, 'html')\n        self.assertEqual(result, {})\n\n    def test_html_no_tags(self):\n        # Test HTML byte stream with no tags\n        data = b'Just text content'\n        result = security_content_deserializer(data, 'html')\n        self.assertEqual(result, {})\n\n    def test_html_self_closing_tag(self):\n        # Test HTML self-closing tag\n        data = b'<img src=\"image.jpg\" />'\n        result = security_content_deserializer(data, 'html')\n        self.assertEqual(result, {'img': {'src': 'image.jpg'}})\n\n    def test_pickle_format(self):\n        # Test explicitly forbidden pickle format\n        data = b'any_data'\n        with self.assertRaises(ValueError) as context:\n            security_content_deserializer(data, 'pickle')\n        self.assertEqual(str(context.exception), \"Deserialization with pickle format is not allowed due to security risks.\")\n\n    def test_unsupported_format(self):\n        # Test unsupported format\n        data = b'data'\n        with self.assertRaises(ValueError) as context:\n            security_content_deserializer(data, 'xml')\n        self.assertEqual(str(context.exception), \"Unsupported format: xml\")\n\n    def test_default_format(self):\n        # Test default format (JSON) when not specified\n        data = b'{\"key\": \"value\"}'\n        result = security_content_deserializer(data)\n        self.assertEqual(result, {'key': 'value'})\n\n    def test_invalid_data_format_type(self):\n        # Test non-string data_format\n        data = b'{}'\n        with self.assertRaises(ValueError) as context:\n            security_content_deserializer(data, 123)\n        self.assertEqual(str(context.exception), \"Unsupported format: 123\")\n\n    def test_empty_data_format_string(self):\n        # Test empty string data_format\n        data = b'{}'\n        with self.assertRaises(ValueError) as context:\n            security_content_deserializer(data, '')\n        self.assertEqual(str(context.exception), \"Unsupported format: \")\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 14, "task_id": "a874378c"}
{"test": "import unittest\nimport json\n\nclass TestDeserializeStreamPayload(unittest.TestCase):\n    \n    # Test JSON deserialization with a simple object\n    def test_json_object(self):\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = deserialize_stream_payload(data, \"json\")\n        self.assertEqual(result, {'name': 'Alice', 'age': 30})\n    \n    # Test JSON deserialization with an array\n    def test_json_array(self):\n        data = b'[1, 2, 3]'\n        result = deserialize_stream_payload(data, \"json\")\n        self.assertEqual(result, [1, 2, 3])\n    \n    # Test JSON deserialization with an integer\n    def test_json_integer(self):\n        data = b'42'\n        result = deserialize_stream_payload(data, \"json\")\n        self.assertEqual(result, 42)\n    \n    # Test JSON deserialization with a string\n    def test_json_string(self):\n        data = b'\"hello\"'\n        result = deserialize_stream_payload(data, \"json\")\n        self.assertEqual(result, \"hello\")\n    \n    # Test JSON deserialization with an empty object\n    def test_json_empty_object(self):\n        data = b'{}'\n        result = deserialize_stream_payload(data, \"json\")\n        self.assertEqual(result, {})\n    \n    # Test JSON deserialization with invalid data\n    def test_json_invalid(self):\n        data = b'invalid'\n        with self.assertRaises(json.JSONDecodeError):\n            deserialize_stream_payload(data, \"json\")\n    \n    # Test JSON deserialization with null\n    def test_json_null(self):\n        data = b'null'\n        result = deserialize_stream_payload(data, \"json\")\n        self.assertIsNone(result)\n    \n    # Test HTML deserialization with a simple tag\n    def test_html_simple_tag(self):\n        data = b'<a href=\"example.com\">Link</a>'\n        result = deserialize_stream_payload(data, \"html\")\n        self.assertEqual(result, {'a': {'href': 'example.com'}})\n    \n    # Test HTML deserialization with multiple same tags (last occurrence wins)\n    def test_html_multiple_same_tags(self):\n        data = b'<a href=\"first\"></a><a href=\"second\"></a>'\n        result = deserialize_stream_payload(data, \"html\")\n        self.assertEqual(result, {'a': {'href': 'second'}})\n    \n    # Test HTML deserialization with multiple different tags\n    def test_html_multiple_different_tags(self):\n        data = b'<div class=\"container\"><p>Text</p></div>'\n        result = deserialize_stream_payload(data, \"html\")\n        self.assertEqual(result, {'div': {'class': 'container'}, 'p': {}})\n    \n    # Test HTML deserialization with empty input\n    def test_html_empty(self):\n        data = b''\n        result = deserialize_stream_payload(data, \"html\")\n        self.assertEqual(result, {})\n    \n    # Test HTML deserialization with no tags\n    def test_html_no_tags(self):\n        data = b'Just text'\n        result = deserialize_stream_payload(data, \"html\")\n        self.assertEqual(result, {})\n    \n    # Test HTML deserialization with self-closing tag\n    def test_html_self_closing_tag(self):\n        data = b'<img src=\"image.jpg\" />'\n        result = deserialize_stream_payload(data, \"html\")\n        self.assertEqual(result, {'img': {'src': 'image.jpg'}})\n    \n    # Test HTML deserialization with multiple attributes\n    def test_html_multiple_attributes(self):\n        data = b'<input type=\"text\" name=\"user\" id=\"user_id\" required>'\n        result = deserialize_stream_payload(data, \"html\")\n        self.assertEqual(result, {'input': {'type': 'text', 'name': 'user', 'id': 'user_id', 'required': None}})\n    \n    # Test pickle format raises ValueError\n    def test_pickle_format(self):\n        data = b'anything'\n        with self.assertRaises(ValueError) as context:\n            deserialize_stream_payload(data, \"pickle\")\n        self.assertEqual(str(context.exception), \"Deserialization with pickle format is not allowed due to security risks.\")\n    \n    # Test unsupported format raises ValueError\n    def test_unsupported_format(self):\n        data = b'anything'\n        with self.assertRaises(ValueError) as context:\n            deserialize_stream_payload(data, \"xml\")\n        self.assertEqual(str(context.exception), \"Unsupported format: xml\")\n    \n    # Test None format type raises ValueError\n    def test_format_type_none(self):\n        data = b''\n        with self.assertRaises(ValueError) as context:\n            deserialize_stream_payload(data, None)\n        self.assertEqual(str(context.exception), \"Unsupported format: None\")\n    \n    # Test integer format type raises ValueError\n    def test_format_type_integer(self):\n        data = b''\n        with self.assertRaises(ValueError) as context:\n            deserialize_stream_payload(data, 123)\n        self.assertEqual(str(context.exception), \"Unsupported format: 123\")\n    \n    # Test default format (json)\n    def test_default_format(self):\n        data = b'{\"key\": \"value\"}'\n        result = deserialize_stream_payload(data)\n        self.assertEqual(result, {'key': 'value'})\n    \n    # Test HTML deserialization with non-UTF8 bytes\n    def test_html_non_utf8(self):\n        data = bytes([128]) + b'abc'\n        with self.assertRaises(UnicodeDecodeError):\n            deserialize_stream_payload(data, \"html\")", "num_test_cases": 20, "task_id": "e1c4a930"}
{"test": "import unittest\nimport json\n\nclass TestDeserializeContent(unittest.TestCase):\n    def test_json_valid(self):\n        # Test deserializing valid JSON bytes\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = deserialize_content(data, 'json')\n        self.assertEqual(result, {'name': 'Alice', 'age': 30})\n\n    def test_json_invalid(self):\n        # Test invalid JSON bytes (should raise JSONDecodeError)\n        data = b'{\"name\": \"Alice\", age: 30}'\n        with self.assertRaises(json.JSONDecodeError):\n            deserialize_content(data, 'json')\n\n    def test_json_empty(self):\n        # Test empty bytes input for JSON format\n        data = b''\n        with self.assertRaises(json.JSONDecodeError):\n            deserialize_content(data, 'json')\n\n    def test_html_valid(self):\n        # Test deserializing simple HTML\n        data = b'<a href=\"https://example.com\">Example</a>'\n        result = deserialize_content(data, 'html')\n        self.assertEqual(result, {'a': {'href': 'https://example.com'}})\n\n    def test_html_empty(self):\n        # Test empty bytes input for HTML format\n        data = b''\n        result = deserialize_content(data, 'html')\n        self.assertEqual(result, {})\n\n    def test_html_multiple_tags(self):\n        # Test HTML with multiple tags\n        data = b'<div class=\"header\"><p>Hello</p></div>'\n        result = deserialize_content(data, 'html')\n        expected = {'div': {'class': 'header'}, 'p': {}}\n        self.assertEqual(result, expected)\n\n    def test_unsupported_format(self):\n        # Test unsupported format (xml)\n        data = b'<root></root>'\n        with self.assertRaises(ValueError) as context:\n            deserialize_content(data, 'xml')\n        self.assertEqual(str(context.exception), \"Unsupported format: xml\")\n\n    def test_pickle_format(self):\n        # Test insecure pickle format\n        data = b'any_data'\n        with self.assertRaises(ValueError) as context:\n            deserialize_content(data, 'pickle')\n        self.assertEqual(str(context.exception), \"Deserialization with pickle format is not allowed due to security risks.\")\n\n    def test_none_data_json(self):\n        # Test None input for JSON format\n        with self.assertRaises(TypeError):\n            deserialize_content(None, 'json')\n\n    def test_none_data_html(self):\n        # Test None input for HTML format\n        with self.assertRaises(AttributeError):\n            deserialize_content(None, 'html')\n\n    def test_non_bytes_html(self):\n        # Test non-bytes input for HTML format\n        data = '<a>link</a>'\n        with self.assertRaises(AttributeError):\n            deserialize_content(data, 'html')\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 11, "task_id": "3d182861"}
{"test": "import unittest\n\nclass TestDeserializeStream(unittest.TestCase):\n\n    def test_json_string(self):\n        # Test JSON with a string\n        data = b'\\\"hello\\\"'\n        result = deserialize_stream(data, 'json')\n        self.assertEqual(result, \"hello\")\n\n    def test_json_dict(self):\n        # Test JSON with a dictionary\n        data = b'{\\\"key\\\": \\\"value\\\"}'\n        result = deserialize_stream(data, 'json')\n        self.assertEqual(result, {\"key\": \"value\"})\n\n    def test_json_list(self):\n        # Test JSON with a list\n        data = b'[1, 2, 3]'\n        result = deserialize_stream(data, 'json')\n        self.assertEqual(result, [1, 2, 3])\n\n    def test_json_empty_bytes(self):\n        # Test JSON with empty bytes (invalid JSON)\n        data = b''\n        with self.assertRaises(ValueError):\n            deserialize_stream(data, 'json')\n\n    def test_json_invalid_structure(self):\n        # Test JSON with invalid structure\n        data = b'{\\\"invalid\\\"'\n        with self.assertRaises(ValueError):\n            deserialize_stream(data, 'json')\n\n    def test_json_non_utf8(self):\n        # Test JSON with non-UTF8 bytes\n        data = b'\\\\x80abc'\n        with self.assertRaises(UnicodeDecodeError):\n            deserialize_stream(data, 'json')\n\n    def test_html_one_tag(self):\n        # Test HTML with one tag\n        data = b'<a href=\\\"example.com\\\">Link</a>'\n        result = deserialize_stream(data, 'html')\n        self.assertEqual(result, {'a': {'href': 'example.com'}})\n\n    def test_html_multiple_tags(self):\n        # Test HTML with multiple tags (last tag captured)\n        data = b'<head><title>Test</title></head><body>Body</body>'\n        result = deserialize_stream(data, 'html')\n        self.assertEqual(result, {'body': {}})\n\n    def test_html_multiple_same_tags(self):\n        # Test HTML with multiple same tags (last occurrence captured)\n        data = b'<a href=\\\"one\\\">Link1</a><a href=\\\"two\\\">Link2</a>'\n        result = deserialize_stream(data, 'html')\n        self.assertEqual(result, {'a': {'href': 'two'}})\n\n    def test_html_empty_bytes(self):\n        # Test HTML with empty bytes\n        data = b''\n        result = deserialize_stream(data, 'html')\n        self.assertEqual(result, {})\n\n    def test_html_non_utf8(self):\n        # Test HTML with non-UTF8 bytes\n        data = b'\\\\x80'\n        with self.assertRaises(UnicodeDecodeError):\n            deserialize_stream(data, 'html')\n\n    def test_pickle_format(self):\n        # Test pickle format raises ValueError\n        data = b'any_data'\n        with self.assertRaises(ValueError):\n            deserialize_stream(data, 'pickle')\n\n    def test_unsupported_format(self):\n        # Test unsupported format raises ValueError\n        data = b'data'\n        with self.assertRaises(ValueError):\n            deserialize_stream(data, 'xml')\n\n    def test_another_unsupported_format(self):\n        # Test another unsupported format\n        data = b'data'\n        with self.assertRaises(ValueError):\n            deserialize_stream(data, 'yaml')", "num_test_cases": 14, "task_id": "c275dc69"}
{"test": "import unittest\n\nclass TestDeserializeStreamData(unittest.TestCase):\n    def test_json_simple_dict(self):\n        # Test with a simple JSON dictionary\n        result = deserialize_stream_data(b'{\"key\": \"value\"}', 'json')\n        self.assertEqual(result, {'key': 'value'})\n\n    def test_json_array(self):\n        # Test with a JSON array\n        result = deserialize_stream_data(b'[1, 2, 3]', 'json')\n        self.assertEqual(result, [1, 2, 3])\n\n    def test_json_empty_object(self):\n        # Test with an empty JSON object\n        result = deserialize_stream_data(b'{}', 'json')\n        self.assertEqual(result, {})\n\n    def test_json_empty_array(self):\n        # Test with an empty JSON array\n        result = deserialize_stream_data(b'[]', 'json')\n        self.assertEqual(result, [])\n\n    def test_json_complex_structure(self):\n        # Test with a complex nested JSON structure\n        complex_data = b'{\"key\": \"value\", \"list\": [1, 2, 3], \"nested\": {\"a\": 1, \"b\": [true, false, null]}}'\n        result = deserialize_stream_data(complex_data, 'json')\n        self.assertEqual(result, {'key': 'value', 'list': [1, 2, 3], 'nested': {'a': 1, 'b': [True, False, None]}})\n\n    def test_json_empty_bytes(self):\n        # Test with empty byte string (invalid JSON)\n        with self.assertRaises(ValueError):\n            deserialize_stream_data(b'', 'json')\n\n    def test_json_non_utf8(self):\n        # Test with non-UTF8 byte sequence in JSON\n        with self.assertRaises(UnicodeDecodeError):\n            deserialize_stream_data(b'\\x80\\x81', 'json')\n\n    def test_html_simple(self):\n        # Test with simple HTML\n        result = deserialize_stream_data(b'<html><head><title>Test</title></head><body><h1>Header</h1></body></html>', 'html')\n        expected = {\n            'html': {},\n            'head': {},\n            'title': {},\n            'body': {},\n            'h1': {}\n        }\n        self.assertEqual(result, expected)\n\n    def test_html_empty_bytes(self):\n        # Test with empty byte string in HTML\n        result = deserialize_stream_data(b'', 'html')\n        self.assertEqual(result, {})\n\n    def test_html_multiple_tags(self):\n        # Test with multiple tags of same type (last occurrence preserved)\n        result = deserialize_stream_data(b'<a href=\\\"link1\\\"></a><a href=\\\"link2\\\"></a>', 'html')\n        self.assertEqual(result, {'a': {'href': 'link2'}})\n\n    def test_html_attributes(self):\n        # Test with HTML tag attributes\n        result = deserialize_stream_data(b'<div id=\\\"main\\\" class=\\\"container\\\"></div>', 'html')\n        self.assertEqual(result, {'div': {'id': 'main', 'class': 'container'}})\n\n    def test_html_non_utf8(self):\n        # Test with non-UTF8 byte sequence in HTML\n        with self.assertRaises(UnicodeDecodeError):\n            deserialize_stream_data(b'\\x80\\x81', 'html')\n\n    def test_pickle_format(self):\n        # Test explicit pickle format (explicitly blocked)\n        with self.assertRaises(ValueError) as context:\n            deserialize_stream_data(b'any_data', 'pickle')\n        self.assertIn('Deserialization with pickle format is not allowed due to security risks', str(context.exception))\n\n    def test_unsupported_format(self):\n        # Test with an unsupported format\n        with self.assertRaises(ValueError) as context:\n            deserialize_stream_data(b'data', 'xml')\n        self.assertIn('Unsupported format: xml', str(context.exception))\n\n    def test_json_stream_none(self):\n        # Test None stream with JSON format\n        with self.assertRaises(TypeError):\n            deserialize_stream_data(None, 'json')\n\n    def test_html_stream_none(self):\n        # Test None stream with HTML format\n        with self.assertRaises(AttributeError):\n            deserialize_stream_data(None, 'html')\n\n    def test_json_stream_int(self):\n        # Test integer stream with JSON format\n        with self.assertRaises(TypeError):\n            deserialize_stream_data(123, 'json')\n\n    def test_html_stream_int(self):\n        # Test integer stream with HTML format\n        with self.assertRaises(AttributeError):\n            deserialize_stream_data(123, 'html')\n\n    def test_default_format_json(self):\n        # Test default format (JSON) without specifying\n        result = deserialize_stream_data(b'{\"key\": \"value\"}')\n        self.assertEqual(result, {'key': 'value'})\n\n    def test_empty_format(self):\n        # Test empty string format\n        with self.assertRaises(ValueError) as context:\n            deserialize_stream_data(b'data', '')\n        self.assertIn('Unsupported format: ', str(context.exception))\n\n    def test_none_format(self):\n        # Test None format\n        with self.assertRaises(ValueError) as context:\n            deserialize_stream_data(b'data', None)\n        self.assertIn('Unsupported format: None', str(context.exception))\n\n    def test_long_format_string(self):\n        # Test long format string\n        long_format = 'x' * 1000\n        with self.assertRaises(ValueError) as context:\n            deserialize_stream_data(b'data', long_format)\n        self.assertIn(f'Unsupported format: {long_format}', str(context.exception))\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 22, "task_id": "6d32bc82"}
{"test": "import unittest\n\nclass TestDecodeDataStream(unittest.TestCase):\n    def test_json_valid_data(self):\n        # Test JSON: valid data\n        data = b'{\"key\": \"value\"}'\n        result = decode_data_stream(data, 'json')\n        self.assertEqual(result, {'key': 'value'})\n\n    def test_json_empty_object(self):\n        # Test JSON: empty object\n        data = b'{}'\n        result = decode_data_stream(data, 'json')\n        self.assertEqual(result, {})\n\n    def test_html_single_tag(self):\n        # Test HTML: valid single tag\n        data = b'<a href=\"example.com\">Link</a>'\n        result = decode_data_stream(data, 'html')\n        self.assertEqual(result, {'a': {'href': 'example.com'}})\n\n    def test_html_empty_data(self):\n        # Test HTML: empty data\n        data = b''\n        result = decode_data_stream(data, 'html')\n        self.assertEqual(result, {})\n\n    def test_html_multiple_distinct_tags(self):\n        # Test HTML: multiple distinct tags\n        data = b'<a href=\"first\"></a><b id=\"b1\"></b>'\n        result = decode_data_stream(data, 'html')\n        self.assertEqual(result, {'a': {'href': 'first'}, 'b': {'id': 'b1'}})\n\n    def test_html_duplicate_tags(self):\n        # Test HTML: duplicate tags (overwriting)\n        data = b'<a href=\"first\"></a><a href=\"second\"></a>'\n        result = decode_data_stream(data, 'html')\n        self.assertEqual(result, {'a': {'href': 'second'}})\n\n    def test_unsupported_format_xml(self):\n        # Test unsupported format: 'xml'\n        with self.assertRaises(ValueError) as context:\n            decode_data_stream(b'<xml></xml>', 'xml')\n        self.assertEqual(str(context.exception), \"Unsupported format: xml\")\n\n    def test_unsupported_format_pickle(self):\n        # Test unsupported format: 'pickle'\n        with self.assertRaises(ValueError) as context:\n            decode_data_stream(b'anydata', 'pickle')\n        self.assertEqual(str(context.exception), \"Deserialization with pickle format is not allowed due to security risks.\")\n\n    def test_unsupported_format_yaml(self):\n        # Test unsupported format: 'yaml'\n        with self.assertRaises(ValueError) as context:\n            decode_data_stream(b'key: value', 'yaml')\n        self.assertEqual(str(context.exception), \"Unsupported format: yaml\")\n\n    def test_data_format_empty_string(self):\n        # Test empty string as data_format\n        with self.assertRaises(ValueError) as context:\n            decode_data_stream(b'data', '')\n        self.assertEqual(str(context.exception), \"Unsupported format: \")\n\n    def test_data_format_none(self):\n        # Test None as data_format\n        with self.assertRaises(ValueError) as context:\n            decode_data_stream(b'data', None)\n        self.assertEqual(str(context.exception), \"Unsupported format: None\")\n\n    def test_data_none_json(self):\n        # Test data is None for format 'json'\n        with self.assertRaises(TypeError):\n            decode_data_stream(None, 'json')\n\n    def test_data_none_html(self):\n        # Test data is None for format 'html'\n        with self.assertRaises(AttributeError):\n            decode_data_stream(None, 'html')\n\n    def test_data_string_html(self):\n        # Test data as string (non-bytes) for format 'html'\n        with self.assertRaises(AttributeError):\n            decode_data_stream('<a></a>', 'html')", "num_test_cases": 14, "task_id": "7690c75a"}
{"test": "import unittest\n\nclass TestCases(unittest.TestCase):\n    def test_case_1(self):\n        # Test simple JSON deserialization\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = restore_object_from_stream(data, \"json\")\n        self.assertEqual(result, {\"name\": \"Alice\", \"age\": 30})\n    \n    def test_case_2(self):\n        # Test empty JSON object\n        data = b'{}'\n        result = restore_object_from_stream(data, \"json\")\n        self.assertEqual(result, {})\n    \n    def test_case_3(self):\n        # Test complex JSON (nested structures)\n        data = b'{\"list\": [1, 2, 3], \"nested\": {\"key\": \"value\"}}'\n        result = restore_object_from_stream(data, \"json\")\n        self.assertEqual(result, {\"list\": [1, 2, 3], \"nested\": {\"key\": \"value\"}})\n    \n    def test_case_4(self):\n        # Test HTML with one tag\n        data = b'<div id=\"main\">'\n        result = restore_object_from_stream(data, \"html\")\n        self.assertEqual(result, {\"div\": {\"id\": \"main\"}})\n    \n    def test_case_5(self):\n        # Test HTML with multiple different tags\n        data = b'<div><p class=\"text\">Hello</p></div>'\n        result = restore_object_from_stream(data, \"html\")\n        self.assertEqual(result, {\"div\": {}, \"p\": {\"class\": \"text\"}})\n    \n    def test_case_6(self):\n        # Test HTML with same tag multiple times (last occurrence overwrites)\n        data = b'<p id=\"first\"><p id=\"second\">'\n        result = restore_object_from_stream(data, \"html\")\n        self.assertEqual(result, {\"p\": {\"id\": \"second\"}})\n    \n    def test_case_7(self):\n        # Test HTML with empty byte_data\n        data = b''\n        result = restore_object_from_stream(data, \"html\")\n        self.assertEqual(result, {})\n    \n    def test_case_8(self):\n        # Test unsupported format 'xml'\n        data = b'<xml></xml>'\n        with self.assertRaises(ValueError):\n            restore_object_from_stream(data, \"xml\")\n    \n    def test_case_9(self):\n        # Test serialization_type as empty string\n        data = b'data'\n        with self.assertRaises(ValueError):\n            restore_object_from_stream(data, \"\")\n    \n    def test_case_10(self):\n        # Test serialization_type as None\n        data = b'data'\n        with self.assertRaises(ValueError):\n            restore_object_from_stream(data, None)\n    \n    def test_case_11(self):\n        # Test unsupported format 'yaml'\n        data = b'key: value'\n        with self.assertRaises(ValueError):\n            restore_object_from_stream(data, \"yaml\")\n    \n    def test_case_12(self):\n        # Test explicitly disallowed 'pickle' format\n        data = b'any_data'\n        with self.assertRaises(ValueError) as context:\n            restore_object_from_stream(data, \"pickle\")\n        self.assertIn(\"Deserialization with pickle format is not allowed due to security risks.\", str(context.exception))\n    \n    def test_case_13(self):\n        # Test default serialization_type (JSON)\n        data = b'{\"key\": \"value\"}'\n        result = restore_object_from_stream(data)\n        self.assertEqual(result, {\"key\": \"value\"})\n\nif __name__ == \"__main__\":\n    unittest.main()", "num_test_cases": 13, "task_id": "ec66cdad"}
{"test": "import unittest\nimport tempfile\nimport os\nimport json\n\nclass TestLoadSerializedData(unittest.TestCase):\n\n    def test_json_valid(self):\n        # Test with valid JSON content\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.json')\n            with open(file_path, 'wb') as f:\n                f.write(b'{\"name\": \"Alice\", \"age\": 30}')\n            result = load_serialized_data(file_path, 'json')\n            self.assertEqual(result, {'name': 'Alice', 'age': 30})\n\n    def test_text_non_empty(self):\n        # Test with non-empty text content\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.txt')\n            with open(file_path, 'wb') as f:\n                f.write(b'Hello, World!')\n            result = load_serialized_data(file_path, 'text')\n            self.assertEqual(result, 'Hello, World!')\n\n    def test_text_empty(self):\n        # Test with empty text content\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.txt')\n            with open(file_path, 'wb') as f:\n                f.write(b'')\n            result = load_serialized_data(file_path, 'text')\n            self.assertEqual(result, '')\n\n    def test_pickle_format(self):\n        # Test that pickle format raises ValueError\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.pkl')\n            with open(file_path, 'wb') as f:\n                f.write(b'any data')\n            with self.assertRaises(ValueError) as context:\n                load_serialized_data(file_path, 'pickle')\n            self.assertEqual(str(context.exception), 'Deserialization using pickle is prohibited due to security concerns.')\n\n    def test_unsupported_format(self):\n        # Test with an unsupported format type\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.xml')\n            with open(file_path, 'wb') as f:\n                f.write(b'<root></root>')\n            with self.assertRaises(ValueError) as context:\n                load_serialized_data(file_path, 'xml')\n            self.assertEqual(str(context.exception), 'Unsupported file format: xml')\n\n    def test_file_not_found(self):\n        # Test with non-existent file path\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'non_existent_file')\n            with self.assertRaises(FileNotFoundError):\n                load_serialized_data(file_path, 'json')\n\n    def test_none_format(self):\n        # Test with None as format_type\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.json')\n            with open(file_path, 'wb') as f:\n                f.write(b'{}')\n            with self.assertRaises(ValueError) as context:\n                load_serialized_data(file_path, None)\n            self.assertEqual(str(context.exception), 'Unsupported file format: None')\n\n    def test_empty_string_format(self):\n        # Test with empty string as format_type\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.json')\n            with open(file_path, 'wb') as f:\n                f.write(b'{}')\n            with self.assertRaises(ValueError) as context:\n                load_serialized_data(file_path, '')\n            self.assertEqual(str(context.exception), 'Unsupported file format: ')\n\n    def test_non_string_format(self):\n        # Test with non-string format_type (integer)\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.json')\n            with open(file_path, 'wb') as f:\n                f.write(b'{}')\n            with self.assertRaises(ValueError) as context:\n                load_serialized_data(file_path, 123)\n            self.assertEqual(str(context.exception), 'Unsupported file format: 123')\n\n    def test_json_empty_file(self):\n        # Test with empty file for JSON format (should raise JSONDecodeError)\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.json')\n            with open(file_path, 'wb') as f:\n                f.write(b'')\n            with self.assertRaises(json.JSONDecodeError):\n                load_serialized_data(file_path, 'json')\n\n    def test_text_invalid_utf8(self):\n        # Test with invalid UTF-8 bytes for text format (should raise UnicodeDecodeError)\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.txt')\n            with open(file_path, 'wb') as f:\n                f.write(b'\\xff\\xfe\\xfd')  # invalid UTF-8\n            with self.assertRaises(UnicodeDecodeError):\n                load_serialized_data(file_path, 'text')", "num_test_cases": 11, "task_id": "158149a4"}
{"test": "import unittest\nimport tempfile\nimport os\n\nclass TestDeserializeFileData(unittest.TestCase):\n\n    def test_json_valid(self):\n        # Test valid JSON deserialization\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp:\n            tmp.write(b'{\"name\": \"Alice\", \"age\": 30}')\n            tmp_path = tmp.name\n        try:\n            result = deserialize_file_data(tmp_path, 'json')\n            self.assertEqual(result, {'name': 'Alice', 'age': 30})\n        finally:\n            os.unlink(tmp_path)\n\n    def test_text_valid(self):\n        # Test valid text deserialization with non-ASCII characters\n        text = 'Hello, 世界!'\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp:\n            tmp.write(text.encode('utf-8'))\n            tmp_path = tmp.name\n        try:\n            result = deserialize_file_data(tmp_path, 'text')\n            self.assertEqual(result, text)\n        finally:\n            os.unlink(tmp_path)\n\n    def test_text_empty(self):\n        # Test empty text file deserialization\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp:\n            tmp_path = tmp.name\n        try:\n            result = deserialize_file_data(tmp_path, 'text')\n            self.assertEqual(result, '')\n        finally:\n            os.unlink(tmp_path)\n\n    def test_pickle_format(self):\n        # Test pickle format raises security error\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp:\n            tmp.write(b'any data')\n            tmp_path = tmp.name\n        try:\n            with self.assertRaises(ValueError) as context:\n                deserialize_file_data(tmp_path, 'pickle')\n            self.assertEqual(str(context.exception), 'Deserialization using pickle is prohibited due to security concerns.')\n        finally:\n            os.unlink(tmp_path)\n\n    def test_unsupported_format(self):\n        # Test unsupported format raises error\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp:\n            tmp.write(b'data')\n            tmp_path = tmp.name\n        try:\n            with self.assertRaises(ValueError) as context:\n                deserialize_file_data(tmp_path, 'xml')\n            self.assertEqual(str(context.exception), 'Unsupported file format: xml')\n        finally:\n            os.unlink(tmp_path)\n\n    def test_default_format_json(self):\n        # Test default format (JSON) deserialization\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp:\n            tmp.write(b'{\"key\": \"value\"}')\n            tmp_path = tmp.name\n        try:\n            result = deserialize_file_data(tmp_path)\n            self.assertEqual(result, {'key': 'value'})\n        finally:\n            os.unlink(tmp_path)\n", "num_test_cases": 6, "task_id": "8066e42d"}
{"test": "import unittest\nimport tempfile\nimport os\n\nclass TestInterpretSerializedContent(unittest.TestCase):\n\n    def test_json_happy_path(self):\n        # Test JSON with a valid JSON object\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.json')\n            with open(file_path, 'wb') as f:\n                f.write(b'{\"name\": \"Alice\", \"age\": 30}')\n            result = interpret_serialized_content(file_path, 'json')\n            self.assertEqual(result, {'name': 'Alice', 'age': 30})\n\n    def test_text_happy_path(self):\n        # Test text with a simple string\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.txt')\n            with open(file_path, 'wb') as f:\n                f.write(b'Hello, World!')\n            result = interpret_serialized_content(file_path, 'text')\n            self.assertEqual(result, 'Hello, World!')\n\n    def test_text_empty(self):\n        # Test text with an empty file\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.txt')\n            with open(file_path, 'wb') as f:\n                f.write(b'')\n            result = interpret_serialized_content(file_path, 'text')\n            self.assertEqual(result, '')\n\n    def test_pickle_prohibited(self):\n        # Test pickle format raises ValueError\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.pkl')\n            with open(file_path, 'wb') as f:\n                f.write(b'any data')\n            with self.assertRaises(ValueError) as context:\n                interpret_serialized_content(file_path, 'pickle')\n            self.assertEqual(str(context.exception), \"Deserialization using pickle is prohibited due to security concerns.\")\n\n    def test_unsupported_format(self):\n        # Test unsupported format (xml)\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.xml')\n            with open(file_path, 'wb') as f:\n                f.write(b'<root></root>')\n            with self.assertRaises(ValueError) as context:\n                interpret_serialized_content(file_path, 'xml')\n            self.assertEqual(str(context.exception), \"Unsupported file format: xml\")\n\n    def test_content_type_none(self):\n        # Test content_type None\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.json')\n            with open(file_path, 'wb') as f:\n                f.write(b'{}')\n            with self.assertRaises(ValueError) as context:\n                interpret_serialized_content(file_path, None)\n            self.assertEqual(str(context.exception), \"Unsupported file format: None\")\n\n    def test_content_type_integer(self):\n        # Test non-string content_type (integer)\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.json')\n            with open(file_path, 'wb') as f:\n                f.write(b'{}')\n            with self.assertRaises(ValueError) as context:\n                interpret_serialized_content(file_path, 123)\n            self.assertEqual(str(context.exception), \"Unsupported file format: 123\")\n\n    def test_default_content_type(self):\n        # Test default content_type (json)\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.json')\n            with open(file_path, 'wb') as f:\n                f.write(b'{\"key\": \"value\"}')\n            result = interpret_serialized_content(file_path)\n            self.assertEqual(result, {'key': 'value'})\n\n    def test_file_not_found(self):\n        # Test non-existent file path\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'non_existent.json')\n            with self.assertRaises(FileNotFoundError):\n                interpret_serialized_content(file_path, 'json')\n\n    def test_non_ascii_text(self):\n        # Test text with non-ASCII characters\n        with tempfile.TemporaryDirectory() as temp_dir:\n            file_path = os.path.join(temp_dir, 'test.txt')\n            with open(file_path, 'wb') as f:\n                f.write(b'\\xe4\\xbd\\xa0\\xe5\\xa5\\xbd')\n            result = interpret_serialized_content(file_path, 'text')\n            self.assertEqual(result, '\\u4f60\\u597d')\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 10, "task_id": "ecf23fbc"}
{"test": "import unittest\nimport tempfile\nimport os\nimport json\n\nclass TestProcessSerialfile(unittest.TestCase):\n    # Helper method to create temporary files\n    def _create_temp_file(self, content):\n        temp_file = tempfile.NamedTemporaryFile(mode='wb', delete=False)\n        temp_file.write(content)\n        temp_file.close()\n        self.addCleanup(os.remove, temp_file.name)\n        return temp_file.name\n\n    def test_json_valid_content(self):\n        # Test JSON format with valid content\n        content = b'{\"name\": \"Alice\", \"age\": 30, \"city\": \"Paris\"}'\n        file_path = self._create_temp_file(content)\n        result = process_serialfile(file_path, 'json')\n        self.assertIsInstance(result, dict)\n        self.assertEqual(result, {\"name\": \"Alice\", \"age\": 30, \"city\": \"Paris\"})\n\n    def test_json_empty_file(self):\n        # Test JSON format with empty file content\n        file_path = self._create_temp_file(b'')\n        with self.assertRaises(json.JSONDecodeError):\n            process_serialfile(file_path, 'json')\n\n    def test_text_valid_content(self):\n        # Test text format with valid content\n        content = b'This is a sample text.'\n        file_path = self._create_temp_file(content)\n        result = process_serialfile(file_path, 'text')\n        self.assertIsInstance(result, str)\n        self.assertEqual(result, 'This is a sample text.')\n\n    def test_text_empty_file(self):\n        # Test text format with empty file content\n        file_path = self._create_temp_file(b'')\n        result = process_serialfile(file_path, 'text')\n        self.assertEqual(result, '')\n\n    def test_pickle_format_prohibited(self):\n        # Test that 'pickle' format raises ValueError\n        content = b'any content'\n        file_path = self._create_temp_file(content)\n        with self.assertRaises(ValueError) as context:\n            process_serialfile(file_path, 'pickle')\n        self.assertEqual(str(context.exception), \"Deserialization using pickle is prohibited due to security concerns.\")\n\n    def test_unsupported_format(self):\n        # Test unsupported format (e.g., 'xml')\n        content = b'any content'\n        file_path = self._create_temp_file(content)\n        with self.assertRaises(ValueError) as context:\n            process_serialfile(file_path, 'xml')\n        self.assertEqual(str(context.exception), \"Unsupported file format: xml\")\n\n    def test_format_type_none(self):\n        # Test None as format type\n        content = b'any content'\n        file_path = self._create_temp_file(content)\n        with self.assertRaises(ValueError) as context:\n            process_serialfile(file_path, None)\n        self.assertEqual(str(context.exception), \"Unsupported file format: None\")\n\n    def test_file_not_found(self):\n        # Test non-existent file path\n        non_existent_path = \"/path/to/non_existent_file_12345\"\n        # Ensure the file doesn't exist\n        if os.path.exists(non_existent_path):\n            os.remove(non_existent_path)\n        with self.assertRaises(FileNotFoundError):\n            process_serialfile(non_existent_path, 'json')\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 9, "task_id": "badea65b"}
{"test": "import unittest\nimport tempfile\nimport os\n\nclass TestLoadSerializedData(unittest.TestCase):\n\n    def test_valid_json(self):\n        \"\"\"Test deserialization of valid JSON data.\"\"\"\n        # Create a temporary JSON file\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as f:\n            f.write(b'{\\\"name\\\": \\\"Alice\\\", \\\"age\\\": 30}')\n            filepath = f.name\n        self.addCleanup(os.unlink, filepath)\n        \n        result = load_serialized_data(filepath, 'json')\n        self.assertIsInstance(result, dict)\n        self.assertEqual(result['name'], 'Alice')\n        self.assertEqual(result['age'], 30)\n\n    def test_valid_text(self):\n        \"\"\"Test reading plain text data.\"\"\"\n        # Create a temporary text file\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as f:\n            f.write(b'Hello, World!')\n            filepath = f.name\n        self.addCleanup(os.unlink, filepath)\n        \n        result = load_serialized_data(filepath, 'text')\n        self.assertIsInstance(result, str)\n        self.assertEqual(result, 'Hello, World!')\n\n    def test_empty_text_file(self):\n        \"\"\"Test reading an empty text file.\"\"\"\n        # Create an empty temporary file\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as f:\n            filepath = f.name\n        self.addCleanup(os.unlink, filepath)\n        \n        result = load_serialized_data(filepath, 'text')\n        self.assertEqual(result, '')\n\n    def test_invalid_json(self):\n        \"\"\"Test deserialization of malformed JSON data.\"\"\"\n        # Create a temporary file with invalid JSON\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as f:\n            f.write(b'{\\\"name\\\": \\\"Bob\\\"')\n            filepath = f.name\n        self.addCleanup(os.unlink, filepath)\n        \n        with self.assertRaises(ValueError):\n            load_serialized_data(filepath, 'json')\n\n    def test_pickle_format_prohibited(self):\n        \"\"\"Test that pickle format raises a security error.\"\"\"\n        # Create a temporary file (content irrelevant for this test)\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as f:\n            f.write(b'any data')\n            filepath = f.name\n        self.addCleanup(os.unlink, filepath)\n        \n        with self.assertRaises(ValueError) as context:\n            load_serialized_data(filepath, 'pickle')\n        self.assertIn('prohibited due to security concerns', str(context.exception))\n\n    def test_unsupported_format(self):\n        \"\"\"Test an unsupported data format.\"\"\"\n        # Create a temporary file\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as f:\n            f.write(b'data')\n            filepath = f.name\n        self.addCleanup(os.unlink, filepath)\n        \n        with self.assertRaises(ValueError) as context:\n            load_serialized_data(filepath, 'xml')\n        self.assertIn('Unsupported file format: xml', str(context.exception))\n\n    def test_nonexistent_file(self):\n        \"\"\"Test handling of non-existent file path.\"\"\"\n        with self.assertRaises(FileNotFoundError):\n            load_serialized_data('non_existent_file.json', 'json')\n\n    def test_default_format_json(self):\n        \"\"\"Test that JSON is used when no format is specified.\"\"\"\n        # Create a temporary JSON file\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as f:\n            f.write(b'{\\\"key\\\": \\\"value\\\"}')\n            filepath = f.name\n        self.addCleanup(os.unlink, filepath)\n        \n        result = load_serialized_data(filepath)\n        self.assertEqual(result, {'key': 'value'})", "num_test_cases": 8, "task_id": "dad1f527"}
{"test": "import unittest\nimport tempfile\nimport os\nimport json\nfrom solution import handle_serialized_file\n\nclass TestHandleSerializedFile(unittest.TestCase):\n    def test_json_dict(self):\n        \"\"\"Test JSON format with a dictionary.\"\"\"\n        data = {'key': 'value'}\n        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n            temp_file.write(json.dumps(data).encode())\n            temp_file_path = temp_file.name\n        \n        try:\n            result = handle_serialized_file(temp_file_path, 'json')\n            self.assertEqual(result, data)\n        finally:\n            os.unlink(temp_file_path)\n    \n    def test_json_array(self):\n        \"\"\"Test JSON format with an array.\"\"\"\n        data = [1, 2, 3]\n        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n            temp_file.write(json.dumps(data).encode())\n            temp_file_path = temp_file.name\n        \n        try:\n            result = handle_serialized_file(temp_file_path, 'json')\n            self.assertEqual(result, data)\n        finally:\n            os.unlink(temp_file_path)\n    \n    def test_text_simple(self):\n        \"\"\"Test text format with a simple string.\"\"\"\n        data = \"simple string\"\n        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n            temp_file.write(data.encode())\n            temp_file_path = temp_file.name\n        \n        try:\n            result = handle_serialized_file(temp_file_path, 'text')\n            self.assertEqual(result, data)\n        finally:\n            os.unlink(temp_file_path)\n    \n    def test_text_multi_line(self):\n        \"\"\"Test text format with a multi-line string.\"\"\"\n        data = \"line1\\nline2\\nline3\"\n        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n            temp_file.write(data.encode())\n            temp_file_path = temp_file.name\n        \n        try:\n            result = handle_serialized_file(temp_file_path, 'text')\n            self.assertEqual(result, data)\n        finally:\n            os.unlink(temp_file_path)\n    \n    def test_default_format(self):\n        \"\"\"Test default format (json) without providing the second argument.\"\"\"\n        data = {'default': 'test'}\n        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n            temp_file.write(json.dumps(data).encode())\n            temp_file_path = temp_file.name\n        \n        try:\n            result = handle_serialized_file(temp_file_path)\n            self.assertEqual(result, data)\n        finally:\n            os.unlink(temp_file_path)\n    \n    def test_pickle_format(self):\n        \"\"\"Test pickle format raises ValueError with specific message.\"\"\"\n        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n            temp_file.write(b\"dummy data\")\n            temp_file_path = temp_file.name\n        \n        try:\n            with self.assertRaises(ValueError) as context:\n                handle_serialized_file(temp_file_path, 'pickle')\n            self.assertEqual(str(context.exception), \"Deserialization using pickle is prohibited due to security concerns.\")\n        finally:\n            os.unlink(temp_file_path)\n    \n    def test_unsupported_format(self):\n        \"\"\"Test unsupported format (xml) raises ValueError.\"\"\"\n        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n            temp_file.write(b\"dummy data\")\n            temp_file_path = temp_file.name\n        \n        try:\n            with self.assertRaises(ValueError) as context:\n                handle_serialized_file(temp_file_path, 'xml')\n            self.assertEqual(str(context.exception), \"Unsupported file format: xml\")\n        finally:\n            os.unlink(temp_file_path)\n    \n    def test_file_not_found(self):\n        \"\"\"Test non-existent file path raises FileNotFoundError.\"\"\"\n        non_existent_path = \"/path/that/does/not/exist\"\n        with self.assertRaises(FileNotFoundError):\n            handle_serialized_file(non_existent_path, 'json')\n    \n    def test_format_none(self):\n        \"\"\"Test serialization_format as None raises ValueError.\"\"\"\n        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n            temp_file.write(b\"dummy data\")\n            temp_file_path = temp_file.name\n        \n        try:\n            with self.assertRaises(ValueError) as context:\n                handle_serialized_file(temp_file_path, None)\n            self.assertIn(\"Unsupported file format\", str(context.exception))\n        finally:\n            os.unlink(temp_file_path)\n    \n    def test_format_integer(self):\n        \"\"\"Test serialization_format as integer raises ValueError.\"\"\"\n        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n            temp_file.write(b\"dummy data\")\n            temp_file_path = temp_file.name\n        \n        try:\n            with self.assertRaises(ValueError) as context:\n                handle_serialized_file(temp_file_path, 123)\n            self.assertIn(\"Unsupported file format\", str(context.exception))\n        finally:\n            os.unlink(temp_file_path)\n    \n    def test_format_empty_string(self):\n        \"\"\"Test serialization_format as empty string raises ValueError.\"\"\"\n        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n            temp_file.write(b\"dummy data\")\n            temp_file_path = temp_file.name\n        \n        try:\n            with self.assertRaises(ValueError) as context:\n                handle_serialized_file(temp_file_path, '')\n            self.assertEqual(str(context.exception), \"Unsupported file format: \")\n        finally:\n            os.unlink(temp_file_path)\n    \n    def test_file_path_empty_string(self):\n        \"\"\"Test file path as empty string raises FileNotFoundError.\"\"\"\n        with self.assertRaises(FileNotFoundError):\n            handle_serialized_file('', 'json')\n    \n    def test_file_path_none(self):\n        \"\"\"Test file path as None raises TypeError.\"\"\"\n        with self.assertRaises(TypeError):\n            handle_serialized_file(None, 'json')", "num_test_cases": 13, "task_id": "dc22610b"}
{"test": "import unittest\nimport tempfile\nimport os\n\nclass TestLoadSerialData(unittest.TestCase):\n\n    def test_json_simple(self):\n        # Test JSON format with a simple dictionary\n        content = b'{\"name\": \"Alice\", \"age\": 30}'\n        with tempfile.NamedTemporaryFile(delete=False) as temp:\n            temp.write(content)\n            temp_path = temp.name\n        try:\n            result = load_serial_data(temp_path, 'json')\n            self.assertEqual(result, {\"name\": \"Alice\", \"age\": 30})\n        finally:\n            os.unlink(temp_path)\n\n    def test_json_complex(self):\n        # Test JSON format with nested data\n        content = b'{\"users\": [{\"name\": \"Alice\", \"age\": 30}, {\"name\": \"Bob\", \"age\": 25}]}'\n        with tempfile.NamedTemporaryFile(delete=False) as temp:\n            temp.write(content)\n            temp_path = temp.name\n        try:\n            result = load_serial_data(temp_path, 'json')\n            expected = {\"users\": [{\"name\": \"Alice\", \"age\": 30}, {\"name\": \"Bob\", \"age\": 25}]}\n            self.assertEqual(result, expected)\n        finally:\n            os.unlink(temp_path)\n\n    def test_text_non_empty(self):\n        # Test text format with non-empty content\n        content = b'This is a text file.'\n        with tempfile.NamedTemporaryFile(delete=False) as temp:\n            temp.write(content)\n            temp_path = temp.name\n        try:\n            result = load_serial_data(temp_path, 'text')\n            self.assertEqual(result, \"This is a text file.\")\n        finally:\n            os.unlink(temp_path)\n\n    def test_text_empty(self):\n        # Test text format with empty file\n        content = b''\n        with tempfile.NamedTemporaryFile(delete=False) as temp:\n            temp.write(content)\n            temp_path = temp.name\n        try:\n            result = load_serial_data(temp_path, 'text')\n            self.assertEqual(result, \"\")\n        finally:\n            os.unlink(temp_path)\n\n    def test_pickle_format(self):\n        # Test pickle format raises ValueError\n        content = b'any content'\n        with tempfile.NamedTemporaryFile(delete=False) as temp:\n            temp.write(content)\n            temp_path = temp.name\n        try:\n            with self.assertRaises(ValueError) as context:\n                load_serial_data(temp_path, 'pickle')\n            self.assertEqual(str(context.exception), \"Deserialization using pickle is prohibited due to security concerns.\")\n        finally:\n            os.unlink(temp_path)\n\n    def test_unsupported_format(self):\n        # Test unsupported format raises ValueError\n        content = b'any content'\n        with tempfile.NamedTemporaryFile(delete=False) as temp:\n            temp.write(content)\n            temp_path = temp.name\n        try:\n            with self.assertRaises(ValueError) as context:\n                load_serial_data(temp_path, 'xml')\n            self.assertEqual(str(context.exception), \"Unsupported file format: xml\")\n        finally:\n            os.unlink(temp_path)\n\n    def test_default_format(self):\n        # Test default format (json) works\n        content = b'{\"key\": \"value\"}'\n        with tempfile.NamedTemporaryFile(delete=False) as temp:\n            temp.write(content)\n            temp_path = temp.name\n        try:\n            result = load_serial_data(temp_path)\n            self.assertEqual(result, {\"key\": \"value\"})\n        finally:\n            os.unlink(temp_path)\n\nif __name__ == '__main__':\n    unittest.main()", "num_test_cases": 7, "task_id": "3c98d6e8"}
{"test": "import unittest\nimport tempfile\nimport os\n\nclass TestDeserializeFileData(unittest.TestCase):\n\n    def test_json_valid(self):\n        \"\"\"Test valid JSON file deserialization.\"\"\"\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp:\n            tmp.write(b'{\\\"key\\\": \\\"value\\\"}')\n            filepath = tmp.name\n        self.addCleanup(os.unlink, filepath)\n        \n        result = deserialize_file_data(filepath, 'json')\n        self.assertEqual(result, {\"key\": \"value\"})\n\n    def test_json_empty(self):\n        \"\"\"Test empty JSON file raises JSONDecodeError.\"\"\"\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp:\n            filepath = tmp.name  # Empty file\n        self.addCleanup(os.unlink, filepath)\n        \n        with self.assertRaises(ValueError) as context:\n            deserialize_file_data(filepath, 'json')\n        self.assertIn('Expecting value', str(context.exception))\n\n    def test_json_invalid(self):\n        \"\"\"Test invalid JSON content raises JSONDecodeError.\"\"\"\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp:\n            tmp.write(b'{invalid}')\n            filepath = tmp.name\n        self.addCleanup(os.unlink, filepath)\n        \n        with self.assertRaises(ValueError) as context:\n            deserialize_file_data(filepath, 'json')\n        self.assertIn('Expecting property name enclosed', str(context.exception))\n\n    def test_text_valid(self):\n        \"\"\"Test valid text file deserialization.\"\"\"\n        content = b'Hello, World!'\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp:\n            tmp.write(content)\n            filepath = tmp.name\n        self.addCleanup(os.unlink, filepath)\n        \n        result = deserialize_file_data(filepath, 'text')\n        self.assertEqual(result, 'Hello, World!')\n\n    def test_text_empty(self):\n        \"\"\"Test empty text file returns empty string.\"\"\"\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp:\n            filepath = tmp.name  # Empty file\n        self.addCleanup(os.unlink, filepath)\n        \n        result = deserialize_file_data(filepath, 'text')\n        self.assertEqual(result, '')\n\n    def test_pickle_format(self):\n        \"\"\"Test pickle format raises ValueError.\"\"\"\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp:\n            tmp.write(b'any content')\n            filepath = tmp.name\n        self.addCleanup(os.unlink, filepath)\n        \n        with self.assertRaises(ValueError) as context:\n            deserialize_file_data(filepath, 'pickle')\n        self.assertEqual(str(context.exception), \"Deserialization using pickle is prohibited due to security concerns.\")\n\n    def test_unsupported_format(self):\n        \"\"\"Test unsupported format raises ValueError.\"\"\"\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp:\n            tmp.write(b'content')\n            filepath = tmp.name\n        self.addCleanup(os.unlink, filepath)\n        \n        with self.assertRaises(ValueError) as context:\n            deserialize_file_data(filepath, 'xml')\n        self.assertEqual(str(context.exception), \"Unsupported file format: xml\")\n\n    def test_nonexistent_file(self):\n        \"\"\"Test non-existent file raises FileNotFoundError.\"\"\"\n        with self.assertRaises(FileNotFoundError):\n            deserialize_file_data(\"/path/that/does/not/exist\", 'json')\n\n    def test_none_filepath(self):\n        \"\"\"Test None filepath raises TypeError.\"\"\"\n        with self.assertRaises(TypeError):\n            deserialize_file_data(None, 'json')\n\n    def test_non_string_filepath(self):\n        \"\"\"Test non-string filepath raises TypeError.\"\"\"\n        with self.assertRaises(TypeError):\n            deserialize_file_data(123, 'json')\n\n    def test_non_string_format(self):\n        \"\"\"Test non-string input_format raises ValueError.\"\"\"\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp:\n            filepath = tmp.name\n        self.addCleanup(os.unlink, filepath)\n        \n        with self.assertRaises(ValueError) as context:\n            deserialize_file_data(filepath, 123)\n        self.assertEqual(str(context.exception), \"Unsupported file format: 123\")\n", "num_test_cases": 11, "task_id": "f876871e"}
{"test": "import unittest\nimport tempfile\nimport os\n\nclass TestLoadSerializedData(unittest.TestCase):\n\n    def test_valid_json_dict(self):\n        # Test loading valid JSON dictionary\n        content = b'{\"name\": \"Alice\", \"age\": 30}'\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp_file:\n            tmp_file.write(content)\n            tmp_path = tmp_file.name\n        self.addCleanup(os.unlink, tmp_path)\n        \n        result = load_serialized_data(tmp_path, 'json')\n        self.assertEqual(result, {\"name\": \"Alice\", \"age\": 30})\n\n    def test_valid_json_list(self):\n        # Test loading valid JSON list\n        content = b'[1, 2, 3, 4, 5]'\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp_file:\n            tmp_file.write(content)\n            tmp_path = tmp_file.name\n        self.addCleanup(os.unlink, tmp_path)\n        \n        result = load_serialized_data(tmp_path, 'json')\n        self.assertEqual(result, [1, 2, 3, 4, 5])\n\n    def test_valid_text(self):\n        # Test loading text content\n        content = b'Simple text content'\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp_file:\n            tmp_file.write(content)\n            tmp_path = tmp_file.name\n        self.addCleanup(os.unlink, tmp_path)\n        \n        result = load_serialized_data(tmp_path, 'text')\n        self.assertEqual(result, 'Simple text content')\n\n    def test_pickle_format(self):\n        # Test pickle format raises ValueError\n        content = b'any content'\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp_file:\n            tmp_file.write(content)\n            tmp_path = tmp_file.name\n        self.addCleanup(os.unlink, tmp_path)\n        \n        with self.assertRaises(ValueError) as context:\n            load_serialized_data(tmp_path, 'pickle')\n        self.assertIn('prohibited due to security concerns', str(context.exception))\n\n    def test_unsupported_format(self):\n        # Test unsupported format\n        content = b'<xml>data</xml>'\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp_file:\n            tmp_file.write(content)\n            tmp_path = tmp_file.name\n        self.addCleanup(os.unlink, tmp_path)\n        \n        with self.assertRaises(ValueError) as context:\n            load_serialized_data(tmp_path, 'xml')\n        self.assertIn('Unsupported file format: xml', str(context.exception))\n\n    def test_empty_format(self):\n        # Test empty format string\n        content = b'content'\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp_file:\n            tmp_file.write(content)\n            tmp_path = tmp_file.name\n        self.addCleanup(os.unlink, tmp_path)\n        \n        with self.assertRaises(ValueError) as context:\n            load_serialized_data(tmp_path, '')\n        self.assertIn('Unsupported file format: ', str(context.exception))\n\n    def test_none_format(self):\n        # Test None format\n        content = b'content'\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp_file:\n            tmp_file.write(content)\n            tmp_path = tmp_file.name\n        self.addCleanup(os.unlink, tmp_path)\n        \n        with self.assertRaises(ValueError) as context:\n            load_serialized_data(tmp_path, None)\n        self.assertIn('Unsupported file format: None', str(context.exception))\n\n    def test_non_string_format(self):\n        # Test non-string format type\n        content = b'content'\n        with tempfile.NamedTemporaryFile(mode='wb', delete=False) as tmp_file:\n            tmp_file.write(content)\n            tmp_path = tmp_file.name\n        self.addCleanup(os.unlink, tmp_path)\n        \n        with self.assertRaises(ValueError) as context:\n            load_serialized_data(tmp_path, 123)\n        self.assertIn('Unsupported file format: 123', str(context.exception))", "num_test_cases": 8, "task_id": "e0e9af1f"}
{"test": "import unittest\n\nclass TestConvertToObject(unittest.TestCase):\n    def test_json_basic(self):\n        # Test basic JSON deserialization\n        data = b'{\\\"name\\\": \\\"Alice\\\", \\\"age\\\": 30}'\n        expected = {'name': 'Alice', 'age': 30}\n        result = convert_to_object(data, 'json')\n        self.assertEqual(result, expected)\n    \n    def test_json_empty(self):\n        # Test empty JSON object\n        data = b'{}'\n        expected = {}\n        result = convert_to_object(data, 'json')\n        self.assertEqual(result, expected)\n    \n    def test_json_string(self):\n        # Test JSON that is a string\n        data = b'\\\"Hello, World!\\\"'\n        expected = 'Hello, World!'\n        result = convert_to_object(data, 'json')\n        self.assertEqual(result, expected)\n    \n    def test_xml_basic_flat(self):\n        # Test basic XML with flat structure\n        data = b'<root><name>Alice</name><age>30</age></root>'\n        expected = {'name': 'Alice', 'age': '30'}\n        result = convert_to_object(data, 'xml')\n        self.assertEqual(result, expected)\n    \n    def test_xml_empty(self):\n        # Test empty XML\n        data = b'<root></root>'\n        expected = {}\n        result = convert_to_object(data, 'xml')\n        self.assertEqual(result, expected)\n    \n    def test_xml_nested(self):\n        # Test XML with nested elements\n        data = b'<root><child><sub>text</sub></child></root>'\n        expected = {'child': None}\n        result = convert_to_object(data, 'xml')\n        self.assertEqual(result, expected)\n    \n    def test_xml_with_attributes(self):\n        # Test XML with attributes in elements\n        data = b'<root><person name=\\\"Alice\\\">25</person></root>'\n        expected = {'person': '25'}\n        result = convert_to_object(data, 'xml')\n        self.assertEqual(result, expected)\n    \n    def test_pickle_prohibited(self):\n        # Test that pickle format raises the expected error\n        with self.assertRaises(ValueError) as context:\n            convert_to_object(b'anything', 'pickle')\n        self.assertEqual(str(context.exception), 'Deserialization using pickle is prohibited due to security concerns.')\n    \n    def test_unsupported_format_yaml(self):\n        # Test an unsupported format (yaml)\n        with self.assertRaises(ValueError) as context:\n            convert_to_object(b'anything', 'yaml')\n        self.assertEqual(str(context.exception), \"Format 'yaml' is not supported.\")\n    \n    def test_unsupported_format_none(self):\n        # Test None as format type\n        with self.assertRaises(ValueError) as context:\n            convert_to_object(b'anything', None)\n        self.assertEqual(str(context.exception), \"Format 'None' is not supported.\")\n    \n    def test_unsupported_format_int(self):\n        # Test non-string format type (integer)\n        with self.assertRaises(ValueError) as context:\n            convert_to_object(b'anything', 123)\n        self.assertEqual(str(context.exception), \"Format '123' is not supported.\")\n", "num_test_cases": 11, "task_id": "4b349d47"}
{"test": "import unittest\nimport json\n\nclass TestRestoreObject(unittest.TestCase):\n    def test_json_valid(self):\n        # Test with valid JSON data\n        data = b'{\"name\": \"Alice\", \"age\": 30}'\n        result = restore_object(data, \"json\")\n        self.assertEqual(result, {\"name\": \"Alice\", \"age\": 30})\n\n    def test_json_invalid(self):\n        # Test with invalid JSON data\n        data = b'invalid json!'\n        with self.assertRaises(json.JSONDecodeError):\n            restore_object(data, \"json\")\n\n    def test_json_empty_bytes(self):\n        # Test with empty bytes for JSON\n        data = b''\n        with self.assertRaises(json.JSONDecodeError):\n            restore_object(data, \"json\")\n\n    def test_json_default_method(self):\n        # Test default method (JSON) with valid data\n        data = b'{\"key\": \"value\"}'\n        result = restore_object(data)\n        self.assertEqual(result, {\"key\": \"value\"})\n\n    def test_csv_valid(self):\n        # Test with valid CSV data\n        data = b'id,name\\n1,Alice\\n2,Bob'\n        result = restore_object(data, \"csv\")\n        self.assertEqual(result, [[\"id\", \"name\"], [\"1\", \"Alice\"], [\"2\", \"Bob\"]])\n\n    def test_csv_empty_bytes(self):\n        # Test with empty bytes for CSV\n        data = b''\n        result = restore_object(data, \"csv\")\n        self.assertEqual(result, [])\n\n    def test_csv_single_row(self):\n        # Test CSV with single row (no newline)\n        data = b'header1,header2'\n        result = restore_object(data, \"csv\")\n        self.assertEqual(result, [[\"header1\", \"header2\"]])\n\n    def test_pickle_method(self):\n        # Test that pickle method raises ValueError\n        data = b'any_data'\n        with self.assertRaises(ValueError) as context:\n            restore_object(data, \"pickle\")\n        self.assertIn(\"Deserialization with pickle is not allowed\", str(context.exception))\n\n    def test_unsupported_method(self):\n        # Test with unsupported serialization method\n        data = b'data'\n        with self.assertRaises(ValueError) as context:\n            restore_object(data, \"xml\")\n        self.assertIn(\"Unsupported serialization method: xml\", str(context.exception))\n\n    def test_none_json(self):\n        # Test None input with JSON method\n        with self.assertRaises(TypeError):\n            restore_object(None, \"json\")\n\n    def test_none_csv(self):\n        # Test None input with CSV method\n        with self.assertRaises(AttributeError):\n            restore_object(None, \"csv\")\n\n    def test_zero_json(self):\n        # Test integer 0 input with JSON method\n        with self.assertRaises(TypeError):\n            restore_object(0, \"json\")\n\n    def test_zero_csv(self):\n        # Test integer 0 input with CSV method\n        with self.assertRaises(AttributeError):\n            restore_object(0, \"csv\")", "num_test_cases": 13, "task_id": "e3c0f8fe"}
